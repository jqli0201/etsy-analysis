{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "combined_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkTJlHqUh9P4",
        "outputId": "f9f0ae9b-78f4-43fe-cc9b-51f1f71d70d6"
      },
      "source": [
        "import pandas as pd \n",
        "import nltk\n",
        "import numpy as np\n",
        "#load inthe NTLK stopwords to remove articles, preposition and other words that are not actionable\n",
        "from nltk.corpus import stopwords\n",
        "# This allows to create individual objects from a bog of words\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "# Lemmatizer helps to reduce words to the base form\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')\n",
        "df=pd.read_csv('gdrive/My Drive/summer.csv')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yMVG2v8iJOT"
      },
      "source": [
        "def process_sentence(sentence):\n",
        "    new_tokens = word_tokenize(sentence)\n",
        "    new_tokens = [t.lower() for t in new_tokens]\n",
        "    new_tokens =[t for t in new_tokens if t not in stopwords.words('english')]\n",
        "    new_tokens = [t for t in new_tokens if t.isalpha()]\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    new_tokens =[lemmatizer.lemmatize(t) for t in new_tokens]\n",
        "    return new_tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WT5b6G3RiORf"
      },
      "source": [
        "titles = df['title_orig'].tolist()\n",
        "tokens = [process_sentence(t) for t in titles]\n",
        "df['title_pre'] = tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCw-jN3BiQ-7"
      },
      "source": [
        "def tag_data(sentences):\n",
        "    tagged_data = [TaggedDocument(words=word_tokenize(sentence.lower()), tags=[str(i)]) for i, sentence in enumerate(sentences)]\n",
        "    return tagged_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRV8bKJBifsX"
      },
      "source": [
        "tagged_data = tag_data(titles)\n",
        "max_epochs = 100\n",
        "vec_size = 50\n",
        "alpha = 0.025\n",
        "\n",
        "# dm=1 means ‘distributed memory’ (PV-DM) and dm =0 means ‘distributed bag of words’ (PV-DBOW). \n",
        "# Distributed Memory model preserves the word order in a document whereas Distributed Bag of words just \n",
        "# uses the bag of words approach, which doesn’t preserve any word order.\n",
        "model = Doc2Vec(vector_size=vec_size,\n",
        "                alpha=alpha, \n",
        "                min_alpha=0.00025,\n",
        "                min_count=1,\n",
        "                dm =1) \n",
        "\n",
        "model.build_vocab(tagged_data)\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "    print('iteration {0}'.format(epoch))\n",
        "    model.train(tagged_data,\n",
        "                total_examples=model.corpus_count,\n",
        "                epochs=model.epochs)\n",
        "    # decrease the learning rate\n",
        "    model.alpha -= 0.0002\n",
        "    # fix the learning rate, no decay\n",
        "    model.min_alpha = model.alpha\n",
        "\n",
        "model.save(\"d2v.model\")\n",
        "print(\"Model Saved\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFMba1yVps33",
        "outputId": "b1b3504e-cc17-4c2b-a102-0f8289a38d62"
      },
      "source": [
        "test_data = word_tokenize(\"I love Siri\".lower())\n",
        "v1 = model.infer_vector(test_data)\n",
        "print(\"V1_infer\", v1)\n",
        "\n",
        "# to find most similar doc using tags\n",
        "similar_doc = model.docvecs.most_similar('71')\n",
        "print(similar_doc)\n",
        "\n",
        "# to find vector of doc in training data using tags or in other words, printing the vector of document at index 1 in training data\n",
        "print(model.docvecs['3'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "V1_infer [-0.03295992  0.02979724  0.0270473   0.01490511 -0.02018705  0.00209453\n",
            "  0.03026015 -0.00412308 -0.00106341  0.00244622  0.04079009 -0.02986277\n",
            "  0.00624197 -0.00837779  0.01563566  0.02020906  0.02805164 -0.00655257\n",
            " -0.01395824  0.00860703  0.02867967 -0.01437546 -0.03614611  0.00723895\n",
            "  0.00838543 -0.04832076 -0.00694362  0.004761    0.00036052 -0.03647539\n",
            "  0.0099448  -0.02011867 -0.03959376  0.05758795  0.02284324 -0.01261535\n",
            "  0.03991595 -0.00916865 -0.01931195  0.0013374   0.00268112  0.00810816\n",
            " -0.01250574 -0.02234735 -0.04877358  0.05425513 -0.0216164   0.01807866\n",
            " -0.0016392  -0.0030226 ]\n",
            "[('575', 0.990645706653595), ('1194', 0.8065142035484314), ('249', 0.7955174446105957), ('1422', 0.7911226153373718), ('1091', 0.6073912382125854), ('731', 0.5884032249450684), ('1039', 0.582223117351532), ('1087', 0.5792473554611206), ('846', 0.5717340111732483), ('312', 0.5704469680786133)]\n",
            "[ 2.1195943  -0.4604921  -0.06325115  1.9574708   2.8432477   1.2415683\n",
            "  2.4366734   1.2175804   0.23761001  2.9702997   3.035476   -0.1493611\n",
            " -0.32038155 -0.2772368   0.7915127  -0.641995   -2.3261795   0.350117\n",
            " -0.955911   -0.8939786   1.2801961  -1.9054172   1.0308466  -0.20483455\n",
            " -0.66686034 -0.21157433  2.853776   -1.7600886  -1.177236   -0.31819397\n",
            " -2.7101815  -2.2444339  -1.6312693  -1.2057014   2.2370481  -0.41775882\n",
            "  0.62847537 -0.36373842 -0.3180934  -2.6551456  -1.5755361   0.7749617\n",
            " -3.1332505  -0.46252576  0.17405829 -1.9310553  -0.9954403   0.54657847\n",
            "  1.3749269   0.24097288]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJseMtmnUS5Q"
      },
      "source": [
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import urllib.request\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# load the image with urllib + BytesIO\n",
        "pixel = [np.array(Image.open(BytesIO(urllib.request.urlopen(url).read())).resize((224,224),Image.ANTIALIAS)) for url in df[\"product_picture\"]]\n",
        "df[\"image_pixel\"] = pixel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJ6TllmWUtw6"
      },
      "source": [
        "def main_color(s):\n",
        "  main_color = {\"red\":\"red\", \"white\":\"white\", \"pink\":\"pink\", \"yellow\":\"yellow\", \"green\":\"green\", \"blue\":\"blue\", \"wine\":\"red\", \"burgundy\":\"red\", \"black\":\"black\", \"navy\":\"navy\", \"orange\":\"orange\", \n",
        "  \"rose\":\"pink\", \"gray\":\"gray\", \"grey\":\"gray\", \"purple\":\"purple\", \"violet\":\"purple\", \"army\":\"green\", \"leopard\":\"orange\", \"ivory\":\"white\", \n",
        "  \"brown\":\"brown\", \"coffee\":\"brown\", \"camel\":\"beige\", \"tan\":\"brown\", \"nude\":\"beige\", \"khaki\":\"khaki\", \"apricot\":\"yellow\", \"camouflage\":\"green\", \"jasper\":\"red\"}  # ordered by importance\n",
        "  for key, value in main_color.items():\n",
        "    if key in s:\n",
        "      return value\n",
        "  return \"others\"\n",
        "product_color = df[\"product_color\"]\n",
        "product_color = [s.lower() if type(s) is str else 'nan' for s in product_color]\n",
        "product_color = [main_color(s) for s in product_color]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32UkGyR2ViTd"
      },
      "source": [
        "from matplotlib import colors\n",
        "avg_list = []\n",
        "for s in product_color:\n",
        "  if s != \"others\":\n",
        "    avg_list.append(np.array(colors.to_rgb(s)))\n",
        "average_color = tuple(np.array(avg_list).mean(0))\n",
        "product_color = [average_color if s == \"others\" else colors.to_rgb(s) for s in product_color]\n",
        "df['product_color_rgb'] = [np.array(t) for t in product_color]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d85FL2Kjnm8"
      },
      "source": [
        "df['doc2vec'] = [model.infer_vector(title) for title in df['title_pre']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vc2x7gg3Wa5q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c46c5b78-7283-4ac4-cea8-bb339740c27e"
      },
      "source": [
        "import pandas as pd \n",
        "import nltk\n",
        "import numpy as np\n",
        "#load inthe NTLK stopwords to remove articles, preposition and other words that are not actionable\n",
        "from nltk.corpus import stopwords\n",
        "# This allows to create individual objects from a bog of words\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "# Lemmatizer helps to reduce words to the base form\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from google.colab import drive \n",
        "# df.to_pickle(\"image_doc2vec_features.pkl\")\n",
        "drive.mount('/content/gdrive')\n",
        "df = pd.read_pickle('gdrive/My Drive/image_doc2vec_features.pkl')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjN7p1taXFWp"
      },
      "source": [
        "df['log_price'] = [np.log(p) for p in df[\"price\"]]\n",
        "df['log_retail_price'] = [np.log(p) for p in df[\"retail_price\"]]\n",
        "df[\"discount_ratio\"] = [df[\"price\"][i]/df[\"retail_price\"][i] for i in range(len(df[\"price\"]))]\n",
        "df['urgent'] = [1 if s == \"Quantité limitée !\" else 0 for s in df[\"urgency_text\"]]\n",
        "label = [1 if sales > 400 else 0 for sales in df[\"units_sold\"]]\n",
        "df['high_sale'] = label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5WVbBHkq8fQ"
      },
      "source": [
        "country = df[\"countries_shipped_to\"]\n",
        "normalized_country = (country-country.mean())/country.std()\n",
        "df[\"countries_shipped_to\"] = normalized_country"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2CRCmb-XTKE",
        "outputId": "a8af486c-1e24-400e-a746-48e6710e1af4"
      },
      "source": [
        "df = df[[\"doc2vec\", \"image_pixel\", \"log_price\", \"log_retail_price\", \"discount_ratio\", \"uses_ad_boosts\", \"badges_count\", \"badge_local_product\", \"badge_product_quality\", \"badge_fast_shipping\", \"shipping_option_price\", \"shipping_is_express\", \"countries_shipped_to\", \"inventory_total\", \"product_color_rgb\", \"urgent\", \"high_sale\"]]\n",
        "rgb = df[\"product_color_rgb\"]\n",
        "rgb = np.stack(rgb.values, axis=0)\n",
        "for i in range(3):\n",
        "  df[\"product_color_rgb\"+str(i)] = rgb[:,i]\n",
        "X = df[df.columns.difference([\"high_sale\", \"product_color_rgb\"])]\n",
        "y = df[\"high_sale\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgpP0STfmIUi",
        "outputId": "3c4f0608-1d41-43fa-a02a-650389aaf00d"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Split into 0.75:0.125:0.125\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.125, random_state=42)\n",
        "X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, test_size=0.14286, random_state=42)\n",
        "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
        "print (\"number of dev examples = \" + str(X_dev.shape[0]))\n",
        "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
        "print (\"X_train shape: \" + str(X_train.shape))\n",
        "print (\"Y_train shape: \" + str(y_train.shape))\n",
        "print (\"X_dev shape: \" + str(X_dev.shape))\n",
        "print (\"Y_dev shape: \" + str(y_dev.shape))\n",
        "print (\"X_test shape: \" + str(X_test.shape))\n",
        "print (\"Y_test shape: \" + str(y_test.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of training examples = 1179\n",
            "number of dev examples = 197\n",
            "number of test examples = 197\n",
            "X_train shape: (1179, 18)\n",
            "Y_train shape: (1179,)\n",
            "X_dev shape: (197, 18)\n",
            "Y_dev shape: (197,)\n",
            "X_test shape: (197, 18)\n",
            "Y_test shape: (197,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeSvWZI7nFJc"
      },
      "source": [
        "import tensorflow as tf\n",
        "def get_image_text_feature(df):\n",
        "  return np.stack(df[\"image_pixel\"].to_numpy(), axis=0), tf.expand_dims(np.stack(df[\"doc2vec\"].to_numpy(), axis=0), axis=-1), df[df.columns.difference([\"image_pixel\", \"doc2vec\"])]\n",
        "X_train_image, X_train_text, X_train_feature = get_image_text_feature(X_train)\n",
        "X_test_image, X_test_text, X_test_feature = get_image_text_feature(X_test)\n",
        "X_dev_image, X_dev_text, X_dev_feature = get_image_text_feature(X_dev)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "pHJrGHa2ny1r",
        "outputId": "76db2315-79b9-4fa0-f5ac-8d9267f3b6c1"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(max_depth=10, random_state=1)\n",
        "clf.fit(X_train_feature, y_train)\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "y_pred = clf.predict(X_test_feature)\n",
        "cf_mat = confusion_matrix(y_test, y_pred)\n",
        "import seaborn as sns\n",
        "sns.heatmap(cf_mat, annot=True, cmap='Blues')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4a100f4690>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73LTATyTiRG4"
      },
      "source": [
        "# doc2vec = np.stack(df['doc2vec'].values, axis=0)\n",
        "# data2 = pd.DataFrame()\n",
        "# for i in range(20):\n",
        "#     data[\"doc2vec\"+str(i)] = doc2vec[:,i]\n",
        "#     # data for only using titile text as input\n",
        "#     data2[\"doc2vec\"+str(i)] = doc2vec[:,i]\n",
        "# rgb = df[\"product_color_rgb\"]\n",
        "# rgb = np.stack(rgb.values, axis=0)\n",
        "# for i in range(4):\n",
        "#     data[\"product_color_rgb\"+str(i)] = rgb[:,i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuzPbZNBVgKG",
        "outputId": "1a23b5b9-28ba-42d6-d1df-541d040ec1f8"
      },
      "source": [
        "X_train_image.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1179, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87wbgpmTVhpf",
        "outputId": "8f083d88-80a4-4bbc-d6cb-77acb39d38e1"
      },
      "source": [
        "X_train_text.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1179, 50, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PsymHeBVxij"
      },
      "source": [
        "X_train_text = tf.expand_dims(X_train_text, axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8qqC41CVlAO",
        "outputId": "b9a44c9c-4425-4b39-e7db-e9ef53b48621"
      },
      "source": [
        "X_train_feature.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1179, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6A-70QWBNBb",
        "outputId": "673b5ab2-56c5-4f07-eca0-a19b86ddcac0"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os, shutil\n",
        "import cv2\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import string\n",
        "import re\n",
        "import nltk\n",
        "from keras import layers\n",
        "from keras import Input\n",
        "from keras.models import Model\n",
        "from keras import models\n",
        "import tensorflow as tf\n",
        "from keras.applications.vgg16 import VGG16\n",
        "vgg16_model = VGG16()\n",
        "\n",
        "image_input = Input(shape=(224, 224, 3), name='image')\n",
        "vgg16 = VGG16(weights='imagenet',\n",
        "                  include_top=False,\n",
        "                  input_shape=(224, 224, 3))(image_input)\n",
        "x = tf.keras.layers.Flatten()(vgg16)\n",
        "x = tf.keras.layers.Dropout(0.3)(x)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 7s 0us/step\n",
            "553476096/553467096 [==============================] - 7s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "58900480/58889256 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8IlQmlxzbNp"
      },
      "source": [
        "text_input = Input(shape=(50,1,), name='title')\n",
        "text = tf.keras.layers.Conv1D(filters=16, kernel_size=8, activation='relu')(text_input)\n",
        "text = tf.keras.layers.MaxPooling1D(pool_size=2)(text)\n",
        "text = tf.keras.layers.Dropout(0.1)(text)\n",
        "text = tf.keras.layers.Flatten()(text)\n",
        "text = tf.keras.layers.Dense(128, activation='relu')(text)\n",
        "feature_input = Input(shape=(16,), name='feature')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSn06-Zl1krg"
      },
      "source": [
        "concatenated = layers.concatenate([x, text, feature_input], axis=-1)\n",
        "concatenated = tf.keras.layers.Dense(64, activation='relu')(concatenated)\n",
        "concatenated = tf.keras.layers.Dense(32, activation='relu')(concatenated)\n",
        "output = layers.Dense(1, activation='sigmoid')(concatenated)\n",
        "model = Model([image_input, text_input, feature_input], output)\n",
        "# output = layers.Dense(1, activation='sigmoid')(x)\n",
        "# model = Model(image_input, output)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovnsj0rUzWzR"
      },
      "source": [
        "# image_model = tf.keras.models.Sequential()\n",
        "# for layer in vgg16_model.layers[:-1]:\n",
        "#     image_model.add(layer)  \n",
        "# # Freeze the layers \n",
        "# for layer in image_model.layers:\n",
        "#     layer.trainable = False\n",
        "# image_model.add(tf.keras.layers.Dropout(0.3))\n",
        "# # model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "# image_model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "# image_model.summary()\n",
        "# image_model.compile(optimizer='adam',\n",
        "#               loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "#               metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nd0whfEfZelk",
        "outputId": "802427d7-881d-437d-c901-6eaacbe034c1"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " title (InputLayer)             [(None, 50, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " image (InputLayer)             [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 43, 16)       144         ['title[0][0]']                  \n",
            "                                                                                                  \n",
            " vgg16 (Functional)             (None, 7, 7, 512)    14714688    ['image[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling1d (MaxPooling1D)   (None, 21, 16)       0           ['conv1d[0][0]']                 \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 25088)        0           ['vgg16[0][0]']                  \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 21, 16)       0           ['max_pooling1d[0][0]']          \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 25088)        0           ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 336)          0           ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          3211392     ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 128)          43136       ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            " feature (InputLayer)           [(None, 16)]         0           []                               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 272)          0           ['dense[0][0]',                  \n",
            "                                                                  'dense_1[0][0]',                \n",
            "                                                                  'feature[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 64)           17472       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 32)           2080        ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 1)            33          ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 17,988,945\n",
            "Trainable params: 17,988,945\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXG20hoFTuXz",
        "outputId": "f49c57ca-e237-41aa-8f9a-f03637dc2fa5"
      },
      "source": [
        "EPOCHS = 25\n",
        "\n",
        "history = model.fit(\n",
        "    [X_train_image, X_train_text, X_train_feature],\n",
        "    y_train,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=([X_dev_image, X_dev_text, X_dev_feature], y_dev))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "37/37 [==============================] - 68s 1s/step - loss: 5.3588 - acc: 0.5437 - val_loss: 0.6626 - val_acc: 0.6294\n",
            "Epoch 2/25\n",
            "37/37 [==============================] - 29s 793ms/step - loss: 0.6893 - acc: 0.5903 - val_loss: 0.6636 - val_acc: 0.6345\n",
            "Epoch 3/25\n",
            "37/37 [==============================] - 30s 824ms/step - loss: 0.6752 - acc: 0.5895 - val_loss: 0.6706 - val_acc: 0.5990\n",
            "Epoch 4/25\n",
            "37/37 [==============================] - 29s 791ms/step - loss: 0.6701 - acc: 0.5844 - val_loss: 0.6493 - val_acc: 0.6345\n",
            "Epoch 5/25\n",
            "37/37 [==============================] - 29s 788ms/step - loss: 0.6690 - acc: 0.5971 - val_loss: 0.6601 - val_acc: 0.5990\n",
            "Epoch 6/25\n",
            "37/37 [==============================] - 29s 787ms/step - loss: 0.6573 - acc: 0.6183 - val_loss: 0.6418 - val_acc: 0.6396\n",
            "Epoch 7/25\n",
            "37/37 [==============================] - 29s 790ms/step - loss: 0.6582 - acc: 0.6124 - val_loss: 0.6419 - val_acc: 0.6497\n",
            "Epoch 8/25\n",
            "37/37 [==============================] - 29s 793ms/step - loss: 0.6512 - acc: 0.6183 - val_loss: 0.6482 - val_acc: 0.6345\n",
            "Epoch 9/25\n",
            "37/37 [==============================] - 29s 793ms/step - loss: 0.6429 - acc: 0.6438 - val_loss: 0.6542 - val_acc: 0.6193\n",
            "Epoch 10/25\n",
            "37/37 [==============================] - 29s 792ms/step - loss: 0.6407 - acc: 0.6344 - val_loss: 0.6540 - val_acc: 0.6041\n",
            "Epoch 11/25\n",
            "37/37 [==============================] - 29s 790ms/step - loss: 0.6405 - acc: 0.6302 - val_loss: 0.6509 - val_acc: 0.6244\n",
            "Epoch 12/25\n",
            "37/37 [==============================] - 29s 788ms/step - loss: 0.6349 - acc: 0.6302 - val_loss: 0.6417 - val_acc: 0.6294\n",
            "Epoch 13/25\n",
            "37/37 [==============================] - 29s 785ms/step - loss: 0.6310 - acc: 0.6429 - val_loss: 0.6737 - val_acc: 0.5685\n",
            "Epoch 14/25\n",
            "37/37 [==============================] - 29s 791ms/step - loss: 0.6236 - acc: 0.6641 - val_loss: 0.6649 - val_acc: 0.5787\n",
            "Epoch 15/25\n",
            "37/37 [==============================] - 30s 819ms/step - loss: 0.6282 - acc: 0.6421 - val_loss: 0.6448 - val_acc: 0.6447\n",
            "Epoch 16/25\n",
            "37/37 [==============================] - 29s 788ms/step - loss: 0.6319 - acc: 0.6497 - val_loss: 0.6424 - val_acc: 0.6142\n",
            "Epoch 17/25\n",
            "37/37 [==============================] - 29s 790ms/step - loss: 0.6100 - acc: 0.6675 - val_loss: 0.6653 - val_acc: 0.5838\n",
            "Epoch 18/25\n",
            "37/37 [==============================] - 29s 788ms/step - loss: 0.6118 - acc: 0.6531 - val_loss: 0.6465 - val_acc: 0.5888\n",
            "Epoch 19/25\n",
            "37/37 [==============================] - 29s 788ms/step - loss: 0.6203 - acc: 0.6548 - val_loss: 0.6453 - val_acc: 0.6091\n",
            "Epoch 20/25\n",
            "37/37 [==============================] - 29s 794ms/step - loss: 1.2999 - acc: 0.6293 - val_loss: 0.6866 - val_acc: 0.5685\n",
            "Epoch 21/25\n",
            "37/37 [==============================] - 29s 793ms/step - loss: 0.6090 - acc: 0.6675 - val_loss: 0.6820 - val_acc: 0.5787\n",
            "Epoch 22/25\n",
            "37/37 [==============================] - 29s 792ms/step - loss: 0.5935 - acc: 0.6794 - val_loss: 1.2973 - val_acc: 0.3655\n",
            "Epoch 23/25\n",
            "37/37 [==============================] - 29s 792ms/step - loss: 0.6576 - acc: 0.6412 - val_loss: 0.6544 - val_acc: 0.6142\n",
            "Epoch 24/25\n",
            "37/37 [==============================] - 29s 791ms/step - loss: 0.5921 - acc: 0.6718 - val_loss: 0.6603 - val_acc: 0.5685\n",
            "Epoch 25/25\n",
            "37/37 [==============================] - 29s 782ms/step - loss: 0.5879 - acc: 0.6836 - val_loss: 0.6563 - val_acc: 0.6091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sh8C20jkrARC",
        "outputId": "228e4209-4610-4967-b137-26e04d6e927f"
      },
      "source": [
        "history = model.fit(\n",
        "    [X_train_image, X_train_text, X_train_feature],\n",
        "    y_train,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=([X_dev_image, X_dev_text, X_dev_feature], y_dev))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "37/37 [==============================] - 29s 776ms/step - loss: 0.6578 - acc: 0.6175 - val_loss: 0.6624 - val_acc: 0.6142\n",
            "Epoch 2/25\n",
            "37/37 [==============================] - 29s 776ms/step - loss: 0.6574 - acc: 0.6200 - val_loss: 0.6600 - val_acc: 0.6244\n",
            "Epoch 3/25\n",
            "37/37 [==============================] - 29s 779ms/step - loss: 0.6583 - acc: 0.6098 - val_loss: 0.6600 - val_acc: 0.6345\n",
            "Epoch 4/25\n",
            "37/37 [==============================] - 29s 777ms/step - loss: 0.6586 - acc: 0.6081 - val_loss: 0.6652 - val_acc: 0.6041\n",
            "Epoch 5/25\n",
            "37/37 [==============================] - 29s 780ms/step - loss: 0.6566 - acc: 0.6098 - val_loss: 0.6688 - val_acc: 0.5939\n",
            "Epoch 6/25\n",
            "37/37 [==============================] - 29s 781ms/step - loss: 0.6570 - acc: 0.6209 - val_loss: 0.6587 - val_acc: 0.6244\n",
            "Epoch 7/25\n",
            "37/37 [==============================] - 29s 780ms/step - loss: 0.6563 - acc: 0.6141 - val_loss: 0.6647 - val_acc: 0.5990\n",
            "Epoch 8/25\n",
            "37/37 [==============================] - 29s 777ms/step - loss: 0.6563 - acc: 0.6158 - val_loss: 0.6662 - val_acc: 0.5888\n",
            "Epoch 9/25\n",
            "37/37 [==============================] - 29s 781ms/step - loss: 0.6551 - acc: 0.6200 - val_loss: 0.6610 - val_acc: 0.6396\n",
            "Epoch 10/25\n",
            "37/37 [==============================] - 29s 782ms/step - loss: 0.6581 - acc: 0.6090 - val_loss: 0.6789 - val_acc: 0.5685\n",
            "Epoch 11/25\n",
            "37/37 [==============================] - 29s 784ms/step - loss: 0.6581 - acc: 0.6039 - val_loss: 0.6598 - val_acc: 0.6345\n",
            "Epoch 12/25\n",
            "37/37 [==============================] - 29s 777ms/step - loss: 0.6540 - acc: 0.6234 - val_loss: 0.6697 - val_acc: 0.6041\n",
            "Epoch 13/25\n",
            "37/37 [==============================] - 29s 779ms/step - loss: 0.6594 - acc: 0.6031 - val_loss: 0.6610 - val_acc: 0.6244\n",
            "Epoch 14/25\n",
            "37/37 [==============================] - 29s 780ms/step - loss: 0.6559 - acc: 0.6260 - val_loss: 0.6638 - val_acc: 0.5939\n",
            "Epoch 15/25\n",
            "37/37 [==============================] - 29s 779ms/step - loss: 0.6550 - acc: 0.6098 - val_loss: 0.6762 - val_acc: 0.5990\n",
            "Epoch 16/25\n",
            "37/37 [==============================] - 29s 776ms/step - loss: 0.6562 - acc: 0.6158 - val_loss: 0.6635 - val_acc: 0.5939\n",
            "Epoch 17/25\n",
            "37/37 [==============================] - 29s 780ms/step - loss: 0.6545 - acc: 0.6277 - val_loss: 0.6589 - val_acc: 0.6396\n",
            "Epoch 18/25\n",
            "37/37 [==============================] - 29s 780ms/step - loss: 0.6536 - acc: 0.6226 - val_loss: 0.6624 - val_acc: 0.5990\n",
            "Epoch 19/25\n",
            "37/37 [==============================] - 29s 779ms/step - loss: 0.6545 - acc: 0.6370 - val_loss: 0.6592 - val_acc: 0.6294\n",
            "Epoch 20/25\n",
            "37/37 [==============================] - 29s 778ms/step - loss: 0.6534 - acc: 0.6234 - val_loss: 0.6638 - val_acc: 0.5888\n",
            "Epoch 21/25\n",
            "37/37 [==============================] - 29s 779ms/step - loss: 0.6530 - acc: 0.6327 - val_loss: 0.6571 - val_acc: 0.6396\n",
            "Epoch 22/25\n",
            "37/37 [==============================] - 29s 780ms/step - loss: 0.6525 - acc: 0.6200 - val_loss: 0.6676 - val_acc: 0.6142\n",
            "Epoch 23/25\n",
            "37/37 [==============================] - 29s 779ms/step - loss: 0.6522 - acc: 0.6302 - val_loss: 0.6594 - val_acc: 0.6142\n",
            "Epoch 24/25\n",
            "37/37 [==============================] - 29s 777ms/step - loss: 0.6524 - acc: 0.6302 - val_loss: 0.6608 - val_acc: 0.6091\n",
            "Epoch 25/25\n",
            "37/37 [==============================] - 29s 779ms/step - loss: 0.6529 - acc: 0.6200 - val_loss: 0.6623 - val_acc: 0.5888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "q77KoNieBTNB",
        "outputId": "452b126a-0399-4fe0-cd3e-8f3badc7177c"
      },
      "source": [
        "EPOCHS = 25\n",
        "# early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "#     monitor='val_accuracy',\n",
        "#     mode='max',\n",
        "#     patience=6\n",
        "# )\n",
        "\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(X_dev, y_dev),\n",
        ")\n",
        "\n",
        "# history = model.fit_generator(\n",
        "#     train_generator,\n",
        "#     steps_per_epoch=50,\n",
        "#     epochs=EPOCHS,\n",
        "#     validation_data=validation_generator,\n",
        "#     validation_steps=25,\n",
        "#     callbacks=[early_stopping]\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-5fc82a6b3246>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type int)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iWJH02ZZ3lR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}