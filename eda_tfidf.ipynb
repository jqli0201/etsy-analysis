{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f4161c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "#load inthe NTLK stopwords to remove articles, preposition and other words that are not actionable\n",
    "from nltk.corpus import stopwords\n",
    "# This allows to create individual objects from a bog of words\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "# Lemmatizer helps to reduce words to the base form\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5135cd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('eda_np.txt', sep=\"\\t\", header=0)\n",
    "df_orig=pd.read_csv('summer-products-with-rating-and-performance_2020-08.csv')\n",
    "# dev=pd.read_csv('np_dev.txt', sep=\"\\t\", header=0)\n",
    "# test=pd.read_csv('np_test.txt', sep=\"\\t\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e1873774",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [1 if sales > 100 else 0 for sales in df_orig[\"units_sold\"]]\n",
    "df_orig['high_sale'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6ac91e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15730, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "87d31617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/jasmineli/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jasmineli/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/jasmineli/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "652bf3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sentence(sentence):\n",
    "    new_tokens = word_tokenize(sentence)\n",
    "    new_tokens = [t.lower() for t in new_tokens]\n",
    "    new_tokens =[t for t in new_tokens if t not in stopwords.words('english')]\n",
    "    new_tokens = [t for t in new_tokens if t.isalpha()]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    new_tokens =[lemmatizer.lemmatize(t) for t in new_tokens]\n",
    "    return \" \".join(new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9c432648",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = df['title_orig'].tolist()\n",
    "tokens = [process_sentence(t) for t in titles]\n",
    "df['title_orig'] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4ec0af5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(df['title_orig'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5278e064",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasmineli/opt/anaconda3/envs/etsy/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "tfidf = pd.DataFrame(denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7ccdfd52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abbreviate</th>\n",
       "      <th>abbreviated</th>\n",
       "      <th>abruptly</th>\n",
       "      <th>absorbent</th>\n",
       "      <th>absorbing</th>\n",
       "      <th>accessory</th>\n",
       "      <th>accouterment</th>\n",
       "      <th>ace</th>\n",
       "      <th>acid</th>\n",
       "      <th>acme</th>\n",
       "      <th>...</th>\n",
       "      <th>zane</th>\n",
       "      <th>zanzea</th>\n",
       "      <th>zapatillas</th>\n",
       "      <th>zapatos</th>\n",
       "      <th>zapper</th>\n",
       "      <th>zen</th>\n",
       "      <th>zip</th>\n",
       "      <th>ziper</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15725</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15726</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15727</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15728</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15729</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15730 rows × 2387 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       abbreviate  abbreviated  abruptly  absorbent  absorbing  accessory  \\\n",
       "0             0.0          0.0       0.0        0.0        0.0        0.0   \n",
       "1             0.0          0.0       0.0        0.0        0.0        0.0   \n",
       "2             0.0          0.0       0.0        0.0        0.0        0.0   \n",
       "3             0.0          0.0       0.0        0.0        0.0        0.0   \n",
       "4             0.0          0.0       0.0        0.0        0.0        0.0   \n",
       "...           ...          ...       ...        ...        ...        ...   \n",
       "15725         0.0          0.0       0.0        0.0        0.0        0.0   \n",
       "15726         0.0          0.0       0.0        0.0        0.0        0.0   \n",
       "15727         0.0          0.0       0.0        0.0        0.0        0.0   \n",
       "15728         0.0          0.0       0.0        0.0        0.0        0.0   \n",
       "15729         0.0          0.0       0.0        0.0        0.0        0.0   \n",
       "\n",
       "       accouterment  ace  acid  acme  ...  zane  zanzea  zapatillas  zapatos  \\\n",
       "0               0.0  0.0   0.0   0.0  ...   0.0     0.0         0.0      0.0   \n",
       "1               0.0  0.0   0.0   0.0  ...   0.0     0.0         0.0      0.0   \n",
       "2               0.0  0.0   0.0   0.0  ...   0.0     0.0         0.0      0.0   \n",
       "3               0.0  0.0   0.0   0.0  ...   0.0     0.0         0.0      0.0   \n",
       "4               0.0  0.0   0.0   0.0  ...   0.0     0.0         0.0      0.0   \n",
       "...             ...  ...   ...   ...  ...   ...     ...         ...      ...   \n",
       "15725           0.0  0.0   0.0   0.0  ...   0.0     0.0         0.0      0.0   \n",
       "15726           0.0  0.0   0.0   0.0  ...   0.0     0.0         0.0      0.0   \n",
       "15727           0.0  0.0   0.0   0.0  ...   0.0     0.0         0.0      0.0   \n",
       "15728           0.0  0.0   0.0   0.0  ...   0.0     0.0         0.0      0.0   \n",
       "15729           0.0  0.0   0.0   0.0  ...   0.0     0.0         0.0      0.0   \n",
       "\n",
       "       zapper  zen  zip  ziper  zipper   zm  \n",
       "0         0.0  0.0  0.0    0.0     0.0  0.0  \n",
       "1         0.0  0.0  0.0    0.0     0.0  0.0  \n",
       "2         0.0  0.0  0.0    0.0     0.0  0.0  \n",
       "3         0.0  0.0  0.0    0.0     0.0  0.0  \n",
       "4         0.0  0.0  0.0    0.0     0.0  0.0  \n",
       "...       ...  ...  ...    ...     ...  ...  \n",
       "15725     0.0  0.0  0.0    0.0     0.0  0.0  \n",
       "15726     0.0  0.0  0.0    0.0     0.0  0.0  \n",
       "15727     0.0  0.0  0.0    0.0     0.0  0.0  \n",
       "15728     0.0  0.0  0.0    0.0     0.0  0.0  \n",
       "15729     0.0  0.0  0.0    0.0     0.0  0.0  \n",
       "\n",
       "[15730 rows x 2387 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1e8dfea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf\n",
    "y = df['high_sale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f30f1879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abbreviate</th>\n",
       "      <th>abbreviated</th>\n",
       "      <th>abruptly</th>\n",
       "      <th>absorbent</th>\n",
       "      <th>absorbing</th>\n",
       "      <th>accessory</th>\n",
       "      <th>accouterment</th>\n",
       "      <th>ace</th>\n",
       "      <th>acid</th>\n",
       "      <th>acme</th>\n",
       "      <th>...</th>\n",
       "      <th>zane</th>\n",
       "      <th>zanzea</th>\n",
       "      <th>zapatillas</th>\n",
       "      <th>zapatos</th>\n",
       "      <th>zapper</th>\n",
       "      <th>zen</th>\n",
       "      <th>zip</th>\n",
       "      <th>ziper</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15725</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15726</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15727</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15728</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15729</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15730 rows × 2387 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       abbreviate  abbreviated  abruptly  absorbent  absorbing  accessory  \\\n",
       "0             0.0          0.0       0.0        0.0        0.0        0.0   \n",
       "1             0.0          0.0       0.0        0.0        0.0        0.0   \n",
       "2             0.0          0.0       0.0        0.0        0.0        0.0   \n",
       "3             0.0          0.0       0.0        0.0        0.0        0.0   \n",
       "4             0.0          0.0       0.0        0.0        0.0        0.0   \n",
       "...           ...          ...       ...        ...        ...        ...   \n",
       "15725         0.0          0.0       0.0        0.0        0.0        0.0   \n",
       "15726         0.0          0.0       0.0        0.0        0.0        0.0   \n",
       "15727         0.0          0.0       0.0        0.0        0.0        0.0   \n",
       "15728         0.0          0.0       0.0        0.0        0.0        0.0   \n",
       "15729         0.0          0.0       0.0        0.0        0.0        0.0   \n",
       "\n",
       "       accouterment  ace  acid  acme  ...  zane  zanzea  zapatillas  zapatos  \\\n",
       "0               0.0  0.0   0.0   0.0  ...   0.0     0.0         0.0      0.0   \n",
       "1               0.0  0.0   0.0   0.0  ...   0.0     0.0         0.0      0.0   \n",
       "2               0.0  0.0   0.0   0.0  ...   0.0     0.0         0.0      0.0   \n",
       "3               0.0  0.0   0.0   0.0  ...   0.0     0.0         0.0      0.0   \n",
       "4               0.0  0.0   0.0   0.0  ...   0.0     0.0         0.0      0.0   \n",
       "...             ...  ...   ...   ...  ...   ...     ...         ...      ...   \n",
       "15725           0.0  0.0   0.0   0.0  ...   0.0     0.0         0.0      0.0   \n",
       "15726           0.0  0.0   0.0   0.0  ...   0.0     0.0         0.0      0.0   \n",
       "15727           0.0  0.0   0.0   0.0  ...   0.0     0.0         0.0      0.0   \n",
       "15728           0.0  0.0   0.0   0.0  ...   0.0     0.0         0.0      0.0   \n",
       "15729           0.0  0.0   0.0   0.0  ...   0.0     0.0         0.0      0.0   \n",
       "\n",
       "       zapper  zen  zip  ziper  zipper   zm  \n",
       "0         0.0  0.0  0.0    0.0     0.0  0.0  \n",
       "1         0.0  0.0  0.0    0.0     0.0  0.0  \n",
       "2         0.0  0.0  0.0    0.0     0.0  0.0  \n",
       "3         0.0  0.0  0.0    0.0     0.0  0.0  \n",
       "4         0.0  0.0  0.0    0.0     0.0  0.0  \n",
       "...       ...  ...  ...    ...     ...  ...  \n",
       "15725     0.0  0.0  0.0    0.0     0.0  0.0  \n",
       "15726     0.0  0.0  0.0    0.0     0.0  0.0  \n",
       "15727     0.0  0.0  0.0    0.0     0.0  0.0  \n",
       "15728     0.0  0.0  0.0    0.0     0.0  0.0  \n",
       "15729     0.0  0.0  0.0    0.0     0.0  0.0  \n",
       "\n",
       "[15730 rows x 2387 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "80b8b544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.125, random_state=42)\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "66487bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_dev = pd.DataFrame(X_dev)\n",
    "# vectors = vectorizer.fit_transform(X_dev['title_orig'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "4c2994d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasmineli/opt/anaconda3/envs/etsy/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "tfidf_dev = pd.DataFrame(denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "81836179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abbreviated</th>\n",
       "      <th>abruptly</th>\n",
       "      <th>absorbent</th>\n",
       "      <th>absorbing</th>\n",
       "      <th>accessory</th>\n",
       "      <th>acrobatic</th>\n",
       "      <th>across</th>\n",
       "      <th>active</th>\n",
       "      <th>activewear</th>\n",
       "      <th>activity</th>\n",
       "      <th>...</th>\n",
       "      <th>youll</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>zanzea</th>\n",
       "      <th>zapatillas</th>\n",
       "      <th>zapatos</th>\n",
       "      <th>zapper</th>\n",
       "      <th>ziper</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2749</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2750</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2751</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2752</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2753 rows × 1575 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      abbreviated  abruptly  absorbent  absorbing  accessory  acrobatic  \\\n",
       "0             0.0       0.0        0.0        0.0        0.0        0.0   \n",
       "1             0.0       0.0        0.0        0.0        0.0        0.0   \n",
       "2             0.0       0.0        0.0        0.0        0.0        0.0   \n",
       "3             0.0       0.0        0.0        0.0        0.0        0.0   \n",
       "4             0.0       0.0        0.0        0.0        0.0        0.0   \n",
       "...           ...       ...        ...        ...        ...        ...   \n",
       "2748          0.0       0.0        0.0        0.0        0.0        0.0   \n",
       "2749          0.0       0.0        0.0        0.0        0.0        0.0   \n",
       "2750          0.0       0.0        0.0        0.0        0.0        0.0   \n",
       "2751          0.0       0.0        0.0        0.0        0.0        0.0   \n",
       "2752          0.0       0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "      across  active  activewear  activity  ...  youll  young  youth  zanzea  \\\n",
       "0        0.0     0.0         0.0       0.0  ...    0.0    0.0    0.0     0.0   \n",
       "1        0.0     0.0         0.0       0.0  ...    0.0    0.0    0.0     0.0   \n",
       "2        0.0     0.0         0.0       0.0  ...    0.0    0.0    0.0     0.0   \n",
       "3        0.0     0.0         0.0       0.0  ...    0.0    0.0    0.0     0.0   \n",
       "4        0.0     0.0         0.0       0.0  ...    0.0    0.0    0.0     0.0   \n",
       "...      ...     ...         ...       ...  ...    ...    ...    ...     ...   \n",
       "2748     0.0     0.0         0.0       0.0  ...    0.0    0.0    0.0     0.0   \n",
       "2749     0.0     0.0         0.0       0.0  ...    0.0    0.0    0.0     0.0   \n",
       "2750     0.0     0.0         0.0       0.0  ...    0.0    0.0    0.0     0.0   \n",
       "2751     0.0     0.0         0.0       0.0  ...    0.0    0.0    0.0     0.0   \n",
       "2752     0.0     0.0         0.0       0.0  ...    0.0    0.0    0.0     0.0   \n",
       "\n",
       "      zapatillas  zapatos  zapper  ziper  zipper   zm  \n",
       "0            0.0      0.0     0.0    0.0     0.0  0.0  \n",
       "1            0.0      0.0     0.0    0.0     0.0  0.0  \n",
       "2            0.0      0.0     0.0    0.0     0.0  0.0  \n",
       "3            0.0      0.0     0.0    0.0     0.0  0.0  \n",
       "4            0.0      0.0     0.0    0.0     0.0  0.0  \n",
       "...          ...      ...     ...    ...     ...  ...  \n",
       "2748         0.0      0.0     0.0    0.0     0.0  0.0  \n",
       "2749         0.0      0.0     0.0    0.0     0.0  0.0  \n",
       "2750         0.0      0.0     0.0    0.0     0.0  0.0  \n",
       "2751         0.0      0.0     0.0    0.0     0.0  0.0  \n",
       "2752         0.0      0.0     0.0    0.0     0.0  0.0  \n",
       "\n",
       "[2753 rows x 1575 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c3eed93f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'title_orig'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/etsy/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/etsy/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/etsy/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'title_orig'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gp/m_sr4f9x1wlcvt5v7g8kfy2r0000gn/T/ipykernel_9326/2272994115.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_dev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title_orig'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/etsy/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/etsy/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'title_orig'"
     ]
    }
   ],
   "source": [
    "X_dev['title_orig']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4b5d2f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        summer vintage flamingo print pajama set every...\n",
       "1        summer vintage flamingo print pajama set casua...\n",
       "2        summer vintage flamingo print pajama set casua...\n",
       "3        summer vintage flamingo print pajama short cas...\n",
       "4        summer vintage flamingo print pajama set casua...\n",
       "                               ...                        \n",
       "15725    fashion woman yoga pant slim fit physical fitn...\n",
       "15726    fashion woman yoga pant slim fit fitness runni...\n",
       "15727    fashion woman fitness pant slim fit yoga runni...\n",
       "15728                fashion yoga slim fit running legging\n",
       "15729    fashion woman yoga pant slim fit fitness runni...\n",
       "Name: title_orig, Length: 15730, dtype: object"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title_orig']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "dc8d2c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title_orig'].to_csv('testtest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7585c0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 11010\n",
      "number of dev examples = 2753\n",
      "number of test examples = 1967\n",
      "X_train shape: (11010, 1)\n",
      "Y_train shape: (11010,)\n",
      "X_dev shape: (2753, 1)\n",
      "Y_dev shape: (2753,)\n",
      "X_test shape: (1967, 1)\n",
      "Y_test shape: (1967,)\n"
     ]
    }
   ],
   "source": [
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of dev examples = \" + str(X_dev.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(y_train.shape))\n",
    "print (\"X_dev shape: \" + str(X_dev.shape))\n",
    "print (\"Y_dev shape: \" + str(y_dev.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ea28eb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from keras.layers import Input, Dense, Concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization, GlobalMaxPooling1D\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# X_train, X_test, X_dev, y_train, y_test, y_dev= X, test['title_orig'], dev['title_orig'], y, test['high_sale'], dev['high_sale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914de41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# titles = dev['title_orig'].tolist()\n",
    "# tokens = [process_sentence(t) for t in titles]\n",
    "# dev['title_pre'] = tokens\n",
    "# vectorizer = TfidfVectorizer()\n",
    "# vectors = vectorizer.fit_transform(dev['title_pre'])\n",
    "# feature_names = vectorizer.get_feature_names()\n",
    "# dense = vectors.todense()\n",
    "# denselist = dense.tolist()\n",
    "# tfidf = pd.DataFrame(denselist, columns=feature_names)\n",
    "# X_dev = tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bfd3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "# print (\"number of dev examples = \" + str(X_dev.shape[0]))\n",
    "# print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "# print (\"X_train shape: \" + str(X_train.shape))\n",
    "# print (\"Y_train shape: \" + str(y_train.shape))\n",
    "# print (\"X_dev shape: \" + str(X_dev.shape))\n",
    "# print (\"Y_dev shape: \" + str(y_dev.shape))\n",
    "# print (\"X_test shape: \" + str(X_test.shape))\n",
    "# print (\"Y_test shape: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41bce21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284980b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f01eb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0a5eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the metrics class\n",
    "from sklearn import metrics\n",
    "cnf_matrix = metrics.confusion_matrix(y_dev, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb42b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728a28ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=[0,1] # name  of classes\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a4aeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "12a95d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-28 02:14:43.791924: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "X_train  = tf.expand_dims(X_train, axis=-1)\n",
    "y_train = tf.expand_dims(y_train, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "3e629157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "# model.add(Dense(128, activation='relu', kernel_regularizer='l1'))\n",
    "# model.add(Dense(32, activation='relu', kernel_regularizer='l2'))\n",
    "model.add(Conv1D(filters=128, kernel_size=12, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(512, activation='relu', kernel_regularizer='l2', kernel_initializer='uniform'))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(64, activation='relu', kernel_initializer='uniform'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "341dc1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=3e-4)\n",
    "model.compile(optimizer=opt,\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=2, patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "08f45b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasmineli/opt/anaconda3/envs/etsy/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173/173 - 65s - loss: 101.1293 - accuracy: 0.6559 - val_loss: 12.0767 - val_accuracy: 0.5812 - 65s/epoch - 374ms/step\n",
      "Epoch 2/100\n",
      "173/173 - 66s - loss: 4.1390 - accuracy: 0.7203 - val_loss: 1.7384 - val_accuracy: 0.6477 - 66s/epoch - 381ms/step\n",
      "Epoch 3/100\n",
      "173/173 - 66s - loss: 1.4651 - accuracy: 0.7246 - val_loss: 1.4271 - val_accuracy: 0.6843 - 66s/epoch - 380ms/step\n",
      "Epoch 4/100\n",
      "173/173 - 65s - loss: 1.3548 - accuracy: 0.7422 - val_loss: 1.3051 - val_accuracy: 0.7465 - 65s/epoch - 375ms/step\n",
      "Epoch 5/100\n",
      "173/173 - 65s - loss: 1.3444 - accuracy: 0.7485 - val_loss: 1.2612 - val_accuracy: 0.7984 - 65s/epoch - 377ms/step\n",
      "Epoch 6/100\n",
      "173/173 - 65s - loss: 1.3338 - accuracy: 0.7559 - val_loss: 1.2738 - val_accuracy: 0.7824 - 65s/epoch - 377ms/step\n",
      "Epoch 7/100\n",
      "173/173 - 65s - loss: 1.3025 - accuracy: 0.7661 - val_loss: 1.2441 - val_accuracy: 0.8111 - 65s/epoch - 376ms/step\n",
      "Epoch 8/100\n",
      "173/173 - 67s - loss: 1.3261 - accuracy: 0.7719 - val_loss: 1.1931 - val_accuracy: 0.8144 - 67s/epoch - 386ms/step\n",
      "Epoch 9/100\n",
      "173/173 - 66s - loss: 1.2963 - accuracy: 0.7815 - val_loss: 1.2350 - val_accuracy: 0.8206 - 66s/epoch - 383ms/step\n",
      "Epoch 10/100\n",
      "173/173 - 66s - loss: 1.2463 - accuracy: 0.7874 - val_loss: 1.1458 - val_accuracy: 0.8275 - 66s/epoch - 382ms/step\n",
      "Epoch 11/100\n",
      "173/173 - 67s - loss: 1.2288 - accuracy: 0.7916 - val_loss: 1.1256 - val_accuracy: 0.8344 - 67s/epoch - 386ms/step\n",
      "Epoch 12/100\n",
      "173/173 - 63s - loss: 1.1832 - accuracy: 0.7997 - val_loss: 1.1155 - val_accuracy: 0.8529 - 63s/epoch - 365ms/step\n",
      "Epoch 13/100\n",
      "173/173 - 61s - loss: 1.1702 - accuracy: 0.8039 - val_loss: 1.0889 - val_accuracy: 0.8507 - 61s/epoch - 350ms/step\n",
      "Epoch 14/100\n",
      "173/173 - 60s - loss: 1.1608 - accuracy: 0.8008 - val_loss: 1.0699 - val_accuracy: 0.8554 - 60s/epoch - 349ms/step\n",
      "Epoch 15/100\n",
      "173/173 - 62s - loss: 1.1517 - accuracy: 0.8093 - val_loss: 1.0819 - val_accuracy: 0.8605 - 62s/epoch - 357ms/step\n",
      "Epoch 16/100\n",
      "173/173 - 61s - loss: 1.1526 - accuracy: 0.8134 - val_loss: 1.0454 - val_accuracy: 0.8721 - 61s/epoch - 352ms/step\n",
      "Epoch 17/100\n",
      "173/173 - 60s - loss: 1.1125 - accuracy: 0.8128 - val_loss: 0.9887 - val_accuracy: 0.8638 - 60s/epoch - 349ms/step\n",
      "Epoch 18/100\n",
      "173/173 - 121s - loss: 1.1034 - accuracy: 0.8138 - val_loss: 0.9991 - val_accuracy: 0.8754 - 121s/epoch - 702ms/step\n",
      "Epoch 19/100\n",
      "173/173 - 69s - loss: 1.0993 - accuracy: 0.8155 - val_loss: 0.9712 - val_accuracy: 0.8790 - 69s/epoch - 402ms/step\n",
      "Epoch 20/100\n",
      "173/173 - 67s - loss: 1.0578 - accuracy: 0.8268 - val_loss: 0.9662 - val_accuracy: 0.8736 - 67s/epoch - 387ms/step\n",
      "Epoch 21/100\n",
      "173/173 - 68s - loss: 1.0468 - accuracy: 0.8296 - val_loss: 0.9251 - val_accuracy: 0.8881 - 68s/epoch - 391ms/step\n",
      "Epoch 22/100\n",
      "173/173 - 68s - loss: 1.0434 - accuracy: 0.8252 - val_loss: 0.9277 - val_accuracy: 0.8867 - 68s/epoch - 394ms/step\n",
      "Epoch 23/100\n",
      "173/173 - 68s - loss: 1.0315 - accuracy: 0.8292 - val_loss: 0.9162 - val_accuracy: 0.8881 - 68s/epoch - 395ms/step\n",
      "Epoch 24/100\n",
      "173/173 - 69s - loss: 1.0605 - accuracy: 0.8247 - val_loss: 0.9366 - val_accuracy: 0.8838 - 69s/epoch - 400ms/step\n",
      "Epoch 25/100\n",
      "173/173 - 69s - loss: 1.0160 - accuracy: 0.8351 - val_loss: 0.9157 - val_accuracy: 0.8939 - 69s/epoch - 397ms/step\n",
      "Epoch 26/100\n",
      "173/173 - 68s - loss: 1.0250 - accuracy: 0.8378 - val_loss: 0.9385 - val_accuracy: 0.8827 - 68s/epoch - 394ms/step\n",
      "Epoch 27/100\n",
      "173/173 - 70s - loss: 1.0121 - accuracy: 0.8344 - val_loss: 0.9149 - val_accuracy: 0.8925 - 70s/epoch - 402ms/step\n",
      "Epoch 28/100\n",
      "173/173 - 69s - loss: 1.0122 - accuracy: 0.8402 - val_loss: 0.9313 - val_accuracy: 0.8830 - 69s/epoch - 400ms/step\n",
      "Epoch 29/100\n",
      "173/173 - 67s - loss: 0.9770 - accuracy: 0.8446 - val_loss: 0.8794 - val_accuracy: 0.8885 - 67s/epoch - 390ms/step\n",
      "Epoch 30/100\n",
      "173/173 - 61s - loss: 0.9974 - accuracy: 0.8391 - val_loss: 0.8967 - val_accuracy: 0.8932 - 61s/epoch - 353ms/step\n",
      "Epoch 31/100\n",
      "173/173 - 63s - loss: 0.9794 - accuracy: 0.8426 - val_loss: 0.8992 - val_accuracy: 0.9005 - 63s/epoch - 365ms/step\n",
      "Epoch 32/100\n",
      "173/173 - 63s - loss: 0.9824 - accuracy: 0.8376 - val_loss: 0.8881 - val_accuracy: 0.8958 - 63s/epoch - 361ms/step\n",
      "Epoch 33/100\n",
      "173/173 - 62s - loss: 0.9735 - accuracy: 0.8452 - val_loss: 0.8607 - val_accuracy: 0.8958 - 62s/epoch - 358ms/step\n",
      "Epoch 34/100\n",
      "173/173 - 62s - loss: 0.9706 - accuracy: 0.8416 - val_loss: 0.8424 - val_accuracy: 0.8972 - 62s/epoch - 358ms/step\n",
      "Epoch 35/100\n",
      "173/173 - 62s - loss: 0.9440 - accuracy: 0.8451 - val_loss: 0.8407 - val_accuracy: 0.9001 - 62s/epoch - 356ms/step\n",
      "Epoch 36/100\n",
      "173/173 - 64s - loss: 0.9587 - accuracy: 0.8440 - val_loss: 0.8741 - val_accuracy: 0.8950 - 64s/epoch - 372ms/step\n",
      "Epoch 37/100\n",
      "173/173 - 62s - loss: 0.9664 - accuracy: 0.8433 - val_loss: 0.8523 - val_accuracy: 0.8968 - 62s/epoch - 355ms/step\n",
      "Epoch 38/100\n",
      "173/173 - 61s - loss: 0.9289 - accuracy: 0.8448 - val_loss: 0.8223 - val_accuracy: 0.9037 - 61s/epoch - 352ms/step\n",
      "Epoch 39/100\n",
      "173/173 - 61s - loss: 0.9102 - accuracy: 0.8550 - val_loss: 0.8239 - val_accuracy: 0.8987 - 61s/epoch - 352ms/step\n",
      "Epoch 40/100\n",
      "173/173 - 61s - loss: 0.9565 - accuracy: 0.8448 - val_loss: 0.8497 - val_accuracy: 0.9008 - 61s/epoch - 354ms/step\n",
      "Epoch 41/100\n",
      "173/173 - 61s - loss: 0.9345 - accuracy: 0.8505 - val_loss: 0.8518 - val_accuracy: 0.9016 - 61s/epoch - 355ms/step\n",
      "Epoch 42/100\n",
      "173/173 - 61s - loss: 0.9331 - accuracy: 0.8528 - val_loss: 0.8200 - val_accuracy: 0.9066 - 61s/epoch - 353ms/step\n",
      "Epoch 43/100\n",
      "173/173 - 60s - loss: 0.9251 - accuracy: 0.8508 - val_loss: 0.8018 - val_accuracy: 0.9045 - 60s/epoch - 346ms/step\n",
      "Epoch 44/100\n",
      "173/173 - 62s - loss: 0.9068 - accuracy: 0.8532 - val_loss: 0.7929 - val_accuracy: 0.9016 - 62s/epoch - 358ms/step\n",
      "Epoch 45/100\n",
      "173/173 - 62s - loss: 0.9085 - accuracy: 0.8505 - val_loss: 0.8279 - val_accuracy: 0.9059 - 62s/epoch - 360ms/step\n",
      "Epoch 46/100\n",
      "173/173 - 62s - loss: 0.9321 - accuracy: 0.8486 - val_loss: 0.8275 - val_accuracy: 0.9048 - 62s/epoch - 358ms/step\n",
      "Epoch 47/100\n",
      "173/173 - 61s - loss: 0.9095 - accuracy: 0.8532 - val_loss: 0.7956 - val_accuracy: 0.9045 - 61s/epoch - 353ms/step\n",
      "Epoch 48/100\n",
      "173/173 - 61s - loss: 0.9199 - accuracy: 0.8574 - val_loss: 0.7932 - val_accuracy: 0.9045 - 61s/epoch - 354ms/step\n",
      "Epoch 49/100\n",
      "173/173 - 61s - loss: 0.9064 - accuracy: 0.8530 - val_loss: 0.7966 - val_accuracy: 0.9063 - 61s/epoch - 355ms/step\n",
      "Epoch 50/100\n",
      "173/173 - 62s - loss: 0.9205 - accuracy: 0.8522 - val_loss: 0.8167 - val_accuracy: 0.9103 - 62s/epoch - 360ms/step\n",
      "Epoch 51/100\n",
      "173/173 - 63s - loss: 0.9128 - accuracy: 0.8570 - val_loss: 0.7931 - val_accuracy: 0.9103 - 63s/epoch - 362ms/step\n",
      "Epoch 52/100\n",
      "173/173 - 64s - loss: 0.9033 - accuracy: 0.8525 - val_loss: 0.7949 - val_accuracy: 0.9063 - 64s/epoch - 370ms/step\n",
      "Epoch 53/100\n",
      "173/173 - 63s - loss: 0.8935 - accuracy: 0.8572 - val_loss: 0.7862 - val_accuracy: 0.9023 - 63s/epoch - 366ms/step\n",
      "Epoch 54/100\n",
      "173/173 - 63s - loss: 0.8837 - accuracy: 0.8569 - val_loss: 0.7830 - val_accuracy: 0.9117 - 63s/epoch - 362ms/step\n",
      "Epoch 55/100\n",
      "173/173 - 62s - loss: 0.8873 - accuracy: 0.8590 - val_loss: 0.7909 - val_accuracy: 0.9088 - 62s/epoch - 359ms/step\n",
      "Epoch 56/100\n",
      "173/173 - 61s - loss: 0.9360 - accuracy: 0.8500 - val_loss: 0.8092 - val_accuracy: 0.9165 - 61s/epoch - 355ms/step\n",
      "Epoch 57/100\n",
      "173/173 - 62s - loss: 0.8935 - accuracy: 0.8579 - val_loss: 0.7926 - val_accuracy: 0.9077 - 62s/epoch - 361ms/step\n",
      "Epoch 58/100\n",
      "173/173 - 63s - loss: 0.8954 - accuracy: 0.8608 - val_loss: 0.7779 - val_accuracy: 0.9099 - 63s/epoch - 364ms/step\n",
      "Epoch 59/100\n",
      "173/173 - 63s - loss: 0.8855 - accuracy: 0.8579 - val_loss: 0.8193 - val_accuracy: 0.9143 - 63s/epoch - 363ms/step\n",
      "Epoch 60/100\n",
      "173/173 - 63s - loss: 0.9338 - accuracy: 0.8523 - val_loss: 0.7930 - val_accuracy: 0.9088 - 63s/epoch - 366ms/step\n",
      "Epoch 61/100\n",
      "173/173 - 61s - loss: 0.8847 - accuracy: 0.8571 - val_loss: 0.7838 - val_accuracy: 0.9114 - 61s/epoch - 350ms/step\n",
      "Epoch 62/100\n",
      "173/173 - 64s - loss: 0.8998 - accuracy: 0.8514 - val_loss: 0.8049 - val_accuracy: 0.9016 - 64s/epoch - 367ms/step\n",
      "Epoch 63/100\n",
      "173/173 - 62s - loss: 0.9082 - accuracy: 0.8550 - val_loss: 0.8219 - val_accuracy: 0.9066 - 62s/epoch - 360ms/step\n",
      "Epoch 64/100\n",
      "173/173 - 63s - loss: 0.9254 - accuracy: 0.8585 - val_loss: 0.8098 - val_accuracy: 0.9096 - 63s/epoch - 362ms/step\n",
      "Epoch 65/100\n",
      "173/173 - 62s - loss: 0.9019 - accuracy: 0.8589 - val_loss: 0.7934 - val_accuracy: 0.9081 - 62s/epoch - 361ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100\n",
      "173/173 - 62s - loss: 0.8894 - accuracy: 0.8626 - val_loss: 0.8016 - val_accuracy: 0.9081 - 62s/epoch - 360ms/step\n",
      "Epoch 67/100\n",
      "173/173 - 62s - loss: 0.8842 - accuracy: 0.8566 - val_loss: 0.7888 - val_accuracy: 0.9132 - 62s/epoch - 361ms/step\n",
      "Epoch 68/100\n",
      "173/173 - 62s - loss: 0.8782 - accuracy: 0.8634 - val_loss: 0.7851 - val_accuracy: 0.9096 - 62s/epoch - 360ms/step\n",
      "Epoch 69/100\n",
      "173/173 - 62s - loss: 0.9320 - accuracy: 0.8574 - val_loss: 0.7954 - val_accuracy: 0.9146 - 62s/epoch - 361ms/step\n",
      "Epoch 70/100\n",
      "173/173 - 62s - loss: 0.8995 - accuracy: 0.8622 - val_loss: 0.7688 - val_accuracy: 0.9081 - 62s/epoch - 360ms/step\n",
      "Epoch 71/100\n",
      "173/173 - 62s - loss: 0.8830 - accuracy: 0.8589 - val_loss: 0.8048 - val_accuracy: 0.9085 - 62s/epoch - 360ms/step\n",
      "Epoch 72/100\n",
      "173/173 - 62s - loss: 0.8792 - accuracy: 0.8635 - val_loss: 0.7740 - val_accuracy: 0.9106 - 62s/epoch - 361ms/step\n",
      "Epoch 73/100\n",
      "173/173 - 62s - loss: 0.8682 - accuracy: 0.8602 - val_loss: 0.7708 - val_accuracy: 0.9139 - 62s/epoch - 360ms/step\n",
      "Epoch 74/100\n",
      "173/173 - 62s - loss: 0.8718 - accuracy: 0.8659 - val_loss: 0.7661 - val_accuracy: 0.9106 - 62s/epoch - 361ms/step\n",
      "Epoch 75/100\n",
      "173/173 - 63s - loss: 0.8831 - accuracy: 0.8589 - val_loss: 0.7676 - val_accuracy: 0.9143 - 63s/epoch - 362ms/step\n",
      "Epoch 76/100\n",
      "173/173 - 63s - loss: 0.8860 - accuracy: 0.8618 - val_loss: 0.7819 - val_accuracy: 0.9099 - 63s/epoch - 362ms/step\n",
      "Epoch 00076: early stopping\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_4 (Conv1D)           (None, 2376, 128)         1664      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 594, 128)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 594, 128)          0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 76032)             0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 76032)            304128    \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 512)               38928896  \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                32832     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 39,267,585\n",
      "Trainable params: 39,115,521\n",
      "Non-trainable params: 152,064\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    verbose=2,\n",
    "    validation_data=(X_dev, y_dev),\n",
    "    batch_size=64,\n",
    "    callbacks=[es]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe2bbbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (etsy)",
   "language": "python",
   "name": "etsy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
