{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b781b314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "#load inthe NTLK stopwords to remove articles, preposition and other words that are not actionable\n",
    "from nltk.corpus import stopwords\n",
    "# This allows to create individual objects from a bog of words\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "# Lemmatizer helps to reduce words to the base form\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b6562eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/jasmineli/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jasmineli/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/jasmineli/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('summer-products-with-rating-and-performance_2020-08.csv')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b4ccf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f8da2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bert_encode'] = [model.encode(sen) for sen in df['title_orig']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b403985c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasmineli/opt/anaconda3/envs/etsy/lib/python3.7/site-packages/pandas/core/arraylike.py:364: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# product color\n",
    "def main_color(s):\n",
    "    main_color = {\"red\":\"red\", \"white\":\"white\", \"pink\":\"pink\", \"yellow\":\"yellow\", \"green\":\"green\", \"blue\":\"blue\", \"wine\":\"red\", \"burgundy\":\"red\", \"black\":\"black\", \"navy\":\"navy\", \"orange\":\"orange\", \n",
    "    \"rose\":\"pink\", \"gray\":\"gray\", \"grey\":\"gray\", \"purple\":\"purple\", \"violet\":\"purple\", \"army\":\"green\", \"leopard\":\"orange\", \"ivory\":\"white\", \n",
    "    \"brown\":\"brown\", \"coffee\":\"brown\", \"camel\":\"beige\", \"tan\":\"brown\", \"nude\":\"beige\", \"khaki\":\"khaki\", \"apricot\":\"yellow\", \"camouflage\":\"green\", \"jasper\":\"red\"}  # ordered by importance\n",
    "    for key, value in main_color.items():\n",
    "        if key in s:\n",
    "            return value\n",
    "    return \"others\"\n",
    "product_color = df[\"product_color\"]\n",
    "product_color = [s.lower() if type(s) is str else 'nan' for s in product_color]\n",
    "product_color = [main_color(s) for s in product_color]\n",
    "from matplotlib import colors\n",
    "product_color = [(-0.1,-0.1,-0.1,-0.1) if s == \"others\" else colors.to_rgba(s) for s in product_color]\n",
    "\n",
    "df['product_color_rgb'] = [np.array(t) for t in product_color]\n",
    "\n",
    "# log prices\n",
    "df['log_price'] = [np.log(p) for p in df[\"price\"]]\n",
    "df['log_retail_price'] = [np.log(p) for p in df[\"retail_price\"]]\n",
    "\n",
    "# log merchant rating count\n",
    "df['log_merchant_rating_count'] = np.log(df['merchant_rating_count'])\n",
    "\n",
    "# urgent text\n",
    "df['urgent'] = [1 if s == \"Quantité limitée !\" else 0 for s in df[\"urgency_text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72613e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = df[\"product_color_rgb\"]\n",
    "rgb = np.stack(rgb.values, axis=0)\n",
    "for i in range(4):\n",
    "    df[\"product_color_rgb\"+str(i)] = rgb[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b36ac31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasmineli/opt/anaconda3/envs/etsy/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/jasmineli/opt/anaconda3/envs/etsy/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/Users/jasmineli/opt/anaconda3/envs/etsy/lib/python3.7/site-packages/ipykernel_launcher.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "data = df[[\"log_price\", \"log_retail_price\", \"uses_ad_boosts\", \"badges_count\", \"badge_local_product\", \n",
    "           \"badge_product_quality\", \"badge_fast_shipping\", \"urgent\", \"units_sold\"]]\n",
    "label = [1 if sales > 200 else 0 for sales in data[\"units_sold\"]]\n",
    "data['high_sale'] = label\n",
    "bert = np.stack(df['bert_encode'].values, axis=0)\n",
    "for i in range(384):\n",
    "    data[\"title_bert\"+str(i)] = bert[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "635f867d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88830f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.loc[:, ~data.columns.isin(['high_sale', 'units_sold'])]\n",
    "y = data['high_sale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc9b60df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from keras.layers import Input, Dense, Concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.125, random_state=42)\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, test_size=0.14286, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77d158e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 1179\n",
      "number of dev examples = 197\n",
      "number of test examples = 197\n",
      "X_train shape: (1179, 392)\n",
      "Y_train shape: (1179,)\n",
      "X_dev shape: (197, 392)\n",
      "Y_dev shape: (197,)\n",
      "X_test shape: (197, 392)\n",
      "Y_test shape: (197,)\n"
     ]
    }
   ],
   "source": [
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of dev examples = \" + str(X_dev.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(y_train.shape))\n",
    "print (\"X_dev shape: \" + str(X_dev.shape))\n",
    "print (\"Y_dev shape: \" + str(y_dev.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42ab0ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "(100, 392)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-06 17:51:49.544309: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Defining hold out data for evaluation \n",
    "evals_X = X[-100:]\n",
    "evals_y = y[-100:]\n",
    "print(evals_y.shape)\n",
    "print(evals_X.shape)\n",
    "X_train = tf.expand_dims(X_train, axis=-1)\n",
    "input_shape = X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ce43e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa199dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39cb5b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasmineli/opt/anaconda3/envs/etsy/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 - 1s - loss: 0.6930 - accuracy: 0.5768 - val_loss: 0.6373 - val_accuracy: 0.6500 - 894ms/epoch - 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasmineli/opt/anaconda3/envs/etsy/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/1000\n",
      "37/37 - 0s - loss: 0.6684 - accuracy: 0.6022 - val_loss: 0.6641 - val_accuracy: 0.6500 - 324ms/epoch - 9ms/step\n",
      "Epoch 3/1000\n",
      "37/37 - 0s - loss: 0.6544 - accuracy: 0.6209 - val_loss: 0.6078 - val_accuracy: 0.6600 - 322ms/epoch - 9ms/step\n",
      "Epoch 4/1000\n",
      "37/37 - 0s - loss: 0.6410 - accuracy: 0.6226 - val_loss: 0.6250 - val_accuracy: 0.7000 - 297ms/epoch - 8ms/step\n",
      "Epoch 5/1000\n",
      "37/37 - 0s - loss: 0.6211 - accuracy: 0.6616 - val_loss: 0.5877 - val_accuracy: 0.6700 - 302ms/epoch - 8ms/step\n",
      "Epoch 6/1000\n",
      "37/37 - 0s - loss: 0.6088 - accuracy: 0.6751 - val_loss: 0.5757 - val_accuracy: 0.6900 - 314ms/epoch - 8ms/step\n",
      "Epoch 7/1000\n",
      "37/37 - 0s - loss: 0.5886 - accuracy: 0.7006 - val_loss: 0.5596 - val_accuracy: 0.6900 - 312ms/epoch - 8ms/step\n",
      "Epoch 8/1000\n",
      "37/37 - 0s - loss: 0.5754 - accuracy: 0.6938 - val_loss: 0.5452 - val_accuracy: 0.7400 - 305ms/epoch - 8ms/step\n",
      "Epoch 9/1000\n",
      "37/37 - 0s - loss: 0.5438 - accuracy: 0.7379 - val_loss: 0.5336 - val_accuracy: 0.7800 - 307ms/epoch - 8ms/step\n",
      "Epoch 10/1000\n",
      "37/37 - 0s - loss: 0.5227 - accuracy: 0.7455 - val_loss: 0.5275 - val_accuracy: 0.7700 - 315ms/epoch - 9ms/step\n",
      "Epoch 11/1000\n",
      "37/37 - 0s - loss: 0.5041 - accuracy: 0.7574 - val_loss: 0.4914 - val_accuracy: 0.7900 - 306ms/epoch - 8ms/step\n",
      "Epoch 12/1000\n",
      "37/37 - 0s - loss: 0.4910 - accuracy: 0.7727 - val_loss: 0.4781 - val_accuracy: 0.8000 - 315ms/epoch - 9ms/step\n",
      "Epoch 13/1000\n",
      "37/37 - 0s - loss: 0.4589 - accuracy: 0.7930 - val_loss: 0.4830 - val_accuracy: 0.8100 - 303ms/epoch - 8ms/step\n",
      "Epoch 14/1000\n",
      "37/37 - 0s - loss: 0.4679 - accuracy: 0.7668 - val_loss: 0.4728 - val_accuracy: 0.7500 - 323ms/epoch - 9ms/step\n",
      "Epoch 15/1000\n",
      "37/37 - 0s - loss: 0.4518 - accuracy: 0.7871 - val_loss: 0.4949 - val_accuracy: 0.7900 - 323ms/epoch - 9ms/step\n",
      "Epoch 16/1000\n",
      "37/37 - 0s - loss: 0.4370 - accuracy: 0.8066 - val_loss: 0.4408 - val_accuracy: 0.8300 - 307ms/epoch - 8ms/step\n",
      "Epoch 17/1000\n",
      "37/37 - 0s - loss: 0.4038 - accuracy: 0.8253 - val_loss: 0.4226 - val_accuracy: 0.8300 - 310ms/epoch - 8ms/step\n",
      "Epoch 18/1000\n",
      "37/37 - 0s - loss: 0.4109 - accuracy: 0.8041 - val_loss: 0.4325 - val_accuracy: 0.8400 - 311ms/epoch - 8ms/step\n",
      "Epoch 19/1000\n",
      "37/37 - 0s - loss: 0.3729 - accuracy: 0.8287 - val_loss: 0.3972 - val_accuracy: 0.8300 - 317ms/epoch - 9ms/step\n",
      "Epoch 20/1000\n",
      "37/37 - 0s - loss: 0.3814 - accuracy: 0.8304 - val_loss: 0.4567 - val_accuracy: 0.8000 - 323ms/epoch - 9ms/step\n",
      "Epoch 21/1000\n",
      "37/37 - 0s - loss: 0.3587 - accuracy: 0.8482 - val_loss: 0.4511 - val_accuracy: 0.8200 - 310ms/epoch - 8ms/step\n",
      "Epoch 22/1000\n",
      "37/37 - 0s - loss: 0.3375 - accuracy: 0.8550 - val_loss: 0.3532 - val_accuracy: 0.8500 - 320ms/epoch - 9ms/step\n",
      "Epoch 23/1000\n",
      "37/37 - 0s - loss: 0.3191 - accuracy: 0.8677 - val_loss: 0.3642 - val_accuracy: 0.8400 - 330ms/epoch - 9ms/step\n",
      "Epoch 24/1000\n",
      "37/37 - 0s - loss: 0.3246 - accuracy: 0.8609 - val_loss: 0.3431 - val_accuracy: 0.8500 - 339ms/epoch - 9ms/step\n",
      "Epoch 25/1000\n",
      "37/37 - 0s - loss: 0.3199 - accuracy: 0.8550 - val_loss: 0.3475 - val_accuracy: 0.8600 - 304ms/epoch - 8ms/step\n",
      "Epoch 26/1000\n",
      "37/37 - 0s - loss: 0.3281 - accuracy: 0.8558 - val_loss: 0.3653 - val_accuracy: 0.8100 - 315ms/epoch - 9ms/step\n",
      "Epoch 27/1000\n",
      "37/37 - 0s - loss: 0.2939 - accuracy: 0.8770 - val_loss: 0.3991 - val_accuracy: 0.8500 - 306ms/epoch - 8ms/step\n",
      "Epoch 28/1000\n",
      "37/37 - 0s - loss: 0.2942 - accuracy: 0.8830 - val_loss: 0.3127 - val_accuracy: 0.8500 - 312ms/epoch - 8ms/step\n",
      "Epoch 29/1000\n",
      "37/37 - 0s - loss: 0.2775 - accuracy: 0.8931 - val_loss: 0.3281 - val_accuracy: 0.8700 - 323ms/epoch - 9ms/step\n",
      "Epoch 30/1000\n",
      "37/37 - 0s - loss: 0.2682 - accuracy: 0.8914 - val_loss: 0.3141 - val_accuracy: 0.8700 - 308ms/epoch - 8ms/step\n",
      "Epoch 31/1000\n",
      "37/37 - 0s - loss: 0.2553 - accuracy: 0.9025 - val_loss: 0.3521 - val_accuracy: 0.8300 - 318ms/epoch - 9ms/step\n",
      "Epoch 32/1000\n",
      "37/37 - 0s - loss: 0.2631 - accuracy: 0.8880 - val_loss: 0.2987 - val_accuracy: 0.8700 - 318ms/epoch - 9ms/step\n",
      "Epoch 33/1000\n",
      "37/37 - 0s - loss: 0.2481 - accuracy: 0.9008 - val_loss: 0.3801 - val_accuracy: 0.8500 - 331ms/epoch - 9ms/step\n",
      "Epoch 34/1000\n",
      "37/37 - 0s - loss: 0.2469 - accuracy: 0.9025 - val_loss: 0.3168 - val_accuracy: 0.8800 - 320ms/epoch - 9ms/step\n",
      "Epoch 35/1000\n",
      "37/37 - 0s - loss: 0.2419 - accuracy: 0.8982 - val_loss: 0.3080 - val_accuracy: 0.8800 - 327ms/epoch - 9ms/step\n",
      "Epoch 36/1000\n",
      "37/37 - 0s - loss: 0.2370 - accuracy: 0.9042 - val_loss: 0.2939 - val_accuracy: 0.8700 - 332ms/epoch - 9ms/step\n",
      "Epoch 37/1000\n",
      "37/37 - 0s - loss: 0.2369 - accuracy: 0.9050 - val_loss: 0.2905 - val_accuracy: 0.8900 - 325ms/epoch - 9ms/step\n",
      "Epoch 38/1000\n",
      "37/37 - 0s - loss: 0.2273 - accuracy: 0.9042 - val_loss: 0.2798 - val_accuracy: 0.8800 - 332ms/epoch - 9ms/step\n",
      "Epoch 39/1000\n",
      "37/37 - 0s - loss: 0.2175 - accuracy: 0.9160 - val_loss: 0.2731 - val_accuracy: 0.8900 - 337ms/epoch - 9ms/step\n",
      "Epoch 40/1000\n",
      "37/37 - 0s - loss: 0.2141 - accuracy: 0.9143 - val_loss: 0.2940 - val_accuracy: 0.9000 - 326ms/epoch - 9ms/step\n",
      "Epoch 41/1000\n",
      "37/37 - 0s - loss: 0.1994 - accuracy: 0.9271 - val_loss: 0.2660 - val_accuracy: 0.9100 - 331ms/epoch - 9ms/step\n",
      "Epoch 42/1000\n",
      "37/37 - 0s - loss: 0.2019 - accuracy: 0.9160 - val_loss: 0.2967 - val_accuracy: 0.8900 - 363ms/epoch - 10ms/step\n",
      "Epoch 43/1000\n",
      "37/37 - 0s - loss: 0.2232 - accuracy: 0.9237 - val_loss: 0.2964 - val_accuracy: 0.8700 - 336ms/epoch - 9ms/step\n",
      "Epoch 44/1000\n",
      "37/37 - 0s - loss: 0.2030 - accuracy: 0.9186 - val_loss: 0.2508 - val_accuracy: 0.9100 - 328ms/epoch - 9ms/step\n",
      "Epoch 45/1000\n",
      "37/37 - 0s - loss: 0.1892 - accuracy: 0.9321 - val_loss: 0.2506 - val_accuracy: 0.9000 - 317ms/epoch - 9ms/step\n",
      "Epoch 46/1000\n",
      "37/37 - 0s - loss: 0.1855 - accuracy: 0.9304 - val_loss: 0.4024 - val_accuracy: 0.8200 - 323ms/epoch - 9ms/step\n",
      "Epoch 47/1000\n",
      "37/37 - 0s - loss: 0.2199 - accuracy: 0.9008 - val_loss: 0.2625 - val_accuracy: 0.8800 - 301ms/epoch - 8ms/step\n",
      "Epoch 48/1000\n",
      "37/37 - 0s - loss: 0.2163 - accuracy: 0.9169 - val_loss: 0.2520 - val_accuracy: 0.9200 - 314ms/epoch - 8ms/step\n",
      "Epoch 49/1000\n",
      "37/37 - 0s - loss: 0.1768 - accuracy: 0.9389 - val_loss: 0.2410 - val_accuracy: 0.9300 - 329ms/epoch - 9ms/step\n",
      "Epoch 50/1000\n",
      "37/37 - 0s - loss: 0.1778 - accuracy: 0.9338 - val_loss: 0.2417 - val_accuracy: 0.9100 - 332ms/epoch - 9ms/step\n",
      "Epoch 51/1000\n",
      "37/37 - 0s - loss: 0.1691 - accuracy: 0.9364 - val_loss: 0.2801 - val_accuracy: 0.8800 - 329ms/epoch - 9ms/step\n",
      "Epoch 52/1000\n",
      "37/37 - 0s - loss: 0.1845 - accuracy: 0.9313 - val_loss: 0.3448 - val_accuracy: 0.8900 - 333ms/epoch - 9ms/step\n",
      "Epoch 53/1000\n",
      "37/37 - 0s - loss: 0.2059 - accuracy: 0.9160 - val_loss: 0.2198 - val_accuracy: 0.9100 - 335ms/epoch - 9ms/step\n",
      "Epoch 54/1000\n",
      "37/37 - 0s - loss: 0.1629 - accuracy: 0.9372 - val_loss: 0.2512 - val_accuracy: 0.9300 - 347ms/epoch - 9ms/step\n",
      "Epoch 55/1000\n",
      "37/37 - 0s - loss: 0.1989 - accuracy: 0.9254 - val_loss: 0.1970 - val_accuracy: 0.9400 - 326ms/epoch - 9ms/step\n",
      "Epoch 56/1000\n",
      "37/37 - 0s - loss: 0.1674 - accuracy: 0.9381 - val_loss: 0.2466 - val_accuracy: 0.9300 - 327ms/epoch - 9ms/step\n",
      "Epoch 57/1000\n",
      "37/37 - 0s - loss: 0.2072 - accuracy: 0.9152 - val_loss: 0.2272 - val_accuracy: 0.9100 - 343ms/epoch - 9ms/step\n",
      "Epoch 58/1000\n",
      "37/37 - 0s - loss: 0.2078 - accuracy: 0.9203 - val_loss: 0.2576 - val_accuracy: 0.9200 - 344ms/epoch - 9ms/step\n",
      "Epoch 59/1000\n",
      "37/37 - 0s - loss: 0.1938 - accuracy: 0.9228 - val_loss: 0.3118 - val_accuracy: 0.9100 - 346ms/epoch - 9ms/step\n",
      "Epoch 60/1000\n",
      "37/37 - 0s - loss: 0.1703 - accuracy: 0.9347 - val_loss: 0.2342 - val_accuracy: 0.8900 - 327ms/epoch - 9ms/step\n",
      "Epoch 61/1000\n",
      "37/37 - 0s - loss: 0.1526 - accuracy: 0.9381 - val_loss: 0.2375 - val_accuracy: 0.9400 - 331ms/epoch - 9ms/step\n",
      "Epoch 62/1000\n",
      "37/37 - 0s - loss: 0.1482 - accuracy: 0.9466 - val_loss: 0.2236 - val_accuracy: 0.9400 - 339ms/epoch - 9ms/step\n",
      "Epoch 63/1000\n",
      "37/37 - 0s - loss: 0.1763 - accuracy: 0.9304 - val_loss: 0.2038 - val_accuracy: 0.9300 - 335ms/epoch - 9ms/step\n",
      "Epoch 64/1000\n",
      "37/37 - 0s - loss: 0.1603 - accuracy: 0.9457 - val_loss: 0.2199 - val_accuracy: 0.9200 - 341ms/epoch - 9ms/step\n",
      "Epoch 65/1000\n",
      "37/37 - 0s - loss: 0.1392 - accuracy: 0.9483 - val_loss: 0.2069 - val_accuracy: 0.9400 - 319ms/epoch - 9ms/step\n",
      "Epoch 66/1000\n",
      "37/37 - 0s - loss: 0.1564 - accuracy: 0.9415 - val_loss: 0.2335 - val_accuracy: 0.9300 - 322ms/epoch - 9ms/step\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 - 0s - loss: 0.1560 - accuracy: 0.9321 - val_loss: 0.2187 - val_accuracy: 0.9100 - 315ms/epoch - 9ms/step\n",
      "Epoch 68/1000\n",
      "37/37 - 0s - loss: 0.2065 - accuracy: 0.9186 - val_loss: 0.2587 - val_accuracy: 0.8900 - 311ms/epoch - 8ms/step\n",
      "Epoch 69/1000\n",
      "37/37 - 0s - loss: 0.1547 - accuracy: 0.9389 - val_loss: 0.2014 - val_accuracy: 0.9400 - 323ms/epoch - 9ms/step\n",
      "Epoch 70/1000\n",
      "37/37 - 0s - loss: 0.1313 - accuracy: 0.9534 - val_loss: 0.2105 - val_accuracy: 0.9300 - 323ms/epoch - 9ms/step\n",
      "Epoch 71/1000\n",
      "37/37 - 0s - loss: 0.1338 - accuracy: 0.9534 - val_loss: 0.2215 - val_accuracy: 0.9200 - 331ms/epoch - 9ms/step\n",
      "Epoch 72/1000\n",
      "37/37 - 0s - loss: 0.1421 - accuracy: 0.9491 - val_loss: 0.2080 - val_accuracy: 0.9400 - 320ms/epoch - 9ms/step\n",
      "Epoch 73/1000\n",
      "37/37 - 0s - loss: 0.1380 - accuracy: 0.9567 - val_loss: 0.2051 - val_accuracy: 0.9400 - 367ms/epoch - 10ms/step\n",
      "Epoch 74/1000\n",
      "37/37 - 0s - loss: 0.1383 - accuracy: 0.9491 - val_loss: 0.2201 - val_accuracy: 0.9300 - 349ms/epoch - 9ms/step\n",
      "Epoch 75/1000\n",
      "37/37 - 0s - loss: 0.1560 - accuracy: 0.9372 - val_loss: 0.2197 - val_accuracy: 0.9200 - 338ms/epoch - 9ms/step\n",
      "Epoch 76/1000\n",
      "37/37 - 0s - loss: 0.1338 - accuracy: 0.9474 - val_loss: 0.2345 - val_accuracy: 0.9300 - 317ms/epoch - 9ms/step\n",
      "Epoch 77/1000\n",
      "37/37 - 0s - loss: 0.1324 - accuracy: 0.9559 - val_loss: 0.2282 - val_accuracy: 0.9300 - 348ms/epoch - 9ms/step\n",
      "Epoch 78/1000\n",
      "37/37 - 0s - loss: 0.1326 - accuracy: 0.9500 - val_loss: 0.2983 - val_accuracy: 0.8700 - 334ms/epoch - 9ms/step\n",
      "Epoch 79/1000\n",
      "37/37 - 0s - loss: 0.1514 - accuracy: 0.9406 - val_loss: 0.2367 - val_accuracy: 0.9100 - 319ms/epoch - 9ms/step\n",
      "Epoch 80/1000\n",
      "37/37 - 0s - loss: 0.1453 - accuracy: 0.9474 - val_loss: 0.2705 - val_accuracy: 0.9000 - 364ms/epoch - 10ms/step\n",
      "Epoch 81/1000\n",
      "37/37 - 0s - loss: 0.1421 - accuracy: 0.9406 - val_loss: 0.2222 - val_accuracy: 0.9200 - 376ms/epoch - 10ms/step\n",
      "Epoch 82/1000\n",
      "37/37 - 0s - loss: 0.1367 - accuracy: 0.9440 - val_loss: 0.2038 - val_accuracy: 0.9400 - 353ms/epoch - 10ms/step\n",
      "Epoch 83/1000\n",
      "37/37 - 0s - loss: 0.1350 - accuracy: 0.9483 - val_loss: 0.2384 - val_accuracy: 0.9100 - 336ms/epoch - 9ms/step\n",
      "Epoch 84/1000\n",
      "37/37 - 0s - loss: 0.1390 - accuracy: 0.9398 - val_loss: 0.2860 - val_accuracy: 0.9000 - 347ms/epoch - 9ms/step\n",
      "Epoch 85/1000\n",
      "37/37 - 0s - loss: 0.1367 - accuracy: 0.9440 - val_loss: 0.2370 - val_accuracy: 0.9200 - 330ms/epoch - 9ms/step\n",
      "Epoch 86/1000\n",
      "37/37 - 0s - loss: 0.1200 - accuracy: 0.9534 - val_loss: 0.2223 - val_accuracy: 0.9300 - 324ms/epoch - 9ms/step\n",
      "Epoch 87/1000\n",
      "37/37 - 0s - loss: 0.1227 - accuracy: 0.9550 - val_loss: 0.2267 - val_accuracy: 0.9200 - 327ms/epoch - 9ms/step\n",
      "Epoch 88/1000\n",
      "37/37 - 0s - loss: 0.1197 - accuracy: 0.9534 - val_loss: 0.1871 - val_accuracy: 0.9400 - 326ms/epoch - 9ms/step\n",
      "Epoch 89/1000\n",
      "37/37 - 0s - loss: 0.1289 - accuracy: 0.9483 - val_loss: 0.2695 - val_accuracy: 0.9000 - 331ms/epoch - 9ms/step\n",
      "Epoch 90/1000\n",
      "37/37 - 0s - loss: 0.1225 - accuracy: 0.9618 - val_loss: 0.2312 - val_accuracy: 0.9300 - 341ms/epoch - 9ms/step\n",
      "Epoch 91/1000\n",
      "37/37 - 0s - loss: 0.1130 - accuracy: 0.9542 - val_loss: 0.2227 - val_accuracy: 0.9200 - 334ms/epoch - 9ms/step\n",
      "Epoch 92/1000\n",
      "37/37 - 0s - loss: 0.1213 - accuracy: 0.9534 - val_loss: 0.2183 - val_accuracy: 0.9100 - 318ms/epoch - 9ms/step\n",
      "Epoch 93/1000\n",
      "37/37 - 0s - loss: 0.1193 - accuracy: 0.9559 - val_loss: 0.2297 - val_accuracy: 0.9200 - 327ms/epoch - 9ms/step\n",
      "Epoch 94/1000\n",
      "37/37 - 0s - loss: 0.1225 - accuracy: 0.9542 - val_loss: 0.2390 - val_accuracy: 0.9200 - 326ms/epoch - 9ms/step\n",
      "Epoch 95/1000\n",
      "37/37 - 0s - loss: 0.1318 - accuracy: 0.9550 - val_loss: 0.2007 - val_accuracy: 0.9300 - 338ms/epoch - 9ms/step\n",
      "Epoch 96/1000\n",
      "37/37 - 0s - loss: 0.1131 - accuracy: 0.9576 - val_loss: 0.2884 - val_accuracy: 0.9100 - 326ms/epoch - 9ms/step\n",
      "Epoch 97/1000\n",
      "37/37 - 0s - loss: 0.1194 - accuracy: 0.9457 - val_loss: 0.2737 - val_accuracy: 0.9100 - 329ms/epoch - 9ms/step\n",
      "Epoch 98/1000\n",
      "37/37 - 0s - loss: 0.1217 - accuracy: 0.9500 - val_loss: 0.1905 - val_accuracy: 0.9300 - 336ms/epoch - 9ms/step\n",
      "Epoch 99/1000\n",
      "37/37 - 0s - loss: 0.1477 - accuracy: 0.9440 - val_loss: 0.2025 - val_accuracy: 0.9100 - 371ms/epoch - 10ms/step\n",
      "Epoch 100/1000\n",
      "37/37 - 0s - loss: 0.1161 - accuracy: 0.9508 - val_loss: 0.2118 - val_accuracy: 0.9300 - 385ms/epoch - 10ms/step\n",
      "Epoch 101/1000\n",
      "37/37 - 0s - loss: 0.1416 - accuracy: 0.9406 - val_loss: 0.1970 - val_accuracy: 0.9400 - 383ms/epoch - 10ms/step\n",
      "Epoch 102/1000\n",
      "37/37 - 0s - loss: 0.1064 - accuracy: 0.9593 - val_loss: 0.2202 - val_accuracy: 0.9100 - 362ms/epoch - 10ms/step\n",
      "Epoch 103/1000\n",
      "37/37 - 0s - loss: 0.1177 - accuracy: 0.9584 - val_loss: 0.2345 - val_accuracy: 0.9400 - 386ms/epoch - 10ms/step\n",
      "Epoch 104/1000\n",
      "37/37 - 0s - loss: 0.1084 - accuracy: 0.9584 - val_loss: 0.1880 - val_accuracy: 0.9500 - 355ms/epoch - 10ms/step\n",
      "Epoch 105/1000\n",
      "37/37 - 0s - loss: 0.1157 - accuracy: 0.9567 - val_loss: 0.2239 - val_accuracy: 0.9400 - 352ms/epoch - 10ms/step\n",
      "Epoch 106/1000\n",
      "37/37 - 0s - loss: 0.1225 - accuracy: 0.9525 - val_loss: 0.2000 - val_accuracy: 0.9400 - 336ms/epoch - 9ms/step\n",
      "Epoch 107/1000\n",
      "37/37 - 0s - loss: 0.1108 - accuracy: 0.9627 - val_loss: 0.2222 - val_accuracy: 0.9200 - 345ms/epoch - 9ms/step\n",
      "Epoch 108/1000\n",
      "37/37 - 0s - loss: 0.1056 - accuracy: 0.9635 - val_loss: 0.1866 - val_accuracy: 0.9500 - 334ms/epoch - 9ms/step\n",
      "Epoch 109/1000\n",
      "37/37 - 0s - loss: 0.0984 - accuracy: 0.9559 - val_loss: 0.2190 - val_accuracy: 0.9300 - 345ms/epoch - 9ms/step\n",
      "Epoch 110/1000\n",
      "37/37 - 0s - loss: 0.1130 - accuracy: 0.9534 - val_loss: 0.1809 - val_accuracy: 0.9500 - 327ms/epoch - 9ms/step\n",
      "Epoch 111/1000\n",
      "37/37 - 0s - loss: 0.1231 - accuracy: 0.9534 - val_loss: 0.1754 - val_accuracy: 0.9500 - 329ms/epoch - 9ms/step\n",
      "Epoch 112/1000\n",
      "37/37 - 0s - loss: 0.1186 - accuracy: 0.9491 - val_loss: 0.2552 - val_accuracy: 0.9100 - 328ms/epoch - 9ms/step\n",
      "Epoch 113/1000\n",
      "37/37 - 0s - loss: 0.1001 - accuracy: 0.9627 - val_loss: 0.2112 - val_accuracy: 0.9300 - 319ms/epoch - 9ms/step\n",
      "Epoch 114/1000\n",
      "37/37 - 0s - loss: 0.1166 - accuracy: 0.9567 - val_loss: 0.1878 - val_accuracy: 0.9300 - 326ms/epoch - 9ms/step\n",
      "Epoch 115/1000\n",
      "37/37 - 0s - loss: 0.1054 - accuracy: 0.9567 - val_loss: 0.1960 - val_accuracy: 0.9300 - 316ms/epoch - 9ms/step\n",
      "Epoch 116/1000\n",
      "37/37 - 0s - loss: 0.1030 - accuracy: 0.9576 - val_loss: 0.2344 - val_accuracy: 0.9300 - 316ms/epoch - 9ms/step\n",
      "Epoch 117/1000\n",
      "37/37 - 0s - loss: 0.1043 - accuracy: 0.9652 - val_loss: 0.2080 - val_accuracy: 0.9200 - 326ms/epoch - 9ms/step\n",
      "Epoch 118/1000\n",
      "37/37 - 0s - loss: 0.0985 - accuracy: 0.9601 - val_loss: 0.1999 - val_accuracy: 0.9400 - 348ms/epoch - 9ms/step\n",
      "Epoch 119/1000\n",
      "37/37 - 0s - loss: 0.1062 - accuracy: 0.9601 - val_loss: 0.2403 - val_accuracy: 0.9100 - 361ms/epoch - 10ms/step\n",
      "Epoch 120/1000\n",
      "37/37 - 0s - loss: 0.0983 - accuracy: 0.9661 - val_loss: 0.2032 - val_accuracy: 0.9200 - 341ms/epoch - 9ms/step\n",
      "Epoch 121/1000\n",
      "37/37 - 0s - loss: 0.1110 - accuracy: 0.9542 - val_loss: 0.2297 - val_accuracy: 0.9100 - 336ms/epoch - 9ms/step\n",
      "Epoch 122/1000\n",
      "37/37 - 0s - loss: 0.1042 - accuracy: 0.9584 - val_loss: 0.1941 - val_accuracy: 0.9500 - 347ms/epoch - 9ms/step\n",
      "Epoch 123/1000\n",
      "37/37 - 0s - loss: 0.0979 - accuracy: 0.9584 - val_loss: 0.1671 - val_accuracy: 0.9400 - 340ms/epoch - 9ms/step\n",
      "Epoch 124/1000\n",
      "37/37 - 0s - loss: 0.1021 - accuracy: 0.9593 - val_loss: 0.2038 - val_accuracy: 0.9200 - 355ms/epoch - 10ms/step\n",
      "Epoch 125/1000\n",
      "37/37 - 0s - loss: 0.1289 - accuracy: 0.9550 - val_loss: 0.3129 - val_accuracy: 0.9000 - 332ms/epoch - 9ms/step\n",
      "Epoch 126/1000\n",
      "37/37 - 0s - loss: 0.1163 - accuracy: 0.9567 - val_loss: 0.2326 - val_accuracy: 0.9100 - 345ms/epoch - 9ms/step\n",
      "Epoch 127/1000\n",
      "37/37 - 0s - loss: 0.1129 - accuracy: 0.9567 - val_loss: 0.1668 - val_accuracy: 0.9400 - 352ms/epoch - 10ms/step\n",
      "Epoch 128/1000\n",
      "37/37 - 0s - loss: 0.1208 - accuracy: 0.9491 - val_loss: 0.2466 - val_accuracy: 0.9200 - 359ms/epoch - 10ms/step\n",
      "Epoch 129/1000\n",
      "37/37 - 0s - loss: 0.1051 - accuracy: 0.9567 - val_loss: 0.1872 - val_accuracy: 0.9200 - 380ms/epoch - 10ms/step\n",
      "Epoch 130/1000\n",
      "37/37 - 0s - loss: 0.1107 - accuracy: 0.9534 - val_loss: 0.2183 - val_accuracy: 0.9300 - 384ms/epoch - 10ms/step\n",
      "Epoch 131/1000\n",
      "37/37 - 0s - loss: 0.1216 - accuracy: 0.9500 - val_loss: 0.1492 - val_accuracy: 0.9500 - 343ms/epoch - 9ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/1000\n",
      "37/37 - 0s - loss: 0.0992 - accuracy: 0.9593 - val_loss: 0.1557 - val_accuracy: 0.9400 - 353ms/epoch - 10ms/step\n",
      "Epoch 133/1000\n",
      "37/37 - 0s - loss: 0.1243 - accuracy: 0.9525 - val_loss: 0.1604 - val_accuracy: 0.9500 - 334ms/epoch - 9ms/step\n",
      "Epoch 134/1000\n",
      "37/37 - 0s - loss: 0.1176 - accuracy: 0.9491 - val_loss: 0.1922 - val_accuracy: 0.9200 - 377ms/epoch - 10ms/step\n",
      "Epoch 135/1000\n",
      "37/37 - 0s - loss: 0.1093 - accuracy: 0.9559 - val_loss: 0.2050 - val_accuracy: 0.9200 - 354ms/epoch - 10ms/step\n",
      "Epoch 136/1000\n",
      "37/37 - 0s - loss: 0.0971 - accuracy: 0.9618 - val_loss: 0.2491 - val_accuracy: 0.8800 - 339ms/epoch - 9ms/step\n",
      "Epoch 137/1000\n",
      "37/37 - 0s - loss: 0.0960 - accuracy: 0.9635 - val_loss: 0.1681 - val_accuracy: 0.9400 - 367ms/epoch - 10ms/step\n",
      "Epoch 138/1000\n",
      "37/37 - 0s - loss: 0.0868 - accuracy: 0.9661 - val_loss: 0.2661 - val_accuracy: 0.9000 - 341ms/epoch - 9ms/step\n",
      "Epoch 139/1000\n",
      "37/37 - 0s - loss: 0.0925 - accuracy: 0.9644 - val_loss: 0.2490 - val_accuracy: 0.9100 - 326ms/epoch - 9ms/step\n",
      "Epoch 140/1000\n",
      "37/37 - 0s - loss: 0.0939 - accuracy: 0.9618 - val_loss: 0.2354 - val_accuracy: 0.9200 - 329ms/epoch - 9ms/step\n",
      "Epoch 141/1000\n",
      "37/37 - 0s - loss: 0.1101 - accuracy: 0.9644 - val_loss: 0.2097 - val_accuracy: 0.9300 - 334ms/epoch - 9ms/step\n",
      "Epoch 142/1000\n",
      "37/37 - 0s - loss: 0.1135 - accuracy: 0.9550 - val_loss: 0.2075 - val_accuracy: 0.9200 - 321ms/epoch - 9ms/step\n",
      "Epoch 143/1000\n",
      "37/37 - 0s - loss: 0.0906 - accuracy: 0.9593 - val_loss: 0.2029 - val_accuracy: 0.9400 - 329ms/epoch - 9ms/step\n",
      "Epoch 144/1000\n",
      "37/37 - 0s - loss: 0.0970 - accuracy: 0.9652 - val_loss: 0.1956 - val_accuracy: 0.9400 - 357ms/epoch - 10ms/step\n",
      "Epoch 145/1000\n",
      "37/37 - 0s - loss: 0.1007 - accuracy: 0.9644 - val_loss: 0.1941 - val_accuracy: 0.9400 - 327ms/epoch - 9ms/step\n",
      "Epoch 146/1000\n",
      "37/37 - 0s - loss: 0.1053 - accuracy: 0.9576 - val_loss: 0.2101 - val_accuracy: 0.9300 - 358ms/epoch - 10ms/step\n",
      "Epoch 147/1000\n",
      "37/37 - 0s - loss: 0.0943 - accuracy: 0.9644 - val_loss: 0.2427 - val_accuracy: 0.9200 - 338ms/epoch - 9ms/step\n",
      "Epoch 148/1000\n",
      "37/37 - 0s - loss: 0.0918 - accuracy: 0.9610 - val_loss: 0.2244 - val_accuracy: 0.9200 - 327ms/epoch - 9ms/step\n",
      "Epoch 149/1000\n",
      "37/37 - 0s - loss: 0.0993 - accuracy: 0.9627 - val_loss: 0.1677 - val_accuracy: 0.9300 - 345ms/epoch - 9ms/step\n",
      "Epoch 150/1000\n",
      "37/37 - 0s - loss: 0.0880 - accuracy: 0.9618 - val_loss: 0.1949 - val_accuracy: 0.9300 - 319ms/epoch - 9ms/step\n",
      "Epoch 151/1000\n",
      "37/37 - 0s - loss: 0.0888 - accuracy: 0.9610 - val_loss: 0.1564 - val_accuracy: 0.9300 - 347ms/epoch - 9ms/step\n",
      "Epoch 152/1000\n",
      "37/37 - 0s - loss: 0.0901 - accuracy: 0.9584 - val_loss: 0.2457 - val_accuracy: 0.9100 - 331ms/epoch - 9ms/step\n",
      "Epoch 153/1000\n",
      "37/37 - 0s - loss: 0.0808 - accuracy: 0.9661 - val_loss: 0.2005 - val_accuracy: 0.9300 - 349ms/epoch - 9ms/step\n",
      "Epoch 154/1000\n",
      "37/37 - 0s - loss: 0.0850 - accuracy: 0.9627 - val_loss: 0.1695 - val_accuracy: 0.9300 - 395ms/epoch - 11ms/step\n",
      "Epoch 155/1000\n",
      "37/37 - 0s - loss: 0.0995 - accuracy: 0.9601 - val_loss: 0.1890 - val_accuracy: 0.9300 - 358ms/epoch - 10ms/step\n",
      "Epoch 156/1000\n",
      "37/37 - 0s - loss: 0.0898 - accuracy: 0.9661 - val_loss: 0.1845 - val_accuracy: 0.9500 - 329ms/epoch - 9ms/step\n",
      "Epoch 157/1000\n",
      "37/37 - 0s - loss: 0.0860 - accuracy: 0.9678 - val_loss: 0.1638 - val_accuracy: 0.9600 - 361ms/epoch - 10ms/step\n",
      "Epoch 158/1000\n",
      "37/37 - 0s - loss: 0.0953 - accuracy: 0.9644 - val_loss: 0.1834 - val_accuracy: 0.9400 - 379ms/epoch - 10ms/step\n",
      "Epoch 159/1000\n",
      "37/37 - 0s - loss: 0.0958 - accuracy: 0.9652 - val_loss: 0.2744 - val_accuracy: 0.8900 - 347ms/epoch - 9ms/step\n",
      "Epoch 160/1000\n",
      "37/37 - 0s - loss: 0.1040 - accuracy: 0.9525 - val_loss: 0.1484 - val_accuracy: 0.9500 - 355ms/epoch - 10ms/step\n",
      "Epoch 161/1000\n",
      "37/37 - 0s - loss: 0.0834 - accuracy: 0.9635 - val_loss: 0.2144 - val_accuracy: 0.9100 - 401ms/epoch - 11ms/step\n",
      "Epoch 162/1000\n",
      "37/37 - 0s - loss: 0.0880 - accuracy: 0.9652 - val_loss: 0.1856 - val_accuracy: 0.9000 - 370ms/epoch - 10ms/step\n",
      "Epoch 163/1000\n",
      "37/37 - 0s - loss: 0.0915 - accuracy: 0.9627 - val_loss: 0.1962 - val_accuracy: 0.9200 - 373ms/epoch - 10ms/step\n",
      "Epoch 164/1000\n",
      "37/37 - 0s - loss: 0.0920 - accuracy: 0.9686 - val_loss: 0.2602 - val_accuracy: 0.9100 - 368ms/epoch - 10ms/step\n",
      "Epoch 165/1000\n",
      "37/37 - 0s - loss: 0.1009 - accuracy: 0.9567 - val_loss: 0.1934 - val_accuracy: 0.9400 - 372ms/epoch - 10ms/step\n",
      "Epoch 166/1000\n",
      "37/37 - 0s - loss: 0.0963 - accuracy: 0.9635 - val_loss: 0.2193 - val_accuracy: 0.9200 - 345ms/epoch - 9ms/step\n",
      "Epoch 167/1000\n",
      "37/37 - 0s - loss: 0.0945 - accuracy: 0.9618 - val_loss: 0.2389 - val_accuracy: 0.9200 - 356ms/epoch - 10ms/step\n",
      "Epoch 168/1000\n",
      "37/37 - 0s - loss: 0.0965 - accuracy: 0.9618 - val_loss: 0.1741 - val_accuracy: 0.9500 - 357ms/epoch - 10ms/step\n",
      "Epoch 169/1000\n",
      "37/37 - 0s - loss: 0.0989 - accuracy: 0.9661 - val_loss: 0.1508 - val_accuracy: 0.9400 - 352ms/epoch - 10ms/step\n",
      "Epoch 170/1000\n",
      "37/37 - 0s - loss: 0.0861 - accuracy: 0.9644 - val_loss: 0.2061 - val_accuracy: 0.9200 - 349ms/epoch - 9ms/step\n",
      "Epoch 171/1000\n",
      "37/37 - 0s - loss: 0.1157 - accuracy: 0.9559 - val_loss: 0.1932 - val_accuracy: 0.9100 - 351ms/epoch - 9ms/step\n",
      "Epoch 172/1000\n",
      "37/37 - 0s - loss: 0.0892 - accuracy: 0.9644 - val_loss: 0.1553 - val_accuracy: 0.9400 - 344ms/epoch - 9ms/step\n",
      "Epoch 173/1000\n",
      "37/37 - 0s - loss: 0.0878 - accuracy: 0.9635 - val_loss: 0.1901 - val_accuracy: 0.9300 - 353ms/epoch - 10ms/step\n",
      "Epoch 174/1000\n",
      "37/37 - 0s - loss: 0.0892 - accuracy: 0.9678 - val_loss: 0.1295 - val_accuracy: 0.9500 - 366ms/epoch - 10ms/step\n",
      "Epoch 175/1000\n",
      "37/37 - 0s - loss: 0.0921 - accuracy: 0.9584 - val_loss: 0.1795 - val_accuracy: 0.9400 - 360ms/epoch - 10ms/step\n",
      "Epoch 176/1000\n",
      "37/37 - 0s - loss: 0.0951 - accuracy: 0.9695 - val_loss: 0.2087 - val_accuracy: 0.9200 - 351ms/epoch - 9ms/step\n",
      "Epoch 177/1000\n",
      "37/37 - 0s - loss: 0.0919 - accuracy: 0.9661 - val_loss: 0.1987 - val_accuracy: 0.9200 - 352ms/epoch - 10ms/step\n",
      "Epoch 178/1000\n",
      "37/37 - 0s - loss: 0.0987 - accuracy: 0.9661 - val_loss: 0.1591 - val_accuracy: 0.9400 - 355ms/epoch - 10ms/step\n",
      "Epoch 179/1000\n",
      "37/37 - 0s - loss: 0.0870 - accuracy: 0.9686 - val_loss: 0.1805 - val_accuracy: 0.9400 - 363ms/epoch - 10ms/step\n",
      "Epoch 180/1000\n",
      "37/37 - 0s - loss: 0.0864 - accuracy: 0.9652 - val_loss: 0.1677 - val_accuracy: 0.9400 - 366ms/epoch - 10ms/step\n",
      "Epoch 181/1000\n",
      "37/37 - 0s - loss: 0.0871 - accuracy: 0.9695 - val_loss: 0.1426 - val_accuracy: 0.9500 - 352ms/epoch - 10ms/step\n",
      "Epoch 182/1000\n",
      "37/37 - 0s - loss: 0.0795 - accuracy: 0.9678 - val_loss: 0.1548 - val_accuracy: 0.9400 - 352ms/epoch - 10ms/step\n",
      "Epoch 183/1000\n",
      "37/37 - 0s - loss: 0.0840 - accuracy: 0.9678 - val_loss: 0.1940 - val_accuracy: 0.9400 - 357ms/epoch - 10ms/step\n",
      "Epoch 184/1000\n",
      "37/37 - 0s - loss: 0.0942 - accuracy: 0.9627 - val_loss: 0.1591 - val_accuracy: 0.9500 - 352ms/epoch - 10ms/step\n",
      "Epoch 185/1000\n",
      "37/37 - 0s - loss: 0.0992 - accuracy: 0.9584 - val_loss: 0.1718 - val_accuracy: 0.9300 - 351ms/epoch - 9ms/step\n",
      "Epoch 186/1000\n",
      "37/37 - 0s - loss: 0.1058 - accuracy: 0.9534 - val_loss: 0.1951 - val_accuracy: 0.9300 - 354ms/epoch - 10ms/step\n",
      "Epoch 187/1000\n",
      "37/37 - 0s - loss: 0.0744 - accuracy: 0.9695 - val_loss: 0.2566 - val_accuracy: 0.9100 - 361ms/epoch - 10ms/step\n",
      "Epoch 188/1000\n",
      "37/37 - 0s - loss: 0.0799 - accuracy: 0.9712 - val_loss: 0.2362 - val_accuracy: 0.9200 - 385ms/epoch - 10ms/step\n",
      "Epoch 189/1000\n",
      "37/37 - 0s - loss: 0.0876 - accuracy: 0.9695 - val_loss: 0.1553 - val_accuracy: 0.9400 - 369ms/epoch - 10ms/step\n",
      "Epoch 190/1000\n",
      "37/37 - 0s - loss: 0.0806 - accuracy: 0.9678 - val_loss: 0.2262 - val_accuracy: 0.9200 - 388ms/epoch - 10ms/step\n",
      "Epoch 191/1000\n",
      "37/37 - 0s - loss: 0.0800 - accuracy: 0.9695 - val_loss: 0.2168 - val_accuracy: 0.9200 - 372ms/epoch - 10ms/step\n",
      "Epoch 192/1000\n",
      "37/37 - 0s - loss: 0.0857 - accuracy: 0.9644 - val_loss: 0.2913 - val_accuracy: 0.9100 - 378ms/epoch - 10ms/step\n",
      "Epoch 193/1000\n",
      "37/37 - 0s - loss: 0.0882 - accuracy: 0.9669 - val_loss: 0.1773 - val_accuracy: 0.9300 - 356ms/epoch - 10ms/step\n",
      "Epoch 194/1000\n",
      "37/37 - 0s - loss: 0.0923 - accuracy: 0.9678 - val_loss: 0.2288 - val_accuracy: 0.9100 - 366ms/epoch - 10ms/step\n",
      "Epoch 195/1000\n",
      "37/37 - 0s - loss: 0.0861 - accuracy: 0.9652 - val_loss: 0.2538 - val_accuracy: 0.9100 - 400ms/epoch - 11ms/step\n",
      "Epoch 196/1000\n",
      "37/37 - 0s - loss: 0.0926 - accuracy: 0.9652 - val_loss: 0.1894 - val_accuracy: 0.9300 - 352ms/epoch - 10ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 197/1000\n",
      "37/37 - 0s - loss: 0.0951 - accuracy: 0.9635 - val_loss: 0.1131 - val_accuracy: 0.9600 - 379ms/epoch - 10ms/step\n",
      "Epoch 198/1000\n",
      "37/37 - 0s - loss: 0.0788 - accuracy: 0.9678 - val_loss: 0.1903 - val_accuracy: 0.9300 - 369ms/epoch - 10ms/step\n",
      "Epoch 199/1000\n",
      "37/37 - 0s - loss: 0.0968 - accuracy: 0.9610 - val_loss: 0.1736 - val_accuracy: 0.9400 - 360ms/epoch - 10ms/step\n",
      "Epoch 200/1000\n",
      "37/37 - 0s - loss: 0.0773 - accuracy: 0.9695 - val_loss: 0.2126 - val_accuracy: 0.9100 - 394ms/epoch - 11ms/step\n",
      "Epoch 201/1000\n",
      "37/37 - 0s - loss: 0.0869 - accuracy: 0.9644 - val_loss: 0.1785 - val_accuracy: 0.9400 - 379ms/epoch - 10ms/step\n",
      "Epoch 202/1000\n",
      "37/37 - 0s - loss: 0.0799 - accuracy: 0.9661 - val_loss: 0.1751 - val_accuracy: 0.9400 - 365ms/epoch - 10ms/step\n",
      "Epoch 203/1000\n",
      "37/37 - 0s - loss: 0.0834 - accuracy: 0.9652 - val_loss: 0.1486 - val_accuracy: 0.9400 - 373ms/epoch - 10ms/step\n",
      "Epoch 204/1000\n",
      "37/37 - 0s - loss: 0.0817 - accuracy: 0.9627 - val_loss: 0.1885 - val_accuracy: 0.9300 - 399ms/epoch - 11ms/step\n",
      "Epoch 205/1000\n",
      "37/37 - 0s - loss: 0.0963 - accuracy: 0.9635 - val_loss: 0.1384 - val_accuracy: 0.9600 - 371ms/epoch - 10ms/step\n",
      "Epoch 206/1000\n",
      "37/37 - 0s - loss: 0.0854 - accuracy: 0.9652 - val_loss: 0.2239 - val_accuracy: 0.9200 - 362ms/epoch - 10ms/step\n",
      "Epoch 207/1000\n",
      "37/37 - 0s - loss: 0.0951 - accuracy: 0.9661 - val_loss: 0.2338 - val_accuracy: 0.9100 - 367ms/epoch - 10ms/step\n",
      "Epoch 208/1000\n",
      "37/37 - 0s - loss: 0.1082 - accuracy: 0.9550 - val_loss: 0.1621 - val_accuracy: 0.9600 - 386ms/epoch - 10ms/step\n",
      "Epoch 209/1000\n",
      "37/37 - 0s - loss: 0.1011 - accuracy: 0.9593 - val_loss: 0.1627 - val_accuracy: 0.9300 - 387ms/epoch - 10ms/step\n",
      "Epoch 210/1000\n",
      "37/37 - 0s - loss: 0.0771 - accuracy: 0.9669 - val_loss: 0.2384 - val_accuracy: 0.9100 - 374ms/epoch - 10ms/step\n",
      "Epoch 211/1000\n",
      "37/37 - 0s - loss: 0.0802 - accuracy: 0.9661 - val_loss: 0.1586 - val_accuracy: 0.9400 - 372ms/epoch - 10ms/step\n",
      "Epoch 212/1000\n",
      "37/37 - 0s - loss: 0.0834 - accuracy: 0.9652 - val_loss: 0.1832 - val_accuracy: 0.9300 - 388ms/epoch - 10ms/step\n",
      "Epoch 213/1000\n",
      "37/37 - 0s - loss: 0.0878 - accuracy: 0.9635 - val_loss: 0.1825 - val_accuracy: 0.9400 - 385ms/epoch - 10ms/step\n",
      "Epoch 214/1000\n",
      "37/37 - 0s - loss: 0.0714 - accuracy: 0.9720 - val_loss: 0.1476 - val_accuracy: 0.9400 - 387ms/epoch - 10ms/step\n",
      "Epoch 215/1000\n",
      "37/37 - 0s - loss: 0.0790 - accuracy: 0.9669 - val_loss: 0.1610 - val_accuracy: 0.9500 - 363ms/epoch - 10ms/step\n",
      "Epoch 216/1000\n",
      "37/37 - 0s - loss: 0.0898 - accuracy: 0.9627 - val_loss: 0.2631 - val_accuracy: 0.9000 - 340ms/epoch - 9ms/step\n",
      "Epoch 217/1000\n",
      "37/37 - 0s - loss: 0.0984 - accuracy: 0.9584 - val_loss: 0.2041 - val_accuracy: 0.9400 - 359ms/epoch - 10ms/step\n",
      "Epoch 218/1000\n",
      "37/37 - 0s - loss: 0.0836 - accuracy: 0.9644 - val_loss: 0.1720 - val_accuracy: 0.9300 - 366ms/epoch - 10ms/step\n",
      "Epoch 219/1000\n",
      "37/37 - 0s - loss: 0.0677 - accuracy: 0.9771 - val_loss: 0.1705 - val_accuracy: 0.9400 - 365ms/epoch - 10ms/step\n",
      "Epoch 220/1000\n",
      "37/37 - 0s - loss: 0.0758 - accuracy: 0.9695 - val_loss: 0.1558 - val_accuracy: 0.9400 - 365ms/epoch - 10ms/step\n",
      "Epoch 221/1000\n",
      "37/37 - 0s - loss: 0.0925 - accuracy: 0.9635 - val_loss: 0.2348 - val_accuracy: 0.9300 - 368ms/epoch - 10ms/step\n",
      "Epoch 222/1000\n",
      "37/37 - 0s - loss: 0.0852 - accuracy: 0.9661 - val_loss: 0.1653 - val_accuracy: 0.9400 - 369ms/epoch - 10ms/step\n",
      "Epoch 223/1000\n",
      "37/37 - 0s - loss: 0.0709 - accuracy: 0.9763 - val_loss: 0.1392 - val_accuracy: 0.9500 - 350ms/epoch - 9ms/step\n",
      "Epoch 224/1000\n",
      "37/37 - 0s - loss: 0.0713 - accuracy: 0.9712 - val_loss: 0.1844 - val_accuracy: 0.9300 - 345ms/epoch - 9ms/step\n",
      "Epoch 225/1000\n",
      "37/37 - 0s - loss: 0.0808 - accuracy: 0.9635 - val_loss: 0.1834 - val_accuracy: 0.9300 - 375ms/epoch - 10ms/step\n",
      "Epoch 226/1000\n",
      "37/37 - 0s - loss: 0.0801 - accuracy: 0.9627 - val_loss: 0.1311 - val_accuracy: 0.9500 - 369ms/epoch - 10ms/step\n",
      "Epoch 227/1000\n",
      "37/37 - 0s - loss: 0.0883 - accuracy: 0.9661 - val_loss: 0.1666 - val_accuracy: 0.9300 - 386ms/epoch - 10ms/step\n",
      "Epoch 228/1000\n",
      "37/37 - 0s - loss: 0.1086 - accuracy: 0.9627 - val_loss: 0.2473 - val_accuracy: 0.9100 - 355ms/epoch - 10ms/step\n",
      "Epoch 229/1000\n",
      "37/37 - 0s - loss: 0.0737 - accuracy: 0.9720 - val_loss: 0.1496 - val_accuracy: 0.9500 - 381ms/epoch - 10ms/step\n",
      "Epoch 230/1000\n",
      "37/37 - 0s - loss: 0.0636 - accuracy: 0.9729 - val_loss: 0.1965 - val_accuracy: 0.9400 - 372ms/epoch - 10ms/step\n",
      "Epoch 231/1000\n",
      "37/37 - 0s - loss: 0.0796 - accuracy: 0.9669 - val_loss: 0.1742 - val_accuracy: 0.9400 - 385ms/epoch - 10ms/step\n",
      "Epoch 232/1000\n",
      "37/37 - 0s - loss: 0.0851 - accuracy: 0.9686 - val_loss: 0.1440 - val_accuracy: 0.9400 - 392ms/epoch - 11ms/step\n",
      "Epoch 233/1000\n",
      "37/37 - 0s - loss: 0.0732 - accuracy: 0.9661 - val_loss: 0.2588 - val_accuracy: 0.9000 - 359ms/epoch - 10ms/step\n",
      "Epoch 234/1000\n",
      "37/37 - 0s - loss: 0.0768 - accuracy: 0.9729 - val_loss: 0.2379 - val_accuracy: 0.9200 - 353ms/epoch - 10ms/step\n",
      "Epoch 235/1000\n",
      "37/37 - 0s - loss: 0.0777 - accuracy: 0.9703 - val_loss: 0.1143 - val_accuracy: 0.9500 - 380ms/epoch - 10ms/step\n",
      "Epoch 236/1000\n",
      "37/37 - 0s - loss: 0.0996 - accuracy: 0.9635 - val_loss: 0.1855 - val_accuracy: 0.9400 - 387ms/epoch - 10ms/step\n",
      "Epoch 237/1000\n",
      "37/37 - 0s - loss: 0.0886 - accuracy: 0.9635 - val_loss: 0.1874 - val_accuracy: 0.9300 - 396ms/epoch - 11ms/step\n",
      "Epoch 238/1000\n",
      "37/37 - 0s - loss: 0.0674 - accuracy: 0.9746 - val_loss: 0.1736 - val_accuracy: 0.9400 - 437ms/epoch - 12ms/step\n",
      "Epoch 239/1000\n",
      "37/37 - 0s - loss: 0.0726 - accuracy: 0.9703 - val_loss: 0.1848 - val_accuracy: 0.9200 - 401ms/epoch - 11ms/step\n",
      "Epoch 240/1000\n",
      "37/37 - 0s - loss: 0.0720 - accuracy: 0.9703 - val_loss: 0.1548 - val_accuracy: 0.9400 - 382ms/epoch - 10ms/step\n",
      "Epoch 241/1000\n",
      "37/37 - 0s - loss: 0.0731 - accuracy: 0.9729 - val_loss: 0.1825 - val_accuracy: 0.9400 - 390ms/epoch - 11ms/step\n",
      "Epoch 242/1000\n",
      "37/37 - 0s - loss: 0.0639 - accuracy: 0.9712 - val_loss: 0.1543 - val_accuracy: 0.9400 - 407ms/epoch - 11ms/step\n",
      "Epoch 243/1000\n",
      "37/37 - 0s - loss: 0.0707 - accuracy: 0.9712 - val_loss: 0.1230 - val_accuracy: 0.9600 - 393ms/epoch - 11ms/step\n",
      "Epoch 244/1000\n",
      "37/37 - 0s - loss: 0.0728 - accuracy: 0.9720 - val_loss: 0.1642 - val_accuracy: 0.9400 - 396ms/epoch - 11ms/step\n",
      "Epoch 245/1000\n",
      "37/37 - 0s - loss: 0.0792 - accuracy: 0.9703 - val_loss: 0.2040 - val_accuracy: 0.9200 - 395ms/epoch - 11ms/step\n",
      "Epoch 246/1000\n",
      "37/37 - 0s - loss: 0.0892 - accuracy: 0.9695 - val_loss: 0.1653 - val_accuracy: 0.9500 - 385ms/epoch - 10ms/step\n",
      "Epoch 247/1000\n",
      "37/37 - 0s - loss: 0.0788 - accuracy: 0.9703 - val_loss: 0.1503 - val_accuracy: 0.9500 - 384ms/epoch - 10ms/step\n",
      "Epoch 00247: early stopping\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 385, 32)           288       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 192, 32)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 192, 32)           0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6144)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               786560    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 786,977\n",
      "Trainable params: 786,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    verbose=2,\n",
    "    validation_data=(evals_X, evals_y),\n",
    "    batch_size=32,\n",
    "    callbacks=[es]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d1f3cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (etsy)",
   "language": "python",
   "name": "etsy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
