{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abc48fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "#load inthe NTLK stopwords to remove articles, preposition and other words that are not actionable\n",
    "from nltk.corpus import stopwords\n",
    "# This allows to create individual objects from a bog of words\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "# Lemmatizer helps to reduce words to the base form\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f5cae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_eda=pd.read_csv('eda_np.txt', sep=\"\\t\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6a73888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29ebda21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/jasmineli/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jasmineli/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/jasmineli/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('summer-products-with-rating-and-performance_2020-08.csv')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b8a0cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sentence(sentence):\n",
    "    new_tokens = word_tokenize(sentence)\n",
    "    new_tokens = [t.lower() for t in new_tokens]\n",
    "    new_tokens =[t for t in new_tokens if t not in stopwords.words('english')]\n",
    "    new_tokens = [t for t in new_tokens if t.isalpha()]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    new_tokens =[lemmatizer.lemmatize(t) for t in new_tokens]\n",
    "    # return \" \".join(new_tokens), len(new_tokens)\n",
    "    return \" \".join(new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0d31ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['tags_pre'] = df['tags'].apply(lambda x: x.replace(',', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a880c2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = df['title_orig'].tolist()\n",
    "# results = [process_sentence(t) for t in titles]\n",
    "tokens = [process_sentence(t) for t in titles]\n",
    "# tokens, length = zip(*results)\n",
    "df['title_pre'] = tokens\n",
    "# df['title_len'] = df['title_pre'].str.split(\" \").str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "000686a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['title_len', 'units_sold']].sort_values(by='units_sold', ascending=False).head(10).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17c1639f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['title_len', 'units_sold']].sort_values(by='units_sold', ascending=False).tail(10).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b65cd8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tags = df['tags_pre'].tolist()\n",
    "# results = [process_sentence(t) for t in tags]\n",
    "# tokens, length = zip(*results)\n",
    "# df['tags_pre'] = tokens\n",
    "# df['tags_num'] = length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f6bfba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['tags_num', 'units_sold']].sort_values(by='units_sold', ascending=False).head(30).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9e15cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['tags_num', 'units_sold']].sort_values(by='units_sold', ascending=False).tail(30).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5a29e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(df['title_pre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "775d0a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasmineli/opt/anaconda3/envs/etsy/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "tfidf = pd.DataFrame(denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6e4b0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absorbing</th>\n",
       "      <th>accessory</th>\n",
       "      <th>active</th>\n",
       "      <th>activewear</th>\n",
       "      <th>activity</th>\n",
       "      <th>acute</th>\n",
       "      <th>adhesive</th>\n",
       "      <th>adjustable</th>\n",
       "      <th>aeeival</th>\n",
       "      <th>african</th>\n",
       "      <th>...</th>\n",
       "      <th>yoga</th>\n",
       "      <th>youth</th>\n",
       "      <th>zanzea</th>\n",
       "      <th>zapatillas</th>\n",
       "      <th>zapatos</th>\n",
       "      <th>zapper</th>\n",
       "      <th>ziper</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zm</th>\n",
       "      <th>übergröße</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.260621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1573 rows × 1171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      absorbing  accessory  active  activewear  activity  acute  adhesive  \\\n",
       "0           0.0        0.0     0.0         0.0       0.0    0.0       0.0   \n",
       "1           0.0        0.0     0.0         0.0       0.0    0.0       0.0   \n",
       "2           0.0        0.0     0.0         0.0       0.0    0.0       0.0   \n",
       "3           0.0        0.0     0.0         0.0       0.0    0.0       0.0   \n",
       "4           0.0        0.0     0.0         0.0       0.0    0.0       0.0   \n",
       "...         ...        ...     ...         ...       ...    ...       ...   \n",
       "1568        0.0        0.0     0.0         0.0       0.0    0.0       0.0   \n",
       "1569        0.0        0.0     0.0         0.0       0.0    0.0       0.0   \n",
       "1570        0.0        0.0     0.0         0.0       0.0    0.0       0.0   \n",
       "1571        0.0        0.0     0.0         0.0       0.0    0.0       0.0   \n",
       "1572        0.0        0.0     0.0         0.0       0.0    0.0       0.0   \n",
       "\n",
       "      adjustable  aeeival  african  ...      yoga  youth  zanzea  zapatillas  \\\n",
       "0            0.0      0.0      0.0  ...  0.000000    0.0     0.0         0.0   \n",
       "1            0.0      0.0      0.0  ...  0.000000    0.0     0.0         0.0   \n",
       "2            0.0      0.0      0.0  ...  0.000000    0.0     0.0         0.0   \n",
       "3            0.0      0.0      0.0  ...  0.000000    0.0     0.0         0.0   \n",
       "4            0.0      0.0      0.0  ...  0.000000    0.0     0.0         0.0   \n",
       "...          ...      ...      ...  ...       ...    ...     ...         ...   \n",
       "1568         0.0      0.0      0.0  ...  0.260621    0.0     0.0         0.0   \n",
       "1569         0.0      0.0      0.0  ...  0.000000    0.0     0.0         0.0   \n",
       "1570         0.0      0.0      0.0  ...  0.000000    0.0     0.0         0.0   \n",
       "1571         0.0      0.0      0.0  ...  0.000000    0.0     0.0         0.0   \n",
       "1572         0.0      0.0      0.0  ...  0.387433    0.0     0.0         0.0   \n",
       "\n",
       "      zapatos  zapper  ziper  zipper   zm  übergröße  \n",
       "0         0.0     0.0    0.0     0.0  0.0        0.0  \n",
       "1         0.0     0.0    0.0     0.0  0.0        0.0  \n",
       "2         0.0     0.0    0.0     0.0  0.0        0.0  \n",
       "3         0.0     0.0    0.0     0.0  0.0        0.0  \n",
       "4         0.0     0.0    0.0     0.0  0.0        0.0  \n",
       "...       ...     ...    ...     ...  ...        ...  \n",
       "1568      0.0     0.0    0.0     0.0  0.0        0.0  \n",
       "1569      0.0     0.0    0.0     0.0  0.0        0.0  \n",
       "1570      0.0     0.0    0.0     0.0  0.0        0.0  \n",
       "1571      0.0     0.0    0.0     0.0  0.0        0.0  \n",
       "1572      0.0     0.0    0.0     0.0  0.0        0.0  \n",
       "\n",
       "[1573 rows x 1171 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b55dca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = TfidfVectorizer()\n",
    "# vectors = vectorizer.fit_transform(df['tags_pre'])\n",
    "# feature_names = vectorizer.get_feature_names()\n",
    "# dense = vectors.todense()\n",
    "# denselist = dense.tolist()\n",
    "# tfidf_tag = pd.DataFrame(denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc8156d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasmineli/opt/anaconda3/envs/etsy/lib/python3.7/site-packages/pandas/core/series.py:726: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# product color\n",
    "def main_color(s):\n",
    "    main_color = {\"red\":\"red\", \"white\":\"white\", \"pink\":\"pink\", \"yellow\":\"yellow\", \"green\":\"green\", \"blue\":\"blue\", \"wine\":\"red\", \"burgundy\":\"red\", \"black\":\"black\", \"navy\":\"navy\", \"orange\":\"orange\", \n",
    "    \"rose\":\"pink\", \"gray\":\"gray\", \"grey\":\"gray\", \"purple\":\"purple\", \"violet\":\"purple\", \"army\":\"green\", \"leopard\":\"orange\", \"ivory\":\"white\", \n",
    "    \"brown\":\"brown\", \"coffee\":\"brown\", \"camel\":\"beige\", \"tan\":\"brown\", \"nude\":\"beige\", \"khaki\":\"khaki\", \"apricot\":\"yellow\", \"camouflage\":\"green\", \"jasper\":\"red\"}  # ordered by importance\n",
    "    for key, value in main_color.items():\n",
    "        if key in s:\n",
    "            return value\n",
    "    return \"others\"\n",
    "product_color = df[\"product_color\"]\n",
    "product_color = [s.lower() if type(s) is str else 'nan' for s in product_color]\n",
    "product_color = [main_color(s) for s in product_color]\n",
    "from matplotlib import colors\n",
    "product_color = [(-0.1,-0.1,-0.1,-0.1) if s == \"others\" else colors.to_rgba(s) for s in product_color]\n",
    "\n",
    "df['product_color_rgb'] = [np.array(t) for t in product_color]\n",
    "\n",
    "# log prices\n",
    "df['log_price'] = [np.log(p) for p in df[\"price\"]]\n",
    "df['log_retail_price'] = [np.log(p) for p in df[\"retail_price\"]]\n",
    "\n",
    "# log merchant rating count\n",
    "df['log_merchant_rating_count'] = np.log(df['merchant_rating_count'])\n",
    "\n",
    "# urgent text\n",
    "df['urgent'] = [1 if s == \"Quantité limitée !\" else 0 for s in df[\"urgency_text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02d69257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    925\n",
      "0    648\n",
      "Name: high_sale, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = df[[\"log_price\", \"log_retail_price\", \"uses_ad_boosts\", \"badges_count\", \"badge_local_product\", \n",
    "           \"badge_product_quality\", \"badge_fast_shipping\", \"urgent\", \"units_sold\"]]\n",
    "df2 = pd.concat([data, tfidf], axis=1)\n",
    "label = [1 if sales > 100 else 0 for sales in data[\"units_sold\"]]\n",
    "df2['high_sale'] = label\n",
    "print(df2['high_sale'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94f48cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1573, 1185)\n"
     ]
    }
   ],
   "source": [
    "rgb = df[\"product_color_rgb\"]\n",
    "rgb = np.stack(rgb.values, axis=0)\n",
    "for i in range(4):\n",
    "    df2[\"product_color_rgb\"+str(i)] = rgb[:,i]\n",
    "df2.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44d3fb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2.loc[:, ~df2.columns.isin(['high_sale', 'units_sold'])]\n",
    "# X = tfidf\n",
    "y = df2['high_sale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e9e81f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from keras.layers import Input, Dense, Concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.125, random_state=42)\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, test_size=0.14286, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1fa30b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 1179\n",
      "number of dev examples = 197\n",
      "number of test examples = 197\n",
      "X_train shape: (1179, 1183)\n",
      "Y_train shape: (1179,)\n",
      "X_dev shape: (197, 1183)\n",
      "Y_dev shape: (197,)\n",
      "X_test shape: (197, 1183)\n",
      "Y_test shape: (197,)\n"
     ]
    }
   ],
   "source": [
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of dev examples = \" + str(X_dev.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(y_train.shape))\n",
    "print (\"X_dev shape: \" + str(X_dev.shape))\n",
    "print (\"Y_dev shape: \" + str(y_dev.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f080968",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.expand_dims(X_train, axis=-1)\n",
    "X_dev = tf.expand_dims(X_dev, axis=-1)\n",
    "input_shape = X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55ab87a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1183, 1)\n"
     ]
    }
   ],
   "source": [
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "231c0ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# classifier = LogisticRegression()\n",
    "# classifier.fit(X_train, y_train)\n",
    "\n",
    "# score = classifier.score(evals_X, evals_y)\n",
    "\n",
    "# print(\"Accuracy:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68feb235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import AveragePooling1D, PReLU, LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d313196d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=24, kernel_size=8, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer='l2'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fcb4c14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='accuracy', mode='max', verbose=1, patience=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be38e41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "WARNING:tensorflow:Layer conv1d is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "74/74 - 1s - loss: 0.9045 - accuracy: 0.4343 - val_loss: 0.6610 - val_accuracy: 0.3655\n",
      "Epoch 2/1000\n",
      "74/74 - 1s - loss: 0.6854 - accuracy: 0.4385 - val_loss: 0.6635 - val_accuracy: 0.4213\n",
      "Epoch 3/1000\n",
      "74/74 - 1s - loss: 0.6848 - accuracy: 0.4207 - val_loss: 0.6623 - val_accuracy: 0.3655\n",
      "Epoch 4/1000\n",
      "74/74 - 1s - loss: 0.6852 - accuracy: 0.4173 - val_loss: 0.6697 - val_accuracy: 0.3655\n",
      "Epoch 5/1000\n",
      "74/74 - 1s - loss: 0.6859 - accuracy: 0.4173 - val_loss: 0.6955 - val_accuracy: 0.3655\n",
      "Epoch 6/1000\n",
      "74/74 - 1s - loss: 0.6864 - accuracy: 0.4173 - val_loss: 0.6708 - val_accuracy: 0.3655\n",
      "Epoch 7/1000\n",
      "74/74 - 2s - loss: 0.6890 - accuracy: 0.4173 - val_loss: 0.6751 - val_accuracy: 0.3655\n",
      "Epoch 8/1000\n",
      "74/74 - 1s - loss: 0.6867 - accuracy: 0.4173 - val_loss: 0.6673 - val_accuracy: 0.3655\n",
      "Epoch 9/1000\n",
      "74/74 - 2s - loss: 0.6856 - accuracy: 0.4173 - val_loss: 0.6637 - val_accuracy: 0.3655\n",
      "Epoch 10/1000\n",
      "74/74 - 2s - loss: 0.6859 - accuracy: 0.4173 - val_loss: 0.6687 - val_accuracy: 0.3655\n",
      "Epoch 11/1000\n",
      "74/74 - 2s - loss: 0.6879 - accuracy: 0.4173 - val_loss: 0.6715 - val_accuracy: 0.3655\n",
      "Epoch 12/1000\n",
      "74/74 - 2s - loss: 0.6881 - accuracy: 0.4173 - val_loss: 0.6706 - val_accuracy: 0.3655\n",
      "Epoch 13/1000\n",
      "74/74 - 2s - loss: 0.6869 - accuracy: 0.4173 - val_loss: 0.6663 - val_accuracy: 0.3655\n",
      "Epoch 14/1000\n",
      "74/74 - 2s - loss: 0.6897 - accuracy: 0.4173 - val_loss: 0.6682 - val_accuracy: 0.3655\n",
      "Epoch 15/1000\n",
      "74/74 - 2s - loss: 0.6893 - accuracy: 0.4173 - val_loss: 0.6734 - val_accuracy: 0.3655\n",
      "Epoch 16/1000\n",
      "74/74 - 2s - loss: 0.6898 - accuracy: 0.4173 - val_loss: 0.6729 - val_accuracy: 0.3655\n",
      "Epoch 17/1000\n",
      "74/74 - 2s - loss: 0.6896 - accuracy: 0.4173 - val_loss: 0.6823 - val_accuracy: 0.3655\n",
      "Epoch 18/1000\n",
      "74/74 - 2s - loss: 0.6895 - accuracy: 0.4173 - val_loss: 0.6748 - val_accuracy: 0.3655\n",
      "Epoch 19/1000\n",
      "74/74 - 2s - loss: 0.6907 - accuracy: 0.4343 - val_loss: 0.6711 - val_accuracy: 0.4365\n",
      "Epoch 20/1000\n",
      "74/74 - 2s - loss: 0.6895 - accuracy: 0.4758 - val_loss: 0.6778 - val_accuracy: 0.3655\n",
      "Epoch 21/1000\n",
      "74/74 - 2s - loss: 0.6908 - accuracy: 0.4826 - val_loss: 0.6773 - val_accuracy: 0.3706\n",
      "Epoch 22/1000\n",
      "74/74 - 2s - loss: 0.6912 - accuracy: 0.4699 - val_loss: 0.6716 - val_accuracy: 0.4061\n",
      "Epoch 23/1000\n",
      "74/74 - 2s - loss: 0.6895 - accuracy: 0.4750 - val_loss: 0.6764 - val_accuracy: 0.4975\n",
      "Epoch 24/1000\n",
      "74/74 - 2s - loss: 0.6874 - accuracy: 0.4902 - val_loss: 0.6754 - val_accuracy: 0.3553\n",
      "Epoch 25/1000\n",
      "74/74 - 2s - loss: 0.6894 - accuracy: 0.5030 - val_loss: 0.6861 - val_accuracy: 0.3807\n",
      "Epoch 26/1000\n",
      "74/74 - 2s - loss: 0.6903 - accuracy: 0.4885 - val_loss: 0.6721 - val_accuracy: 0.4518\n",
      "Epoch 27/1000\n",
      "74/74 - 2s - loss: 0.6873 - accuracy: 0.5030 - val_loss: 0.6717 - val_accuracy: 0.4822\n",
      "Epoch 28/1000\n",
      "74/74 - 2s - loss: 0.6877 - accuracy: 0.5250 - val_loss: 0.6769 - val_accuracy: 0.4061\n",
      "Epoch 29/1000\n",
      "74/74 - 2s - loss: 0.6870 - accuracy: 0.5140 - val_loss: 0.6695 - val_accuracy: 0.5431\n",
      "Epoch 30/1000\n",
      "74/74 - 2s - loss: 0.6871 - accuracy: 0.5352 - val_loss: 0.6723 - val_accuracy: 0.5127\n",
      "Epoch 31/1000\n",
      "74/74 - 2s - loss: 0.6853 - accuracy: 0.5462 - val_loss: 0.6772 - val_accuracy: 0.4518\n",
      "Epoch 32/1000\n",
      "74/74 - 2s - loss: 0.6851 - accuracy: 0.5462 - val_loss: 0.6708 - val_accuracy: 0.4924\n",
      "Epoch 33/1000\n",
      "74/74 - 2s - loss: 0.6857 - accuracy: 0.5420 - val_loss: 0.6791 - val_accuracy: 0.4365\n",
      "Epoch 34/1000\n",
      "74/74 - 2s - loss: 0.6862 - accuracy: 0.5496 - val_loss: 0.6701 - val_accuracy: 0.5076\n",
      "Epoch 35/1000\n",
      "74/74 - 2s - loss: 0.6818 - accuracy: 0.5666 - val_loss: 0.6717 - val_accuracy: 0.4670\n",
      "Epoch 36/1000\n",
      "74/74 - 2s - loss: 0.6841 - accuracy: 0.5640 - val_loss: 0.6645 - val_accuracy: 0.5482\n",
      "Epoch 37/1000\n",
      "74/74 - 2s - loss: 0.6812 - accuracy: 0.5725 - val_loss: 0.6698 - val_accuracy: 0.6041\n",
      "Epoch 38/1000\n",
      "74/74 - 2s - loss: 0.6824 - accuracy: 0.5598 - val_loss: 0.6666 - val_accuracy: 0.5787\n",
      "Epoch 39/1000\n",
      "74/74 - 2s - loss: 0.6814 - accuracy: 0.5742 - val_loss: 0.6590 - val_accuracy: 0.5838\n",
      "Epoch 40/1000\n",
      "74/74 - 2s - loss: 0.6786 - accuracy: 0.5920 - val_loss: 0.6692 - val_accuracy: 0.5635\n",
      "Epoch 41/1000\n",
      "74/74 - 2s - loss: 0.6768 - accuracy: 0.6022 - val_loss: 0.6638 - val_accuracy: 0.6345\n",
      "Epoch 42/1000\n",
      "74/74 - 2s - loss: 0.6774 - accuracy: 0.6064 - val_loss: 0.6691 - val_accuracy: 0.4975\n",
      "Epoch 43/1000\n",
      "74/74 - 2s - loss: 0.6759 - accuracy: 0.5997 - val_loss: 0.6705 - val_accuracy: 0.6193\n",
      "Epoch 44/1000\n",
      "74/74 - 2s - loss: 0.6781 - accuracy: 0.5954 - val_loss: 0.6674 - val_accuracy: 0.6041\n",
      "Epoch 45/1000\n",
      "74/74 - 2s - loss: 0.6745 - accuracy: 0.6200 - val_loss: 0.6894 - val_accuracy: 0.4010\n",
      "Epoch 46/1000\n",
      "74/74 - 2s - loss: 0.6744 - accuracy: 0.6141 - val_loss: 0.6734 - val_accuracy: 0.4619\n",
      "Epoch 47/1000\n",
      "74/74 - 2s - loss: 0.6722 - accuracy: 0.6192 - val_loss: 0.6661 - val_accuracy: 0.6345\n",
      "Epoch 48/1000\n",
      "74/74 - 2s - loss: 0.6717 - accuracy: 0.6277 - val_loss: 0.6653 - val_accuracy: 0.5736\n",
      "Epoch 49/1000\n",
      "74/74 - 2s - loss: 0.6697 - accuracy: 0.6387 - val_loss: 0.6663 - val_accuracy: 0.5533\n",
      "Epoch 50/1000\n",
      "74/74 - 2s - loss: 0.6689 - accuracy: 0.6446 - val_loss: 0.6606 - val_accuracy: 0.6345\n",
      "Epoch 51/1000\n",
      "74/74 - 2s - loss: 0.6659 - accuracy: 0.6387 - val_loss: 0.6602 - val_accuracy: 0.5888\n",
      "Epoch 52/1000\n",
      "74/74 - 2s - loss: 0.6718 - accuracy: 0.6497 - val_loss: 0.6587 - val_accuracy: 0.6345\n",
      "Epoch 53/1000\n",
      "74/74 - 2s - loss: 0.6670 - accuracy: 0.6404 - val_loss: 0.6565 - val_accuracy: 0.6294\n",
      "Epoch 54/1000\n",
      "74/74 - 2s - loss: 0.6644 - accuracy: 0.6582 - val_loss: 0.6604 - val_accuracy: 0.6244\n",
      "Epoch 55/1000\n",
      "74/74 - 2s - loss: 0.6638 - accuracy: 0.6743 - val_loss: 0.6575 - val_accuracy: 0.6041\n",
      "Epoch 56/1000\n",
      "74/74 - 2s - loss: 0.6607 - accuracy: 0.6845 - val_loss: 0.6602 - val_accuracy: 0.5990\n",
      "Epoch 57/1000\n",
      "74/74 - 2s - loss: 0.6574 - accuracy: 0.6853 - val_loss: 0.6652 - val_accuracy: 0.5533\n",
      "Epoch 58/1000\n",
      "74/74 - 2s - loss: 0.6597 - accuracy: 0.6692 - val_loss: 0.6566 - val_accuracy: 0.6650\n",
      "Epoch 59/1000\n",
      "74/74 - 2s - loss: 0.6591 - accuracy: 0.7023 - val_loss: 0.6595 - val_accuracy: 0.6041\n",
      "Epoch 60/1000\n",
      "74/74 - 2s - loss: 0.6555 - accuracy: 0.6930 - val_loss: 0.6593 - val_accuracy: 0.5939\n",
      "Epoch 61/1000\n",
      "74/74 - 2s - loss: 0.6538 - accuracy: 0.7082 - val_loss: 0.6543 - val_accuracy: 0.6447\n",
      "Epoch 62/1000\n",
      "74/74 - 2s - loss: 0.6530 - accuracy: 0.7057 - val_loss: 0.6530 - val_accuracy: 0.6294\n",
      "Epoch 63/1000\n",
      "74/74 - 2s - loss: 0.6528 - accuracy: 0.7184 - val_loss: 0.6532 - val_accuracy: 0.6396\n",
      "Epoch 64/1000\n",
      "74/74 - 2s - loss: 0.6484 - accuracy: 0.7040 - val_loss: 0.6567 - val_accuracy: 0.6041\n",
      "Epoch 65/1000\n",
      "74/74 - 2s - loss: 0.6507 - accuracy: 0.7159 - val_loss: 0.6617 - val_accuracy: 0.6650\n",
      "Epoch 66/1000\n",
      "74/74 - 2s - loss: 0.6471 - accuracy: 0.7286 - val_loss: 0.6584 - val_accuracy: 0.6142\n",
      "Epoch 67/1000\n",
      "74/74 - 2s - loss: 0.6471 - accuracy: 0.7277 - val_loss: 0.6583 - val_accuracy: 0.6142\n",
      "Epoch 68/1000\n",
      "74/74 - 2s - loss: 0.6423 - accuracy: 0.7489 - val_loss: 0.6539 - val_accuracy: 0.6802\n",
      "Epoch 69/1000\n",
      "74/74 - 2s - loss: 0.6445 - accuracy: 0.7447 - val_loss: 0.6588 - val_accuracy: 0.6244\n",
      "Epoch 70/1000\n",
      "74/74 - 2s - loss: 0.6406 - accuracy: 0.7455 - val_loss: 0.6523 - val_accuracy: 0.6954\n",
      "Epoch 71/1000\n",
      "74/74 - 2s - loss: 0.6421 - accuracy: 0.7464 - val_loss: 0.6647 - val_accuracy: 0.5635\n",
      "Epoch 72/1000\n",
      "74/74 - 2s - loss: 0.6401 - accuracy: 0.7574 - val_loss: 0.6568 - val_accuracy: 0.6244\n",
      "Epoch 73/1000\n",
      "74/74 - 2s - loss: 0.6394 - accuracy: 0.7634 - val_loss: 0.6617 - val_accuracy: 0.6041\n",
      "Epoch 74/1000\n",
      "74/74 - 2s - loss: 0.6389 - accuracy: 0.7506 - val_loss: 0.6536 - val_accuracy: 0.6853\n",
      "Epoch 75/1000\n",
      "74/74 - 2s - loss: 0.6422 - accuracy: 0.7439 - val_loss: 0.6536 - val_accuracy: 0.6802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/1000\n",
      "74/74 - 2s - loss: 0.6347 - accuracy: 0.7727 - val_loss: 0.6505 - val_accuracy: 0.6853\n",
      "Epoch 77/1000\n",
      "74/74 - 2s - loss: 0.6340 - accuracy: 0.7676 - val_loss: 0.6500 - val_accuracy: 0.6853\n",
      "Epoch 78/1000\n",
      "74/74 - 2s - loss: 0.6317 - accuracy: 0.7820 - val_loss: 0.6455 - val_accuracy: 0.6954\n",
      "Epoch 79/1000\n",
      "74/74 - 2s - loss: 0.6326 - accuracy: 0.7786 - val_loss: 0.6500 - val_accuracy: 0.6650\n",
      "Epoch 80/1000\n",
      "74/74 - 2s - loss: 0.6299 - accuracy: 0.7803 - val_loss: 0.6493 - val_accuracy: 0.6751\n",
      "Epoch 81/1000\n",
      "74/74 - 2s - loss: 0.6280 - accuracy: 0.7897 - val_loss: 0.6504 - val_accuracy: 0.6701\n",
      "Epoch 82/1000\n",
      "74/74 - 2s - loss: 0.6241 - accuracy: 0.7956 - val_loss: 0.6594 - val_accuracy: 0.5939\n",
      "Epoch 83/1000\n",
      "74/74 - 2s - loss: 0.6268 - accuracy: 0.7998 - val_loss: 0.6463 - val_accuracy: 0.6802\n",
      "Epoch 84/1000\n",
      "74/74 - 2s - loss: 0.6236 - accuracy: 0.8024 - val_loss: 0.6397 - val_accuracy: 0.6802\n",
      "Epoch 85/1000\n",
      "74/74 - 2s - loss: 0.6224 - accuracy: 0.8015 - val_loss: 0.6468 - val_accuracy: 0.6954\n",
      "Epoch 86/1000\n",
      "74/74 - 2s - loss: 0.6177 - accuracy: 0.8142 - val_loss: 0.6527 - val_accuracy: 0.6193\n",
      "Epoch 87/1000\n",
      "74/74 - 2s - loss: 0.6220 - accuracy: 0.8100 - val_loss: 0.6442 - val_accuracy: 0.6802\n",
      "Epoch 88/1000\n",
      "74/74 - 2s - loss: 0.6222 - accuracy: 0.8041 - val_loss: 0.6449 - val_accuracy: 0.6650\n",
      "Epoch 89/1000\n",
      "74/74 - 2s - loss: 0.6185 - accuracy: 0.7964 - val_loss: 0.6483 - val_accuracy: 0.6599\n",
      "Epoch 90/1000\n",
      "74/74 - 2s - loss: 0.6208 - accuracy: 0.8092 - val_loss: 0.6461 - val_accuracy: 0.6497\n",
      "Epoch 91/1000\n",
      "74/74 - 2s - loss: 0.6151 - accuracy: 0.8202 - val_loss: 0.6467 - val_accuracy: 0.6650\n",
      "Epoch 92/1000\n",
      "74/74 - 2s - loss: 0.6146 - accuracy: 0.8253 - val_loss: 0.6493 - val_accuracy: 0.6396\n",
      "Epoch 93/1000\n",
      "74/74 - 2s - loss: 0.6146 - accuracy: 0.8244 - val_loss: 0.6400 - val_accuracy: 0.6954\n",
      "Epoch 94/1000\n",
      "74/74 - 2s - loss: 0.6145 - accuracy: 0.8193 - val_loss: 0.6510 - val_accuracy: 0.6599\n",
      "Epoch 95/1000\n",
      "74/74 - 2s - loss: 0.6166 - accuracy: 0.8126 - val_loss: 0.6418 - val_accuracy: 0.7310\n",
      "Epoch 96/1000\n",
      "74/74 - 2s - loss: 0.6164 - accuracy: 0.8083 - val_loss: 0.6411 - val_accuracy: 0.7208\n",
      "Epoch 97/1000\n",
      "74/74 - 2s - loss: 0.6116 - accuracy: 0.8321 - val_loss: 0.6385 - val_accuracy: 0.7157\n",
      "Epoch 98/1000\n",
      "74/74 - 2s - loss: 0.6077 - accuracy: 0.8372 - val_loss: 0.6394 - val_accuracy: 0.7208\n",
      "Epoch 99/1000\n",
      "74/74 - 2s - loss: 0.6093 - accuracy: 0.8312 - val_loss: 0.6399 - val_accuracy: 0.7005\n",
      "Epoch 100/1000\n",
      "74/74 - 2s - loss: 0.6091 - accuracy: 0.8278 - val_loss: 0.6368 - val_accuracy: 0.6954\n",
      "Epoch 101/1000\n",
      "74/74 - 2s - loss: 0.6068 - accuracy: 0.8338 - val_loss: 0.6348 - val_accuracy: 0.7107\n",
      "Epoch 102/1000\n",
      "74/74 - 3s - loss: 0.6086 - accuracy: 0.8219 - val_loss: 0.6350 - val_accuracy: 0.7107\n",
      "Epoch 103/1000\n",
      "74/74 - 2s - loss: 0.6049 - accuracy: 0.8295 - val_loss: 0.6327 - val_accuracy: 0.7056\n",
      "Epoch 104/1000\n",
      "74/74 - 2s - loss: 0.6045 - accuracy: 0.8312 - val_loss: 0.6418 - val_accuracy: 0.6802\n",
      "Epoch 105/1000\n",
      "74/74 - 2s - loss: 0.6019 - accuracy: 0.8473 - val_loss: 0.6380 - val_accuracy: 0.6701\n",
      "Epoch 106/1000\n",
      "74/74 - 2s - loss: 0.6036 - accuracy: 0.8405 - val_loss: 0.6427 - val_accuracy: 0.6904\n",
      "Epoch 107/1000\n",
      "74/74 - 2s - loss: 0.6009 - accuracy: 0.8473 - val_loss: 0.6350 - val_accuracy: 0.6904\n",
      "Epoch 108/1000\n",
      "74/74 - 2s - loss: 0.6013 - accuracy: 0.8405 - val_loss: 0.6418 - val_accuracy: 0.6548\n",
      "Epoch 109/1000\n",
      "74/74 - 2s - loss: 0.6018 - accuracy: 0.8473 - val_loss: 0.6473 - val_accuracy: 0.6497\n",
      "Epoch 110/1000\n",
      "74/74 - 2s - loss: 0.6004 - accuracy: 0.8456 - val_loss: 0.6380 - val_accuracy: 0.6904\n",
      "Epoch 111/1000\n",
      "74/74 - 2s - loss: 0.5996 - accuracy: 0.8558 - val_loss: 0.6477 - val_accuracy: 0.6650\n",
      "Epoch 112/1000\n",
      "74/74 - 2s - loss: 0.5992 - accuracy: 0.8490 - val_loss: 0.6366 - val_accuracy: 0.6853\n",
      "Epoch 113/1000\n",
      "74/74 - 2s - loss: 0.5976 - accuracy: 0.8617 - val_loss: 0.6408 - val_accuracy: 0.6853\n",
      "Epoch 114/1000\n",
      "74/74 - 2s - loss: 0.5956 - accuracy: 0.8592 - val_loss: 0.6526 - val_accuracy: 0.6345\n",
      "Epoch 115/1000\n",
      "74/74 - 2s - loss: 0.6009 - accuracy: 0.8355 - val_loss: 0.6446 - val_accuracy: 0.6853\n",
      "Epoch 116/1000\n",
      "74/74 - 2s - loss: 0.5987 - accuracy: 0.8524 - val_loss: 0.6504 - val_accuracy: 0.6447\n",
      "Epoch 117/1000\n",
      "74/74 - 2s - loss: 0.5961 - accuracy: 0.8558 - val_loss: 0.6454 - val_accuracy: 0.6599\n",
      "Epoch 118/1000\n",
      "74/74 - 2s - loss: 0.5971 - accuracy: 0.8473 - val_loss: 0.6376 - val_accuracy: 0.7056\n",
      "Epoch 119/1000\n",
      "74/74 - 2s - loss: 0.5946 - accuracy: 0.8643 - val_loss: 0.6351 - val_accuracy: 0.6954\n",
      "Epoch 120/1000\n",
      "74/74 - 2s - loss: 0.5964 - accuracy: 0.8516 - val_loss: 0.6420 - val_accuracy: 0.6751\n",
      "Epoch 121/1000\n",
      "74/74 - 2s - loss: 0.5953 - accuracy: 0.8634 - val_loss: 0.6421 - val_accuracy: 0.6853\n",
      "Epoch 122/1000\n",
      "74/74 - 2s - loss: 0.5944 - accuracy: 0.8609 - val_loss: 0.6420 - val_accuracy: 0.6853\n",
      "Epoch 123/1000\n",
      "74/74 - 2s - loss: 0.5909 - accuracy: 0.8702 - val_loss: 0.6402 - val_accuracy: 0.6802\n",
      "Epoch 124/1000\n",
      "74/74 - 2s - loss: 0.5989 - accuracy: 0.8541 - val_loss: 0.6424 - val_accuracy: 0.7005\n",
      "Epoch 125/1000\n",
      "74/74 - 2s - loss: 0.5901 - accuracy: 0.8694 - val_loss: 0.6497 - val_accuracy: 0.6599\n",
      "Epoch 126/1000\n",
      "74/74 - 2s - loss: 0.5940 - accuracy: 0.8575 - val_loss: 0.6384 - val_accuracy: 0.6904\n",
      "Epoch 127/1000\n",
      "74/74 - 2s - loss: 0.5920 - accuracy: 0.8609 - val_loss: 0.6425 - val_accuracy: 0.6548\n",
      "Epoch 128/1000\n",
      "74/74 - 2s - loss: 0.5931 - accuracy: 0.8584 - val_loss: 0.6364 - val_accuracy: 0.6802\n",
      "Epoch 129/1000\n",
      "74/74 - 2s - loss: 0.5879 - accuracy: 0.8643 - val_loss: 0.6398 - val_accuracy: 0.6954\n",
      "Epoch 130/1000\n",
      "74/74 - 2s - loss: 0.5914 - accuracy: 0.8634 - val_loss: 0.6370 - val_accuracy: 0.7157\n",
      "Epoch 131/1000\n",
      "74/74 - 2s - loss: 0.5897 - accuracy: 0.8677 - val_loss: 0.6403 - val_accuracy: 0.6853\n",
      "Epoch 132/1000\n",
      "74/74 - 2s - loss: 0.5874 - accuracy: 0.8711 - val_loss: 0.6377 - val_accuracy: 0.7005\n",
      "Epoch 133/1000\n",
      "74/74 - 3s - loss: 0.5852 - accuracy: 0.8787 - val_loss: 0.6422 - val_accuracy: 0.6650\n",
      "Epoch 134/1000\n",
      "74/74 - 2s - loss: 0.5869 - accuracy: 0.8643 - val_loss: 0.6450 - val_accuracy: 0.6701\n",
      "Epoch 135/1000\n",
      "74/74 - 2s - loss: 0.5820 - accuracy: 0.8821 - val_loss: 0.6407 - val_accuracy: 0.6954\n",
      "Epoch 136/1000\n",
      "74/74 - 2s - loss: 0.5819 - accuracy: 0.8787 - val_loss: 0.6301 - val_accuracy: 0.7208\n",
      "Epoch 137/1000\n",
      "74/74 - 2s - loss: 0.5840 - accuracy: 0.8838 - val_loss: 0.6374 - val_accuracy: 0.7005\n",
      "Epoch 138/1000\n",
      "74/74 - 2s - loss: 0.5796 - accuracy: 0.8974 - val_loss: 0.6295 - val_accuracy: 0.7157\n",
      "Epoch 139/1000\n",
      "74/74 - 2s - loss: 0.5862 - accuracy: 0.8685 - val_loss: 0.6427 - val_accuracy: 0.6802\n",
      "Epoch 140/1000\n",
      "74/74 - 2s - loss: 0.5870 - accuracy: 0.8702 - val_loss: 0.6473 - val_accuracy: 0.6650\n",
      "Epoch 141/1000\n",
      "74/74 - 2s - loss: 0.5820 - accuracy: 0.8770 - val_loss: 0.6386 - val_accuracy: 0.6701\n",
      "Epoch 142/1000\n",
      "74/74 - 2s - loss: 0.5809 - accuracy: 0.8804 - val_loss: 0.6417 - val_accuracy: 0.6802\n",
      "Epoch 143/1000\n",
      "74/74 - 2s - loss: 0.5827 - accuracy: 0.8736 - val_loss: 0.6444 - val_accuracy: 0.6599\n",
      "Epoch 144/1000\n",
      "74/74 - 2s - loss: 0.5812 - accuracy: 0.8779 - val_loss: 0.6435 - val_accuracy: 0.6904\n",
      "Epoch 145/1000\n",
      "74/74 - 2s - loss: 0.5852 - accuracy: 0.8728 - val_loss: 0.6466 - val_accuracy: 0.6345\n",
      "Epoch 146/1000\n",
      "74/74 - 2s - loss: 0.5814 - accuracy: 0.8880 - val_loss: 0.6475 - val_accuracy: 0.6599\n",
      "Epoch 147/1000\n",
      "74/74 - 2s - loss: 0.5758 - accuracy: 0.8897 - val_loss: 0.6411 - val_accuracy: 0.6599\n",
      "Epoch 148/1000\n",
      "74/74 - 2s - loss: 0.5792 - accuracy: 0.8846 - val_loss: 0.6451 - val_accuracy: 0.6853\n",
      "Epoch 149/1000\n",
      "74/74 - 2s - loss: 0.5831 - accuracy: 0.8753 - val_loss: 0.6441 - val_accuracy: 0.6599\n",
      "Epoch 150/1000\n",
      "74/74 - 2s - loss: 0.5794 - accuracy: 0.8855 - val_loss: 0.6421 - val_accuracy: 0.6954\n",
      "Epoch 151/1000\n",
      "74/74 - 2s - loss: 0.5768 - accuracy: 0.8897 - val_loss: 0.6318 - val_accuracy: 0.7005\n",
      "Epoch 152/1000\n",
      "74/74 - 2s - loss: 0.5756 - accuracy: 0.8897 - val_loss: 0.6435 - val_accuracy: 0.6599\n",
      "Epoch 153/1000\n",
      "74/74 - 2s - loss: 0.5721 - accuracy: 0.8974 - val_loss: 0.6351 - val_accuracy: 0.6802\n",
      "Epoch 154/1000\n",
      "74/74 - 2s - loss: 0.5791 - accuracy: 0.8813 - val_loss: 0.6498 - val_accuracy: 0.6599\n",
      "Epoch 155/1000\n",
      "74/74 - 2s - loss: 0.5750 - accuracy: 0.8863 - val_loss: 0.6319 - val_accuracy: 0.7056\n",
      "Epoch 156/1000\n",
      "74/74 - 2s - loss: 0.5773 - accuracy: 0.8855 - val_loss: 0.6407 - val_accuracy: 0.6853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/1000\n",
      "74/74 - 2s - loss: 0.5768 - accuracy: 0.8821 - val_loss: 0.6347 - val_accuracy: 0.7056\n",
      "Epoch 158/1000\n",
      "74/74 - 2s - loss: 0.5760 - accuracy: 0.8863 - val_loss: 0.6502 - val_accuracy: 0.6294\n",
      "Epoch 159/1000\n",
      "74/74 - 2s - loss: 0.5762 - accuracy: 0.8796 - val_loss: 0.6432 - val_accuracy: 0.6904\n",
      "Epoch 160/1000\n",
      "74/74 - 2s - loss: 0.5744 - accuracy: 0.8889 - val_loss: 0.6367 - val_accuracy: 0.7056\n",
      "Epoch 161/1000\n",
      "74/74 - 2s - loss: 0.5697 - accuracy: 0.8991 - val_loss: 0.6479 - val_accuracy: 0.6802\n",
      "Epoch 162/1000\n",
      "74/74 - 2s - loss: 0.5805 - accuracy: 0.8770 - val_loss: 0.6292 - val_accuracy: 0.7056\n",
      "Epoch 163/1000\n",
      "74/74 - 2s - loss: 0.5831 - accuracy: 0.8694 - val_loss: 0.6447 - val_accuracy: 0.6853\n",
      "Epoch 164/1000\n",
      "74/74 - 2s - loss: 0.5753 - accuracy: 0.8838 - val_loss: 0.6379 - val_accuracy: 0.7056\n",
      "Epoch 165/1000\n",
      "74/74 - 2s - loss: 0.5740 - accuracy: 0.8863 - val_loss: 0.6324 - val_accuracy: 0.7157\n",
      "Epoch 166/1000\n",
      "74/74 - 2s - loss: 0.5710 - accuracy: 0.8863 - val_loss: 0.6380 - val_accuracy: 0.6599\n",
      "Epoch 167/1000\n",
      "74/74 - 2s - loss: 0.5745 - accuracy: 0.8846 - val_loss: 0.6399 - val_accuracy: 0.6954\n",
      "Epoch 168/1000\n",
      "74/74 - 2s - loss: 0.5741 - accuracy: 0.8872 - val_loss: 0.6490 - val_accuracy: 0.6396\n",
      "Epoch 169/1000\n",
      "74/74 - 2s - loss: 0.5746 - accuracy: 0.8923 - val_loss: 0.6506 - val_accuracy: 0.6447\n",
      "Epoch 170/1000\n",
      "74/74 - 2s - loss: 0.5746 - accuracy: 0.8999 - val_loss: 0.6565 - val_accuracy: 0.6142\n",
      "Epoch 171/1000\n",
      "74/74 - 2s - loss: 0.5677 - accuracy: 0.9016 - val_loss: 0.6422 - val_accuracy: 0.6650\n",
      "Epoch 172/1000\n",
      "74/74 - 2s - loss: 0.5715 - accuracy: 0.9008 - val_loss: 0.6472 - val_accuracy: 0.6701\n",
      "Epoch 173/1000\n",
      "74/74 - 2s - loss: 0.5701 - accuracy: 0.9016 - val_loss: 0.6474 - val_accuracy: 0.6548\n",
      "Epoch 174/1000\n",
      "74/74 - 2s - loss: 0.5703 - accuracy: 0.8982 - val_loss: 0.6479 - val_accuracy: 0.6244\n",
      "Epoch 175/1000\n",
      "74/74 - 2s - loss: 0.5742 - accuracy: 0.8948 - val_loss: 0.6401 - val_accuracy: 0.6548\n",
      "Epoch 176/1000\n",
      "74/74 - 2s - loss: 0.5735 - accuracy: 0.8940 - val_loss: 0.6362 - val_accuracy: 0.6904\n",
      "Epoch 177/1000\n",
      "74/74 - 2s - loss: 0.5711 - accuracy: 0.8872 - val_loss: 0.6202 - val_accuracy: 0.7360\n",
      "Epoch 178/1000\n",
      "74/74 - 2s - loss: 0.5722 - accuracy: 0.8923 - val_loss: 0.6416 - val_accuracy: 0.6751\n",
      "Epoch 179/1000\n",
      "74/74 - 2s - loss: 0.5738 - accuracy: 0.8940 - val_loss: 0.6375 - val_accuracy: 0.6853\n",
      "Epoch 180/1000\n",
      "74/74 - 2s - loss: 0.5701 - accuracy: 0.9008 - val_loss: 0.6390 - val_accuracy: 0.6853\n",
      "Epoch 181/1000\n",
      "74/74 - 2s - loss: 0.5717 - accuracy: 0.8914 - val_loss: 0.6439 - val_accuracy: 0.6751\n",
      "Epoch 182/1000\n",
      "74/74 - 2s - loss: 0.5670 - accuracy: 0.8982 - val_loss: 0.6302 - val_accuracy: 0.7005\n",
      "Epoch 183/1000\n",
      "74/74 - 2s - loss: 0.5689 - accuracy: 0.8914 - val_loss: 0.6197 - val_accuracy: 0.7310\n",
      "Epoch 184/1000\n",
      "74/74 - 2s - loss: 0.5673 - accuracy: 0.8940 - val_loss: 0.6371 - val_accuracy: 0.6802\n",
      "Epoch 185/1000\n",
      "74/74 - 2s - loss: 0.5662 - accuracy: 0.8965 - val_loss: 0.6441 - val_accuracy: 0.7005\n",
      "Epoch 186/1000\n",
      "74/74 - 2s - loss: 0.5705 - accuracy: 0.8948 - val_loss: 0.6466 - val_accuracy: 0.6396\n",
      "Epoch 187/1000\n",
      "74/74 - 2s - loss: 0.5674 - accuracy: 0.8982 - val_loss: 0.6264 - val_accuracy: 0.7107\n",
      "Epoch 188/1000\n",
      "74/74 - 2s - loss: 0.5688 - accuracy: 0.8948 - val_loss: 0.6313 - val_accuracy: 0.7005\n",
      "Epoch 189/1000\n",
      "74/74 - 2s - loss: 0.5664 - accuracy: 0.8940 - val_loss: 0.6351 - val_accuracy: 0.6904\n",
      "Epoch 190/1000\n",
      "74/74 - 2s - loss: 0.5683 - accuracy: 0.8906 - val_loss: 0.6228 - val_accuracy: 0.7208\n",
      "Epoch 191/1000\n",
      "74/74 - 2s - loss: 0.5671 - accuracy: 0.8982 - val_loss: 0.6311 - val_accuracy: 0.7005\n",
      "Epoch 192/1000\n",
      "74/74 - 2s - loss: 0.5702 - accuracy: 0.9008 - val_loss: 0.6285 - val_accuracy: 0.7107\n",
      "Epoch 193/1000\n",
      "74/74 - 2s - loss: 0.5653 - accuracy: 0.9016 - val_loss: 0.6326 - val_accuracy: 0.6904\n",
      "Epoch 194/1000\n",
      "74/74 - 2s - loss: 0.5647 - accuracy: 0.8940 - val_loss: 0.6199 - val_accuracy: 0.7462\n",
      "Epoch 195/1000\n",
      "74/74 - 2s - loss: 0.5631 - accuracy: 0.9025 - val_loss: 0.6341 - val_accuracy: 0.6802\n",
      "Epoch 196/1000\n",
      "74/74 - 2s - loss: 0.5654 - accuracy: 0.9050 - val_loss: 0.6336 - val_accuracy: 0.7208\n",
      "Epoch 197/1000\n",
      "74/74 - 2s - loss: 0.5678 - accuracy: 0.8940 - val_loss: 0.6292 - val_accuracy: 0.7005\n",
      "Epoch 198/1000\n",
      "74/74 - 2s - loss: 0.5695 - accuracy: 0.8855 - val_loss: 0.6440 - val_accuracy: 0.6751\n",
      "Epoch 199/1000\n",
      "74/74 - 2s - loss: 0.5699 - accuracy: 0.8940 - val_loss: 0.6373 - val_accuracy: 0.7005\n",
      "Epoch 200/1000\n",
      "74/74 - 2s - loss: 0.5662 - accuracy: 0.8999 - val_loss: 0.6468 - val_accuracy: 0.6599\n",
      "Epoch 201/1000\n",
      "74/74 - 2s - loss: 0.5660 - accuracy: 0.8991 - val_loss: 0.6552 - val_accuracy: 0.6396\n",
      "Epoch 202/1000\n",
      "74/74 - 2s - loss: 0.5704 - accuracy: 0.8923 - val_loss: 0.6480 - val_accuracy: 0.6650\n",
      "Epoch 203/1000\n",
      "74/74 - 2s - loss: 0.5688 - accuracy: 0.8957 - val_loss: 0.6433 - val_accuracy: 0.6904\n",
      "Epoch 204/1000\n",
      "74/74 - 2s - loss: 0.5673 - accuracy: 0.9025 - val_loss: 0.6327 - val_accuracy: 0.7107\n",
      "Epoch 205/1000\n",
      "74/74 - 2s - loss: 0.5644 - accuracy: 0.9050 - val_loss: 0.6393 - val_accuracy: 0.6904\n",
      "Epoch 206/1000\n",
      "74/74 - 2s - loss: 0.5668 - accuracy: 0.8974 - val_loss: 0.6312 - val_accuracy: 0.6802\n",
      "Epoch 207/1000\n",
      "74/74 - 2s - loss: 0.5588 - accuracy: 0.9084 - val_loss: 0.6467 - val_accuracy: 0.6650\n",
      "Epoch 208/1000\n",
      "74/74 - 2s - loss: 0.5674 - accuracy: 0.8931 - val_loss: 0.6352 - val_accuracy: 0.6954\n",
      "Epoch 209/1000\n",
      "74/74 - 2s - loss: 0.5675 - accuracy: 0.8957 - val_loss: 0.6294 - val_accuracy: 0.7056\n",
      "Epoch 210/1000\n",
      "74/74 - 2s - loss: 0.5656 - accuracy: 0.9033 - val_loss: 0.6238 - val_accuracy: 0.7157\n",
      "Epoch 211/1000\n",
      "74/74 - 2s - loss: 0.5687 - accuracy: 0.8914 - val_loss: 0.6447 - val_accuracy: 0.6751\n",
      "Epoch 212/1000\n",
      "74/74 - 2s - loss: 0.5629 - accuracy: 0.9126 - val_loss: 0.6344 - val_accuracy: 0.6853\n",
      "Epoch 213/1000\n",
      "74/74 - 2s - loss: 0.5630 - accuracy: 0.9101 - val_loss: 0.6420 - val_accuracy: 0.6599\n",
      "Epoch 214/1000\n",
      "74/74 - 2s - loss: 0.5646 - accuracy: 0.9008 - val_loss: 0.6346 - val_accuracy: 0.6853\n",
      "Epoch 215/1000\n",
      "74/74 - 2s - loss: 0.5632 - accuracy: 0.9033 - val_loss: 0.6426 - val_accuracy: 0.6701\n",
      "Epoch 216/1000\n",
      "74/74 - 2s - loss: 0.5637 - accuracy: 0.9025 - val_loss: 0.6221 - val_accuracy: 0.7259\n",
      "Epoch 217/1000\n",
      "74/74 - 2s - loss: 0.5633 - accuracy: 0.9033 - val_loss: 0.6391 - val_accuracy: 0.6701\n",
      "Epoch 218/1000\n",
      "74/74 - 2s - loss: 0.5613 - accuracy: 0.9042 - val_loss: 0.6230 - val_accuracy: 0.7310\n",
      "Epoch 219/1000\n",
      "74/74 - 2s - loss: 0.5606 - accuracy: 0.9016 - val_loss: 0.6266 - val_accuracy: 0.7107\n",
      "Epoch 220/1000\n",
      "74/74 - 2s - loss: 0.5601 - accuracy: 0.9084 - val_loss: 0.6380 - val_accuracy: 0.6650\n",
      "Epoch 221/1000\n",
      "74/74 - 2s - loss: 0.5636 - accuracy: 0.8948 - val_loss: 0.6370 - val_accuracy: 0.6650\n",
      "Epoch 222/1000\n",
      "74/74 - 2s - loss: 0.5651 - accuracy: 0.8999 - val_loss: 0.6291 - val_accuracy: 0.7259\n",
      "Epoch 223/1000\n",
      "74/74 - 2s - loss: 0.5642 - accuracy: 0.9101 - val_loss: 0.6456 - val_accuracy: 0.6751\n",
      "Epoch 224/1000\n",
      "74/74 - 2s - loss: 0.5599 - accuracy: 0.9109 - val_loss: 0.6285 - val_accuracy: 0.7107\n",
      "Epoch 225/1000\n",
      "74/74 - 2s - loss: 0.5557 - accuracy: 0.9169 - val_loss: 0.6350 - val_accuracy: 0.6701\n",
      "Epoch 226/1000\n",
      "74/74 - 2s - loss: 0.5570 - accuracy: 0.9118 - val_loss: 0.6298 - val_accuracy: 0.7107\n",
      "Epoch 227/1000\n",
      "74/74 - 2s - loss: 0.5574 - accuracy: 0.9092 - val_loss: 0.6376 - val_accuracy: 0.7157\n",
      "Epoch 228/1000\n",
      "74/74 - 2s - loss: 0.5621 - accuracy: 0.8974 - val_loss: 0.6358 - val_accuracy: 0.6751\n",
      "Epoch 229/1000\n",
      "74/74 - 2s - loss: 0.5580 - accuracy: 0.9143 - val_loss: 0.6456 - val_accuracy: 0.6650\n",
      "Epoch 230/1000\n",
      "74/74 - 2s - loss: 0.5583 - accuracy: 0.9008 - val_loss: 0.6401 - val_accuracy: 0.6701\n",
      "Epoch 231/1000\n",
      "74/74 - 2s - loss: 0.5616 - accuracy: 0.9075 - val_loss: 0.6359 - val_accuracy: 0.6548\n",
      "Epoch 232/1000\n",
      "74/74 - 2s - loss: 0.5656 - accuracy: 0.8931 - val_loss: 0.6303 - val_accuracy: 0.6853\n",
      "Epoch 233/1000\n",
      "74/74 - 2s - loss: 0.5624 - accuracy: 0.8948 - val_loss: 0.6373 - val_accuracy: 0.7005\n",
      "Epoch 234/1000\n",
      "74/74 - 2s - loss: 0.5601 - accuracy: 0.9118 - val_loss: 0.6398 - val_accuracy: 0.6701\n",
      "Epoch 235/1000\n",
      "74/74 - 2s - loss: 0.5601 - accuracy: 0.9059 - val_loss: 0.6376 - val_accuracy: 0.6447\n",
      "Epoch 236/1000\n",
      "74/74 - 2s - loss: 0.5627 - accuracy: 0.8931 - val_loss: 0.6339 - val_accuracy: 0.7056\n",
      "Epoch 237/1000\n",
      "74/74 - 2s - loss: 0.5661 - accuracy: 0.8931 - val_loss: 0.6371 - val_accuracy: 0.6853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/1000\n",
      "74/74 - 2s - loss: 0.5637 - accuracy: 0.8974 - val_loss: 0.6421 - val_accuracy: 0.6701\n",
      "Epoch 239/1000\n",
      "74/74 - 2s - loss: 0.5653 - accuracy: 0.8957 - val_loss: 0.6392 - val_accuracy: 0.6599\n",
      "Epoch 240/1000\n",
      "74/74 - 2s - loss: 0.5606 - accuracy: 0.9092 - val_loss: 0.6543 - val_accuracy: 0.6244\n",
      "Epoch 241/1000\n",
      "74/74 - 2s - loss: 0.5637 - accuracy: 0.9025 - val_loss: 0.6404 - val_accuracy: 0.6802\n",
      "Epoch 242/1000\n",
      "74/74 - 2s - loss: 0.5583 - accuracy: 0.9109 - val_loss: 0.6367 - val_accuracy: 0.6802\n",
      "Epoch 243/1000\n",
      "74/74 - 2s - loss: 0.5581 - accuracy: 0.9084 - val_loss: 0.6307 - val_accuracy: 0.6954\n",
      "Epoch 244/1000\n",
      "74/74 - 2s - loss: 0.5577 - accuracy: 0.9059 - val_loss: 0.6364 - val_accuracy: 0.6954\n",
      "Epoch 245/1000\n",
      "74/74 - 2s - loss: 0.5613 - accuracy: 0.8965 - val_loss: 0.6407 - val_accuracy: 0.6853\n",
      "Epoch 246/1000\n",
      "74/74 - 2s - loss: 0.5629 - accuracy: 0.8940 - val_loss: 0.6452 - val_accuracy: 0.6447\n",
      "Epoch 247/1000\n",
      "74/74 - 2s - loss: 0.5571 - accuracy: 0.9152 - val_loss: 0.6450 - val_accuracy: 0.6802\n",
      "Epoch 248/1000\n",
      "74/74 - 2s - loss: 0.5620 - accuracy: 0.9059 - val_loss: 0.6350 - val_accuracy: 0.6650\n",
      "Epoch 249/1000\n",
      "74/74 - 2s - loss: 0.5632 - accuracy: 0.9042 - val_loss: 0.6275 - val_accuracy: 0.6853\n",
      "Epoch 250/1000\n",
      "74/74 - 2s - loss: 0.5626 - accuracy: 0.8948 - val_loss: 0.6376 - val_accuracy: 0.6701\n",
      "Epoch 251/1000\n",
      "74/74 - 2s - loss: 0.5603 - accuracy: 0.9067 - val_loss: 0.6336 - val_accuracy: 0.6954\n",
      "Epoch 252/1000\n",
      "74/74 - 2s - loss: 0.5573 - accuracy: 0.9075 - val_loss: 0.6383 - val_accuracy: 0.6802\n",
      "Epoch 253/1000\n",
      "74/74 - 2s - loss: 0.5559 - accuracy: 0.9092 - val_loss: 0.6254 - val_accuracy: 0.6954\n",
      "Epoch 254/1000\n",
      "74/74 - 2s - loss: 0.5566 - accuracy: 0.9059 - val_loss: 0.6444 - val_accuracy: 0.6751\n",
      "Epoch 255/1000\n",
      "74/74 - 2s - loss: 0.5608 - accuracy: 0.9008 - val_loss: 0.6273 - val_accuracy: 0.7310\n",
      "Epoch 00255: early stopping\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 1176, 24)          216       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 588, 24)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 588, 24)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 14112)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1806464   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,806,809\n",
      "Trainable params: 1,806,809\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    verbose=2,\n",
    "    validation_data=(X_dev, y_dev),\n",
    "    batch_size=16,\n",
    "    callbacks=[es]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e5f279",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (etsy)",
   "language": "python",
   "name": "etsy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
