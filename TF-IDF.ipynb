{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abc48fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "#load inthe NTLK stopwords to remove articles, preposition and other words that are not actionable\n",
    "from nltk.corpus import stopwords\n",
    "# This allows to create individual objects from a bog of words\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "# Lemmatizer helps to reduce words to the base form\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f5cae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_eda=pd.read_csv('eda_np.txt', sep=\"\\t\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6a73888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29ebda21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/jasmineli/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jasmineli/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/jasmineli/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('summer-products-with-rating-and-performance_2020-08.csv')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b8a0cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sentence(sentence):\n",
    "    new_tokens = word_tokenize(sentence)\n",
    "    new_tokens = [t.lower() for t in new_tokens]\n",
    "    new_tokens =[t for t in new_tokens if t not in stopwords.words('english')]\n",
    "    new_tokens = [t for t in new_tokens if t.isalpha()]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    new_tokens =[lemmatizer.lemmatize(t) for t in new_tokens]\n",
    "    return \" \".join(new_tokens), len(new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c0d31ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tags_pre'] = df['tags'].apply(lambda x: x.replace(',', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a880c2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = df['title_orig'].tolist()\n",
    "results = [process_sentence(t) for t in titles]\n",
    "tokens, length = zip(*results)\n",
    "df['title_pre'] = tokens\n",
    "df['title_len'] = df['title_pre'].str.split(\" \").str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "000686a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title_len        12.7\n",
       "units_sold    80000.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['title_len', 'units_sold']].sort_values(by='units_sold', ascending=False).head(10).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "17c1639f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title_len     11.6\n",
       "units_sold     3.3\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['title_len', 'units_sold']].sort_values(by='units_sold', ascending=False).tail(10).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b65cd8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = df['tags_pre'].tolist()\n",
    "results = [process_sentence(t) for t in tags]\n",
    "tokens, length = zip(*results)\n",
    "df['tags_pre'] = tokens\n",
    "df['tags_num'] = length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2f6bfba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tags_num         23.8\n",
       "units_sold    53000.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['tags_num', 'units_sold']].sort_values(by='units_sold', ascending=False).head(30).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c9e15cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tags_num      19.833333\n",
       "units_sold     7.500000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['tags_num', 'units_sold']].sort_values(by='units_sold', ascending=False).tail(30).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "a5a29e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(df['title_pre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "775d0a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasmineli/opt/anaconda3/envs/etsy/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "tfidf = pd.DataFrame(denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "a6e4b0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absorbing</th>\n",
       "      <th>accessory</th>\n",
       "      <th>active</th>\n",
       "      <th>activewear</th>\n",
       "      <th>activity</th>\n",
       "      <th>acute</th>\n",
       "      <th>adhesive</th>\n",
       "      <th>adjustable</th>\n",
       "      <th>aeeival</th>\n",
       "      <th>african</th>\n",
       "      <th>...</th>\n",
       "      <th>yoga</th>\n",
       "      <th>youth</th>\n",
       "      <th>zanzea</th>\n",
       "      <th>zapatillas</th>\n",
       "      <th>zapatos</th>\n",
       "      <th>zapper</th>\n",
       "      <th>ziper</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zm</th>\n",
       "      <th>übergröße</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.260621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1573 rows × 1171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      absorbing  accessory  active  activewear  activity  acute  adhesive  \\\n",
       "0           0.0        0.0     0.0         0.0       0.0    0.0       0.0   \n",
       "1           0.0        0.0     0.0         0.0       0.0    0.0       0.0   \n",
       "2           0.0        0.0     0.0         0.0       0.0    0.0       0.0   \n",
       "3           0.0        0.0     0.0         0.0       0.0    0.0       0.0   \n",
       "4           0.0        0.0     0.0         0.0       0.0    0.0       0.0   \n",
       "...         ...        ...     ...         ...       ...    ...       ...   \n",
       "1568        0.0        0.0     0.0         0.0       0.0    0.0       0.0   \n",
       "1569        0.0        0.0     0.0         0.0       0.0    0.0       0.0   \n",
       "1570        0.0        0.0     0.0         0.0       0.0    0.0       0.0   \n",
       "1571        0.0        0.0     0.0         0.0       0.0    0.0       0.0   \n",
       "1572        0.0        0.0     0.0         0.0       0.0    0.0       0.0   \n",
       "\n",
       "      adjustable  aeeival  african  ...      yoga  youth  zanzea  zapatillas  \\\n",
       "0            0.0      0.0      0.0  ...  0.000000    0.0     0.0         0.0   \n",
       "1            0.0      0.0      0.0  ...  0.000000    0.0     0.0         0.0   \n",
       "2            0.0      0.0      0.0  ...  0.000000    0.0     0.0         0.0   \n",
       "3            0.0      0.0      0.0  ...  0.000000    0.0     0.0         0.0   \n",
       "4            0.0      0.0      0.0  ...  0.000000    0.0     0.0         0.0   \n",
       "...          ...      ...      ...  ...       ...    ...     ...         ...   \n",
       "1568         0.0      0.0      0.0  ...  0.260621    0.0     0.0         0.0   \n",
       "1569         0.0      0.0      0.0  ...  0.000000    0.0     0.0         0.0   \n",
       "1570         0.0      0.0      0.0  ...  0.000000    0.0     0.0         0.0   \n",
       "1571         0.0      0.0      0.0  ...  0.000000    0.0     0.0         0.0   \n",
       "1572         0.0      0.0      0.0  ...  0.387433    0.0     0.0         0.0   \n",
       "\n",
       "      zapatos  zapper  ziper  zipper   zm  übergröße  \n",
       "0         0.0     0.0    0.0     0.0  0.0        0.0  \n",
       "1         0.0     0.0    0.0     0.0  0.0        0.0  \n",
       "2         0.0     0.0    0.0     0.0  0.0        0.0  \n",
       "3         0.0     0.0    0.0     0.0  0.0        0.0  \n",
       "4         0.0     0.0    0.0     0.0  0.0        0.0  \n",
       "...       ...     ...    ...     ...  ...        ...  \n",
       "1568      0.0     0.0    0.0     0.0  0.0        0.0  \n",
       "1569      0.0     0.0    0.0     0.0  0.0        0.0  \n",
       "1570      0.0     0.0    0.0     0.0  0.0        0.0  \n",
       "1571      0.0     0.0    0.0     0.0  0.0        0.0  \n",
       "1572      0.0     0.0    0.0     0.0  0.0        0.0  \n",
       "\n",
       "[1573 rows x 1171 columns]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "9b55dca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(df['tags_pre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "f281cd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasmineli/opt/anaconda3/envs/etsy/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "tfidf_tag = pd.DataFrame(denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "fc8156d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasmineli/opt/anaconda3/envs/etsy/lib/python3.7/site-packages/pandas/core/arraylike.py:364: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# product color\n",
    "def main_color(s):\n",
    "    main_color = {\"red\":\"red\", \"white\":\"white\", \"pink\":\"pink\", \"yellow\":\"yellow\", \"green\":\"green\", \"blue\":\"blue\", \"wine\":\"red\", \"burgundy\":\"red\", \"black\":\"black\", \"navy\":\"navy\", \"orange\":\"orange\", \n",
    "    \"rose\":\"pink\", \"gray\":\"gray\", \"grey\":\"gray\", \"purple\":\"purple\", \"violet\":\"purple\", \"army\":\"green\", \"leopard\":\"orange\", \"ivory\":\"white\", \n",
    "    \"brown\":\"brown\", \"coffee\":\"brown\", \"camel\":\"beige\", \"tan\":\"brown\", \"nude\":\"beige\", \"khaki\":\"khaki\", \"apricot\":\"yellow\", \"camouflage\":\"green\", \"jasper\":\"red\"}  # ordered by importance\n",
    "    for key, value in main_color.items():\n",
    "        if key in s:\n",
    "            return value\n",
    "    return \"others\"\n",
    "product_color = df[\"product_color\"]\n",
    "product_color = [s.lower() if type(s) is str else 'nan' for s in product_color]\n",
    "product_color = [main_color(s) for s in product_color]\n",
    "from matplotlib import colors\n",
    "product_color = [(-0.1,-0.1,-0.1,-0.1) if s == \"others\" else colors.to_rgba(s) for s in product_color]\n",
    "\n",
    "df['product_color_rgb'] = [np.array(t) for t in product_color]\n",
    "\n",
    "# log prices\n",
    "df['log_price'] = [np.log(p) for p in df[\"price\"]]\n",
    "df['log_retail_price'] = [np.log(p) for p in df[\"retail_price\"]]\n",
    "\n",
    "# log merchant rating count\n",
    "df['log_merchant_rating_count'] = np.log(df['merchant_rating_count'])\n",
    "\n",
    "# urgent text\n",
    "df['urgent'] = [1 if s == \"Quantité limitée !\" else 0 for s in df[\"urgency_text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "02d69257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    925\n",
      "0    648\n",
      "Name: high_sale, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = df[[\"log_price\", \"log_retail_price\", \"uses_ad_boosts\", \"badges_count\", \"badge_local_product\", \n",
    "           \"badge_product_quality\", \"badge_fast_shipping\", \"urgent\", \"units_sold\"]]\n",
    "df2 = pd.concat([data, tfidf], axis=1)\n",
    "label = [1 if sales > 100 else 0 for sales in data[\"units_sold\"]]\n",
    "df2['high_sale'] = label\n",
    "print(df2['high_sale'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "94f48cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1573, 1185)\n"
     ]
    }
   ],
   "source": [
    "rgb = df[\"product_color_rgb\"]\n",
    "rgb = np.stack(rgb.values, axis=0)\n",
    "for i in range(4):\n",
    "    df2[\"product_color_rgb\"+str(i)] = rgb[:,i]\n",
    "df2.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "44d3fb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2.loc[:, ~df2.columns.isin(['high_sale', 'units_sold'])]\n",
    "# X = tfidf\n",
    "y = df2['high_sale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "3e9e81f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from keras.layers import Input, Dense, Concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.125, random_state=42)\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, test_size=0.14286, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "1fa30b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 1179\n",
      "number of dev examples = 197\n",
      "number of test examples = 197\n",
      "X_train shape: (1179, 1183)\n",
      "Y_train shape: (1179,)\n",
      "X_dev shape: (197, 1183)\n",
      "Y_dev shape: (197,)\n",
      "X_test shape: (197, 1183)\n",
      "Y_test shape: (197,)\n"
     ]
    }
   ],
   "source": [
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of dev examples = \" + str(X_dev.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(y_train.shape))\n",
    "print (\"X_dev shape: \" + str(X_dev.shape))\n",
    "print (\"Y_dev shape: \" + str(y_dev.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "2f080968",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.expand_dims(X_train, axis=-1)\n",
    "input_shape = X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "55ab87a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1183, 1)\n"
     ]
    }
   ],
   "source": [
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "231c0ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# classifier = LogisticRegression()\n",
    "# classifier.fit(X_train, y_train)\n",
    "\n",
    "# score = classifier.score(evals_X, evals_y)\n",
    "\n",
    "# print(\"Accuracy:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "68feb235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import AveragePooling1D, PReLU, LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "d313196d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=20,  activation='relu',kernel_size=4))\n",
    "# model.add(Conv1D(filters=20, kernel_size=4, padding='same'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "# model.add(AveragePooling1D(pool_size=2, strides=None, padding=\"valid\"))\n",
    "# model.add(PReLU())\n",
    "model.add(Dropout(0.05))\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(256, activation='relu', kernel_regularizer='l2'))\n",
    "model.add(Dense(256, activation='relu')) \n",
    "# model.add(LeakyReLU(alpha=0.05))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "fcb4c14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=0, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "be38e41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "37/37 - 1s - loss: 0.6617 - accuracy: 0.5997 - val_loss: 0.6216 - val_accuracy: 0.6396 - 1s/epoch - 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasmineli/opt/anaconda3/envs/etsy/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/1000\n",
      "37/37 - 1s - loss: 0.5749 - accuracy: 0.7133 - val_loss: 0.6056 - val_accuracy: 0.6701 - 642ms/epoch - 17ms/step\n",
      "Epoch 3/1000\n",
      "37/37 - 1s - loss: 0.5067 - accuracy: 0.7549 - val_loss: 0.6238 - val_accuracy: 0.6497 - 662ms/epoch - 18ms/step\n",
      "Epoch 4/1000\n",
      "37/37 - 1s - loss: 0.4486 - accuracy: 0.7659 - val_loss: 0.6566 - val_accuracy: 0.6701 - 637ms/epoch - 17ms/step\n",
      "Epoch 5/1000\n",
      "37/37 - 1s - loss: 0.4036 - accuracy: 0.7905 - val_loss: 0.6204 - val_accuracy: 0.6701 - 622ms/epoch - 17ms/step\n",
      "Epoch 6/1000\n",
      "37/37 - 1s - loss: 0.3882 - accuracy: 0.8083 - val_loss: 0.7106 - val_accuracy: 0.6701 - 635ms/epoch - 17ms/step\n",
      "Epoch 7/1000\n",
      "37/37 - 1s - loss: 0.3500 - accuracy: 0.8397 - val_loss: 0.7311 - val_accuracy: 0.6853 - 625ms/epoch - 17ms/step\n",
      "Epoch 8/1000\n",
      "37/37 - 1s - loss: 0.3122 - accuracy: 0.8592 - val_loss: 0.7135 - val_accuracy: 0.6853 - 614ms/epoch - 17ms/step\n",
      "Epoch 9/1000\n",
      "37/37 - 1s - loss: 0.2881 - accuracy: 0.8719 - val_loss: 0.7703 - val_accuracy: 0.6599 - 608ms/epoch - 16ms/step\n",
      "Epoch 10/1000\n",
      "37/37 - 1s - loss: 0.2700 - accuracy: 0.8804 - val_loss: 0.7486 - val_accuracy: 0.6954 - 613ms/epoch - 17ms/step\n",
      "Epoch 11/1000\n",
      "37/37 - 1s - loss: 0.2374 - accuracy: 0.8931 - val_loss: 0.8298 - val_accuracy: 0.6701 - 627ms/epoch - 17ms/step\n",
      "Epoch 12/1000\n",
      "37/37 - 1s - loss: 0.2183 - accuracy: 0.9126 - val_loss: 0.8223 - val_accuracy: 0.7005 - 645ms/epoch - 17ms/step\n",
      "Epoch 13/1000\n",
      "37/37 - 1s - loss: 0.1964 - accuracy: 0.9203 - val_loss: 0.8054 - val_accuracy: 0.7056 - 618ms/epoch - 17ms/step\n",
      "Epoch 14/1000\n",
      "37/37 - 1s - loss: 0.1875 - accuracy: 0.9143 - val_loss: 0.8407 - val_accuracy: 0.7056 - 630ms/epoch - 17ms/step\n",
      "Epoch 15/1000\n",
      "37/37 - 1s - loss: 0.1793 - accuracy: 0.9271 - val_loss: 0.8580 - val_accuracy: 0.7157 - 672ms/epoch - 18ms/step\n",
      "Epoch 16/1000\n",
      "37/37 - 1s - loss: 0.1504 - accuracy: 0.9398 - val_loss: 0.9192 - val_accuracy: 0.7005 - 687ms/epoch - 19ms/step\n",
      "Epoch 17/1000\n",
      "37/37 - 1s - loss: 0.1477 - accuracy: 0.9466 - val_loss: 0.9284 - val_accuracy: 0.7056 - 672ms/epoch - 18ms/step\n",
      "Epoch 18/1000\n",
      "37/37 - 1s - loss: 0.1335 - accuracy: 0.9517 - val_loss: 0.9671 - val_accuracy: 0.7157 - 625ms/epoch - 17ms/step\n",
      "Epoch 19/1000\n",
      "37/37 - 1s - loss: 0.1232 - accuracy: 0.9576 - val_loss: 1.0099 - val_accuracy: 0.7107 - 640ms/epoch - 17ms/step\n",
      "Epoch 20/1000\n",
      "37/37 - 1s - loss: 0.1177 - accuracy: 0.9593 - val_loss: 1.0667 - val_accuracy: 0.7208 - 617ms/epoch - 17ms/step\n",
      "Epoch 21/1000\n",
      "37/37 - 1s - loss: 0.1117 - accuracy: 0.9542 - val_loss: 1.0251 - val_accuracy: 0.7056 - 621ms/epoch - 17ms/step\n",
      "Epoch 22/1000\n",
      "37/37 - 1s - loss: 0.1049 - accuracy: 0.9576 - val_loss: 1.1056 - val_accuracy: 0.7056 - 624ms/epoch - 17ms/step\n",
      "Epoch 23/1000\n",
      "37/37 - 1s - loss: 0.0963 - accuracy: 0.9593 - val_loss: 1.1988 - val_accuracy: 0.7056 - 617ms/epoch - 17ms/step\n",
      "Epoch 24/1000\n",
      "37/37 - 1s - loss: 0.0929 - accuracy: 0.9644 - val_loss: 1.2119 - val_accuracy: 0.7107 - 606ms/epoch - 16ms/step\n",
      "Epoch 25/1000\n",
      "37/37 - 1s - loss: 0.0943 - accuracy: 0.9652 - val_loss: 1.2187 - val_accuracy: 0.7056 - 624ms/epoch - 17ms/step\n",
      "Epoch 26/1000\n",
      "37/37 - 1s - loss: 0.0866 - accuracy: 0.9644 - val_loss: 1.1534 - val_accuracy: 0.7005 - 622ms/epoch - 17ms/step\n",
      "Epoch 27/1000\n",
      "37/37 - 1s - loss: 0.0869 - accuracy: 0.9610 - val_loss: 1.1800 - val_accuracy: 0.7157 - 633ms/epoch - 17ms/step\n",
      "Epoch 28/1000\n",
      "37/37 - 1s - loss: 0.0818 - accuracy: 0.9737 - val_loss: 1.3165 - val_accuracy: 0.6954 - 639ms/epoch - 17ms/step\n",
      "Epoch 29/1000\n",
      "37/37 - 1s - loss: 0.0731 - accuracy: 0.9720 - val_loss: 1.2806 - val_accuracy: 0.7259 - 622ms/epoch - 17ms/step\n",
      "Epoch 30/1000\n",
      "37/37 - 1s - loss: 0.0795 - accuracy: 0.9720 - val_loss: 1.3277 - val_accuracy: 0.7005 - 618ms/epoch - 17ms/step\n",
      "Epoch 31/1000\n",
      "37/37 - 1s - loss: 0.0813 - accuracy: 0.9661 - val_loss: 1.2231 - val_accuracy: 0.7107 - 616ms/epoch - 17ms/step\n",
      "Epoch 32/1000\n",
      "37/37 - 1s - loss: 0.0700 - accuracy: 0.9720 - val_loss: 1.3364 - val_accuracy: 0.7157 - 631ms/epoch - 17ms/step\n",
      "Epoch 33/1000\n",
      "37/37 - 1s - loss: 0.0741 - accuracy: 0.9703 - val_loss: 1.3296 - val_accuracy: 0.7157 - 626ms/epoch - 17ms/step\n",
      "Epoch 34/1000\n",
      "37/37 - 1s - loss: 0.0654 - accuracy: 0.9771 - val_loss: 1.3279 - val_accuracy: 0.6954 - 640ms/epoch - 17ms/step\n",
      "Epoch 35/1000\n",
      "37/37 - 1s - loss: 0.0638 - accuracy: 0.9779 - val_loss: 1.3271 - val_accuracy: 0.7005 - 630ms/epoch - 17ms/step\n",
      "Epoch 36/1000\n",
      "37/37 - 1s - loss: 0.0596 - accuracy: 0.9779 - val_loss: 1.3533 - val_accuracy: 0.7157 - 620ms/epoch - 17ms/step\n",
      "Epoch 37/1000\n",
      "37/37 - 1s - loss: 0.0654 - accuracy: 0.9678 - val_loss: 1.3833 - val_accuracy: 0.7056 - 617ms/epoch - 17ms/step\n",
      "Epoch 38/1000\n",
      "37/37 - 1s - loss: 0.0696 - accuracy: 0.9712 - val_loss: 1.3281 - val_accuracy: 0.7157 - 620ms/epoch - 17ms/step\n",
      "Epoch 39/1000\n",
      "37/37 - 1s - loss: 0.0608 - accuracy: 0.9737 - val_loss: 1.4065 - val_accuracy: 0.7107 - 647ms/epoch - 17ms/step\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_42 (Conv1D)          (None, 1180, 20)          100       \n",
      "                                                                 \n",
      " max_pooling1d_38 (MaxPoolin  (None, 590, 20)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 590, 20)           0         \n",
      "                                                                 \n",
      " flatten_41 (Flatten)        (None, 11800)             0         \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 256)               3021056   \n",
      "                                                                 \n",
      " dense_88 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,021,413\n",
      "Trainable params: 3,021,413\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    verbose=2,\n",
    "    validation_data=(X_dev, y_dev),\n",
    "    batch_size=32,\n",
    "    callbacks=[es]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e5f279",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (etsy)",
   "language": "python",
   "name": "etsy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
