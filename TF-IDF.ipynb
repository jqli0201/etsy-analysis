{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "abc48fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "#load inthe NTLK stopwords to remove articles, preposition and other words that are not actionable\n",
    "from nltk.corpus import stopwords\n",
    "# This allows to create individual objects from a bog of words\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "# Lemmatizer helps to reduce words to the base form\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "29ebda21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/jasmineli/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jasmineli/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/jasmineli/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('summer-products-with-rating-and-performance_2020-08.csv')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "9b8a0cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sentence(sentence):\n",
    "    new_tokens = word_tokenize(sentence)\n",
    "    new_tokens = [t.lower() for t in new_tokens]\n",
    "    new_tokens =[t for t in new_tokens if t not in stopwords.words('english')]\n",
    "    new_tokens = [t for t in new_tokens if t.isalpha()]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    new_tokens =[lemmatizer.lemmatize(t) for t in new_tokens]\n",
    "    return \"\".join(new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "a880c2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = df['title_orig'].tolist()\n",
    "tokens = [process_sentence(t) for t in titles]\n",
    "df['title_pre'] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "a5a29e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(df['title_pre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "775d0a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasmineli/opt/anaconda3/envs/etsy/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "tfidf = pd.DataFrame(denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "a6e4b0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1573, 1159)\n"
     ]
    }
   ],
   "source": [
    "print(tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "fc8156d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasmineli/opt/anaconda3/envs/etsy/lib/python3.7/site-packages/pandas/core/arraylike.py:364: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# product color\n",
    "def main_color(s):\n",
    "    main_color = {\"red\":\"red\", \"white\":\"white\", \"pink\":\"pink\", \"yellow\":\"yellow\", \"green\":\"green\", \"blue\":\"blue\", \"wine\":\"red\", \"burgundy\":\"red\", \"black\":\"black\", \"navy\":\"navy\", \"orange\":\"orange\", \n",
    "    \"rose\":\"pink\", \"gray\":\"gray\", \"grey\":\"gray\", \"purple\":\"purple\", \"violet\":\"purple\", \"army\":\"green\", \"leopard\":\"orange\", \"ivory\":\"white\", \n",
    "    \"brown\":\"brown\", \"coffee\":\"brown\", \"camel\":\"beige\", \"tan\":\"brown\", \"nude\":\"beige\", \"khaki\":\"khaki\", \"apricot\":\"yellow\", \"camouflage\":\"green\", \"jasper\":\"red\"}  # ordered by importance\n",
    "    for key, value in main_color.items():\n",
    "        if key in s:\n",
    "            return value\n",
    "    return \"others\"\n",
    "product_color = df[\"product_color\"]\n",
    "product_color = [s.lower() if type(s) is str else 'nan' for s in product_color]\n",
    "product_color = [main_color(s) for s in product_color]\n",
    "from matplotlib import colors\n",
    "product_color = [(-0.1,-0.1,-0.1,-0.1) if s == \"others\" else colors.to_rgba(s) for s in product_color]\n",
    "\n",
    "df['product_color_rgb'] = [np.array(t) for t in product_color]\n",
    "\n",
    "# log prices\n",
    "df['log_price'] = [np.log(p) for p in df[\"price\"]]\n",
    "df['log_retail_price'] = [np.log(p) for p in df[\"retail_price\"]]\n",
    "\n",
    "# log merchant rating count\n",
    "df['log_merchant_rating_count'] = np.log(df['merchant_rating_count'])\n",
    "\n",
    "# urgent text\n",
    "df['urgent'] = [1 if s == \"Quantité limitée !\" else 0 for s in df[\"urgency_text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "02d69257",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[[\"log_price\", \"log_retail_price\", \"uses_ad_boosts\", \"badges_count\", \"badge_local_product\", \n",
    "           \"badge_product_quality\", \"badge_fast_shipping\", \"urgent\", \"units_sold\"]]\n",
    "df2 = pd.concat([data, tfidf], axis=1)\n",
    "label = [1 if sales > 1000 else 0 for sales in data[\"units_sold\"]]\n",
    "df2['high_sale'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "94f48cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1573, 1173)\n"
     ]
    }
   ],
   "source": [
    "rgb = df[\"product_color_rgb\"]\n",
    "rgb = np.stack(rgb.values, axis=0)\n",
    "for i in range(4):\n",
    "    df2[\"product_color_rgb\"+str(i)] = rgb[:,i]\n",
    "df2.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "44d3fb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2.loc[:, ~df2.columns.isin(['high_sale', 'units_sold'])]\n",
    "# X = tfidf\n",
    "y = df2['high_sale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "3e9e81f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from keras.layers import Input, Dense, Concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.125, random_state=42)\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, test_size=0.14286, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "1fa30b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 1179\n",
      "number of dev examples = 197\n",
      "number of test examples = 197\n",
      "X_train shape: (1179, 1171)\n",
      "Y_train shape: (1179,)\n",
      "X_dev shape: (197, 1171)\n",
      "Y_dev shape: (197,)\n",
      "X_test shape: (197, 1171)\n",
      "Y_test shape: (197,)\n"
     ]
    }
   ],
   "source": [
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of dev examples = \" + str(X_dev.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(y_train.shape))\n",
    "print (\"X_dev shape: \" + str(X_dev.shape))\n",
    "print (\"Y_dev shape: \" + str(y_dev.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "2f080968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining hold out data for evaluation \n",
    "X_train = tf.expand_dims(X_train, axis=-1)\n",
    "input_shape = X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "55ab87a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1171, 1)\n"
     ]
    }
   ],
   "source": [
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "231c0ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# classifier = LogisticRegression()\n",
    "# classifier.fit(X_train, y_train)\n",
    "\n",
    "# score = classifier.score(evals_X, evals_y)\n",
    "\n",
    "# print(\"Accuracy:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "d313196d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=24, kernel_size=8, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer='l2'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "fcb4c14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "be38e41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "37/37 - 1s - loss: 1.1274 - accuracy: 0.5818 - val_loss: 0.6975 - val_accuracy: 0.6345 - 1s/epoch - 38ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasmineli/opt/anaconda3/envs/etsy/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/1000\n",
      "37/37 - 1s - loss: 0.6967 - accuracy: 0.5869 - val_loss: 0.6732 - val_accuracy: 0.6345 - 836ms/epoch - 23ms/step\n",
      "Epoch 3/1000\n",
      "37/37 - 1s - loss: 0.6938 - accuracy: 0.5869 - val_loss: 0.6742 - val_accuracy: 0.6396 - 889ms/epoch - 24ms/step\n",
      "Epoch 4/1000\n",
      "37/37 - 1s - loss: 0.6906 - accuracy: 0.5937 - val_loss: 0.6792 - val_accuracy: 0.6599 - 864ms/epoch - 23ms/step\n",
      "Epoch 5/1000\n",
      "37/37 - 1s - loss: 0.6934 - accuracy: 0.6031 - val_loss: 0.6870 - val_accuracy: 0.6701 - 844ms/epoch - 23ms/step\n",
      "Epoch 6/1000\n",
      "37/37 - 1s - loss: 0.6957 - accuracy: 0.6073 - val_loss: 0.6753 - val_accuracy: 0.6904 - 830ms/epoch - 22ms/step\n",
      "Epoch 7/1000\n",
      "37/37 - 1s - loss: 0.6958 - accuracy: 0.6098 - val_loss: 0.6815 - val_accuracy: 0.6548 - 866ms/epoch - 23ms/step\n",
      "Epoch 8/1000\n",
      "37/37 - 1s - loss: 0.6983 - accuracy: 0.6268 - val_loss: 0.6824 - val_accuracy: 0.6853 - 810ms/epoch - 22ms/step\n",
      "Epoch 9/1000\n",
      "37/37 - 1s - loss: 0.7029 - accuracy: 0.6243 - val_loss: 0.6937 - val_accuracy: 0.6802 - 850ms/epoch - 23ms/step\n",
      "Epoch 10/1000\n",
      "37/37 - 1s - loss: 0.6955 - accuracy: 0.6310 - val_loss: 0.6843 - val_accuracy: 0.6701 - 808ms/epoch - 22ms/step\n",
      "Epoch 11/1000\n",
      "37/37 - 1s - loss: 0.7046 - accuracy: 0.6056 - val_loss: 0.6992 - val_accuracy: 0.6701 - 827ms/epoch - 22ms/step\n",
      "Epoch 12/1000\n",
      "37/37 - 1s - loss: 0.6934 - accuracy: 0.6633 - val_loss: 0.6863 - val_accuracy: 0.6650 - 862ms/epoch - 23ms/step\n",
      "Epoch 13/1000\n",
      "37/37 - 1s - loss: 0.6914 - accuracy: 0.6590 - val_loss: 0.6837 - val_accuracy: 0.6701 - 910ms/epoch - 25ms/step\n",
      "Epoch 14/1000\n",
      "37/37 - 1s - loss: 0.6944 - accuracy: 0.6743 - val_loss: 0.6896 - val_accuracy: 0.6853 - 870ms/epoch - 24ms/step\n",
      "Epoch 15/1000\n",
      "37/37 - 1s - loss: 0.6937 - accuracy: 0.6641 - val_loss: 0.7020 - val_accuracy: 0.6650 - 823ms/epoch - 22ms/step\n",
      "Epoch 16/1000\n",
      "37/37 - 1s - loss: 0.6917 - accuracy: 0.6853 - val_loss: 0.7066 - val_accuracy: 0.6802 - 815ms/epoch - 22ms/step\n",
      "Epoch 17/1000\n",
      "37/37 - 1s - loss: 0.6864 - accuracy: 0.7150 - val_loss: 0.7156 - val_accuracy: 0.6548 - 818ms/epoch - 22ms/step\n",
      "Epoch 18/1000\n",
      "37/37 - 1s - loss: 0.6882 - accuracy: 0.7099 - val_loss: 0.7144 - val_accuracy: 0.6802 - 810ms/epoch - 22ms/step\n",
      "Epoch 19/1000\n",
      "37/37 - 1s - loss: 0.6680 - accuracy: 0.7472 - val_loss: 0.6924 - val_accuracy: 0.6802 - 791ms/epoch - 21ms/step\n",
      "Epoch 20/1000\n",
      "37/37 - 1s - loss: 0.6467 - accuracy: 0.7583 - val_loss: 0.6885 - val_accuracy: 0.7107 - 876ms/epoch - 24ms/step\n",
      "Epoch 21/1000\n",
      "37/37 - 1s - loss: 0.6549 - accuracy: 0.7523 - val_loss: 0.7357 - val_accuracy: 0.6954 - 858ms/epoch - 23ms/step\n",
      "Epoch 22/1000\n",
      "37/37 - 1s - loss: 0.6551 - accuracy: 0.7574 - val_loss: 0.7200 - val_accuracy: 0.6853 - 790ms/epoch - 21ms/step\n",
      "Epoch 00022: early stopping\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_23 (Conv1D)          (None, 1164, 24)          216       \n",
      "                                                                 \n",
      " max_pooling1d_23 (MaxPoolin  (None, 582, 24)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 582, 24)           0         \n",
      "                                                                 \n",
      " flatten_27 (Flatten)        (None, 13968)             0         \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 128)               1788032   \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,788,377\n",
      "Trainable params: 1,788,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    verbose=2,\n",
    "    validation_data=(X_dev, y_dev),\n",
    "    batch_size=32,\n",
    "    callbacks=[es]\n",
    ")\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (etsy)",
   "language": "python",
   "name": "etsy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
